{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835b171f-bf99-42a4-addd-79c633d23f4b",
   "metadata": {},
   "source": [
    "[TFM](https://github.com/jmrplens/TFG-TFM_EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fb9ae-88b7-4246-8fb7-f7e904b6d049",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Diagrama de flujo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60478eb5-96bc-4235-801e-0bef3c9b2433",
   "metadata": {},
   "source": [
    "<center><img width='600px' src=\"Data/Data_flow.png\"/></center>\n",
    "\n",
    "Metodología\n",
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=294849"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2e215-b652-4dbb-a951-8a62aff35046",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Métodos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yabWKtrCSTTp",
   "metadata": {
    "id": "yabWKtrCSTTp",
    "tags": []
   },
   "source": [
    "## Carga Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9kRlrtLcSWSU",
   "metadata": {
    "id": "9kRlrtLcSWSU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509f4f4-6594-4a0c-9bed-927d3922d6a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Versión y especificación de directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d2b404dc-0e9c-4945-b4e5-d1a77d863a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "MODEL_TIMESTAMP = datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "WEIGHTS_PATH  = './feature_weights/'\n",
    "REPORTS_PATH  = 'Reports/'\n",
    "MODELS_PATH   = 'Models/'\n",
    "F1_SCORES_PATH = 'F1scores/'\n",
    "GA_SCORES_PATH = 'GA_Scores/'\n",
    "HYPERPARAMS_PATH = './hyperparams/'\n",
    "\n",
    "HYPERPARAMS_EVOLUTON_PATH = './hyperparams_evolution/'\n",
    "FINAL_POPULATION_PATH  = './population/'\n",
    "CONFUSIONS_MATRIX_PATH = 'confusion_matrix/'\n",
    "TSNE_PATH = 'tsne/'\n",
    "\n",
    "REPORTS_TIMES_PATH = 'times/'\n",
    "\n",
    "\n",
    "###### MODELS ######\n",
    "MODELS_NAME = ['knn', 'convolution_1d', 'convolution_2d', 'nb', 'svc', 'auto_ml']\n",
    "\n",
    "REPORTS_SUMMARY_PATH = f\"{REPORTS_PATH}summary/\"\n",
    "######## CONFIG ########\n",
    "loaded_timestamp = '2022-07-06-10:47:41'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ccaf93ea-bab8-4846-a12e-bcfa1b14a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop = True\n",
    "calculate_weights = False\n",
    "tsne = True\n",
    "\n",
    "madrid = True\n",
    "\n",
    "tree_method = 'auto' if laptop else 'gpu_hist'\n",
    "\n",
    "train_nn = not laptop\n",
    "other_models = cnn1d = False\n",
    "cnn1d = True\n",
    "cnn2d = True\n",
    "other_models = cnn1d = True\n",
    "\n",
    "# calculate_cnn_hyperparams = True\n",
    "calculate_cnn_hyperparams = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea665cef-e563-4798-8ed2-78a8f2ddb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laptop = True\n",
    "# calculate_weights = True\n",
    "# tsne = False\n",
    "\n",
    "# leeds  = False\n",
    "# madrid = False\n",
    "# UK = True\n",
    "\n",
    "# tree_method = 'auto' if laptop else 'gpu_hist'\n",
    "# # tree_method = 'gpu_hist'\n",
    "# train_nn = False\n",
    "# other_models = cnn1d = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb628e-a7f4-40e8-a62d-576f7a78c2fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importar Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5bb40e62-06ae-46b9-a711-a5d5667c4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "32053d4d-f4d8-4b07-9cd8-bb5bf4ac8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import applications, optimizers\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "from tensorflow.keras.layers import Input, Lambda, Activation, Conv2D, MaxPooling2D, BatchNormalization, Add, concatenate, Conv2DTranspose, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e5732f07-8398-47a1-9d62-53cf7dd45556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 12:34:13.260095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.260849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.261482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.262192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.262816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.263409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 3329 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b591c-8916-415a-a23c-8309f52f56e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importador/Exportador JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "75269bf0-27f7-4b71-b311-256035370133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_json(feature_vector, root_path, file_name):\n",
    "    with open(root_path + file_name, 'w') as outfile:\n",
    "        json.dump(feature_vector, outfile)\n",
    "\n",
    "def load_json(root_path, file_name):\n",
    "    with open(root_path + file_name) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4388716-87a9-4e2d-ab4a-e3959fa1958f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Construcción de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "75b5661a-a9ac-4686-9611-6d43711d1528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_feature_matrix_indexes(sorted_feature_vector,matrix):  \n",
    "\n",
    "    half_row = round((matrix.shape[0] - 1) / 2)\n",
    "    half_column = round((matrix.shape[1] - 1) / 2)\n",
    "\n",
    "    matrix_indexes = {}\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for parent_key in sorted_feature_vector:\n",
    "        normalized_index = math.ceil(index/2)\n",
    "\n",
    "        if (index % 2 != 0): # Impar\n",
    "            current_row = half_row - normalized_index\n",
    "        else: # Par\n",
    "            current_row = half_row + normalized_index\n",
    "\n",
    "        sorted_child_indexes = np.argsort(feature_vector[parent_key]['feature_weights'])[::-1]\n",
    "\n",
    "        child_names   = np.array(feature_vector[parent_key]['feature_childs'])\n",
    "        child_weights = np.array(feature_vector[parent_key]['feature_weights'])\n",
    "\n",
    "        sorted_child_names   = child_names[sorted_child_indexes]\n",
    "        sorted_child_weights = child_weights[sorted_child_indexes]\n",
    "\n",
    "        position = 0\n",
    "        for sorted_child_index in sorted_child_indexes:\n",
    "            normalized_position = math.ceil(position/2)\n",
    "\n",
    "            if (position % 2 != 0): # Impar\n",
    "                current_column = half_column - normalized_position\n",
    "            else: # Par\n",
    "                current_column = half_column + normalized_position\n",
    "\n",
    "            matrix_indexes[child_names[sorted_child_index]] = [current_row, current_column]\n",
    "            position = position + 1 \n",
    "\n",
    "        index = index + 1\n",
    "\n",
    "    return matrix_indexes\n",
    "    \n",
    "def fv2gi(feature_vector):\n",
    "\n",
    "    max_dimension = 0\n",
    "    for key in feature_vector:\n",
    "        childs_number = len(feature_vector[key]['feature_childs'])\n",
    "        max_dimension = max(childs_number, max_dimension)\n",
    "                \n",
    "    matrix = np.zeros((max_dimension, max_dimension))\n",
    "\n",
    "    weights_vector = []\n",
    "    for parent_key in feature_vector:\n",
    "        wpi = sum([float(child_weight) for child_weight in feature_vector[parent_key]['feature_weights']])\n",
    "        feature_vector[parent_key]['wpi'] = wpi\n",
    "        weights_vector.append(wpi)\n",
    "\n",
    "   \n",
    "    sorted_feature_vector = sorted(feature_vector.items(),\n",
    "                                   key = lambda item: item[1]['wpi'],\n",
    "                                   reverse = True)\n",
    "     \n",
    "    sorted_feature_vector = dict(sorted_feature_vector)\n",
    "\n",
    "    \n",
    "    matrix_indexes = get_feature_matrix_indexes(sorted_feature_vector, matrix)\n",
    "\n",
    "    return matrix_indexes\n",
    "\n",
    "# matrix_indexes = fv2gi(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb0004-1f9b-493a-9c83-91d943b5309d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Construcción Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "077b732a-ca4a-440e-8ae2-dbb3d15ba01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_feature_vector(X_dataset,child_weights):\n",
    "  # Obtenemos el set de columnas del dataset\n",
    "  train_columns_set  = set(X_dataset.columns)\n",
    "\n",
    "  for parent_feature in feature_vector.keys():\n",
    "    # Obtiene el set de características hijas del padre actual\n",
    "    # dict.fromleys para mantener el orden, un set desordena los valores\n",
    "    feature_childs_set = dict.fromkeys(feature_vector[parent_feature]['feature_childs'])\n",
    "\n",
    "    # Obtener el índice de las columnas del actual padre para acceder a los pesos del XGBoost\n",
    "    index_feature_childs = X_dataset.columns.get_indexer(feature_childs_set)\n",
    "\n",
    "    feature_vector[parent_feature]['feature_weights'] = list([str(child_weight) for child_weight in child_weights[index_feature_childs]])\n",
    "\n",
    "  return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c95ea-ae18-4406-b116-5ce6674b7f6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Normalización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "017e1821-71be-48d9-85cb-07808165a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_data(X_data):\n",
    "\n",
    "    # Create a sample df\n",
    "    normalized_df = X_data\n",
    "\n",
    "    # Calculate the zscores and drop zscores into new column\n",
    "    for column in normalized_df.columns:\n",
    "        normalized_df[column] = zscore(normalized_df[column])\n",
    "    \n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8358c9a0-6423-4aa8-92a3-e01a8ac72bb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Oversampling de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "efac95c3-8dc1-4acf-b4e0-78d24fa64131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "\n",
    "def oversample_data(X_data, Y_labels):\n",
    "\n",
    "    oversampler = BorderlineSMOTE(kind='borderline-2', random_state = 3)\n",
    "    # oversampler = RandomOverSampler()\n",
    "    # oversampler = KMeansSMOTE()\n",
    "    X_oversampled, Y_oversampled = oversampler.fit_resample(X_data, Y_labels)\n",
    "\n",
    "    print('********** After OverSampling **********')\n",
    "    # print('Slight: ', (Y_oversampled == 'Slight').sum())\n",
    "    # print('Serious:', (Y_oversampled == 'Serious').sum())\n",
    "    # print('Fatal:  ', (Y_oversampled == 'Fatal').sum())\n",
    "    # print('\\n Total X: ', len(X_oversampled), ' Total Y: ', len(Y_oversampled), '\\n')\n",
    "\n",
    "    # print('********** After OverSampling **********')\n",
    "    print('Slight: ', (Y_oversampled == 'Slight').sum())\n",
    "    print('Assistance:', (Y_oversampled == 'Assistance').sum())\n",
    "    print('\\n Total X: ', len(X_oversampled), ' Total Y: ', len(Y_oversampled), '\\n')\n",
    "\n",
    "    return X_oversampled, Y_oversampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e306be-543d-4ba7-b9a4-2cb1cb938f0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Construcción de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7b61998b-bd46-4dad-a0e8-8363f92f7741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gray_images(dataset, max_dimension, matrix_indexes):\n",
    "\n",
    "    matrix_3d = np.zeros((max_dimension, max_dimension, len(dataset.index)))\n",
    "    print(len(dataset.index))\n",
    "    for feature, value in matrix_indexes.items():\n",
    "        matrix_3d[value[0], value[1],] = dataset[feature]\n",
    "        \n",
    "    return matrix_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc000ada-10b7-43b8-ab9f-789d9d35be8c",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Algoritmo genético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a263a40b-6570-42df-8c3c-8f57209e49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMS_TO_OPTIMIZE = {'eta': {'type': 'float',\n",
    "                                   'init': [0.01, 1],\n",
    "                                   'mutation': [-0.2, 0.2],\n",
    "                                   'round': 2\n",
    "                                   },\n",
    "                           'max_depth': {'type': 'int',\n",
    "                                         'init': [1, 25],\n",
    "                                         'mutation': [-3, 3],\n",
    "                                         'step': 1\n",
    "                                   },\n",
    "                           'min_child_weight': {'type': 'float',\n",
    "                                                'init': [0.01, 20.0],\n",
    "                                                'mutation': [-4, 4],\n",
    "                                                'round': 1\n",
    "                                   }\n",
    "                          }\n",
    "\n",
    "number_of_individuals = 50\n",
    "numberOfParentsMating = 10\n",
    "number_of_hyperparams = len(HYPERPARAMS_TO_OPTIMIZE)\n",
    "number_of_generations = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabcfd52-f850-40a9-a44f-183653456b65",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inicializar población"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1f539cc1-22ad-467b-8e0b-0c892aff1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_individual(hyperparams_to_optimize):\n",
    "\n",
    "    individual = []\n",
    "\n",
    "    for key in hyperparams_to_optimize:\n",
    "        min_value = hyperparams_to_optimize[key]['init'][0]\n",
    "        max_value = hyperparams_to_optimize[key]['init'][1]\n",
    "        data_type = hyperparams_to_optimize[key]['type']\n",
    "        \n",
    "        if data_type == 'int':\n",
    "            step = hyperparams_to_optimize[key]['step']\n",
    "            hyperparam = int(random.randrange(min_value, max_value))\n",
    "\n",
    "        if data_type == 'float':\n",
    "            round_to = hyperparams_to_optimize[key]['round']\n",
    "            hyperparam = round(random.uniform(min_value, max_value), round_to)\n",
    "\n",
    "        individual.append(hyperparam)\n",
    "    \n",
    "    return individual\n",
    "\n",
    "def initialize_population(number_of_individuals, hyperparams_to_optimize):\n",
    "    population = []\n",
    "\n",
    "    for i in range(number_of_individuals):\n",
    "\n",
    "        population.append(generate_individual(hyperparams_to_optimize))\n",
    "      \n",
    "    return np.array(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b80a92b-17eb-4a29-b12e-3852265dde12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d5133e38-307e-4138-a664-fd4e28dc89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def fitness_f1score(y_true, y_pred):\n",
    "\n",
    "    fitness = round((f1_score(y_true, y_pred, average='micro')), 4)\n",
    "\n",
    "    return fitness # Train the data annd find fitness score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9222dcc-088c-468e-bbc7-a0dec6541004",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluación de población"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "03f69b5d-1aba-4bad-a705-adcc672e68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "def train_population(population, hyperparams_to_optimize, dMatrixTrain, dMatrixTest, Y_test):\n",
    "\n",
    "    fScore = []\n",
    "    \n",
    "    params = {'objective':'multi:softprob',\n",
    "              'tree_method': 'auto',\n",
    "              'single_precision_histogram': True,\n",
    "              'num_class': 2\n",
    "             }\n",
    "\n",
    "    # params = {'objective':'binary:logistic',\n",
    "    #           'tree_method': tree_method,\n",
    "    #           'single_precision_histogram': True\n",
    "    #          }\n",
    "    for individual_index in range(population.shape[0]):\n",
    "        # Se almacenan en hyperparams_to_optimize los valores del individuo con su nombre correspondiente de hyperparams_name_to_optimize.\n",
    "        hyperparams = {}\n",
    "\n",
    "        for index, hyperparam_value in enumerate(population[individual_index]):\n",
    "\n",
    "            hyperparam_name_to_optimize = list(hyperparams_to_optimize.keys())[index]\n",
    "            data_type = hyperparams_to_optimize[hyperparam_name_to_optimize]['type']\n",
    "\n",
    "            hyperparams[hyperparam_name_to_optimize] = hyperparam_value\n",
    "            hyperparams[hyperparam_name_to_optimize] = hyperparams[hyperparam_name_to_optimize].astype(data_type)\n",
    "        \n",
    "        params.update(hyperparams)\n",
    "\n",
    "        # num_round = params['n_estimators']\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        xgb.set_config(verbosity = 0)\n",
    "        bst = xgb.train(params,\n",
    "                        dMatrixTrain)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        preds = bst.predict(dMatrixTest)\n",
    "        \n",
    "        single_predictions = [np.argmax(pred) for pred in preds]\n",
    "        # preds = preds > 0.5\n",
    "        fitness_score = fitness_f1score(Y_test, single_predictions)\n",
    "\n",
    "        # print(f\"{individual_index}: {hyperparams} --> time(s): {round(end - start, 2)} --> score: {fitness_score}\")\n",
    "\n",
    "        fScore.append(fitness_score)\n",
    "\n",
    "    return fScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b66fd8-ae70-4f20-84f6-0113ae309a08",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Selección de padres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "771d8007-f28e-424c-8ff6-f174822b02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select parents for mating\n",
    "def new_parents_selection(population, fitness, numParents):\n",
    "    selectedParents = np.empty((numParents, population.shape[1])) # Create an array to store fittest parents.\n",
    "\n",
    "    for parentId in range(numParents):\n",
    "        bestFitnessId = np.where(fitness == np.max(fitness))\n",
    "        bestFitnessId  = bestFitnessId[0][0]\n",
    "        selectedParents[parentId, :] = population[bestFitnessId, :]\n",
    "        fitness[bestFitnessId] = -1 # Set this value to negative, in case of F1-score, so this parent is not selected again\n",
    "\n",
    "    return selectedParents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f9b882-ad82-4446-a301-a856dedbd660",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cruzamiento de población"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "db837b53-3d02-446c-aa9c-6c772da6be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Mate these parents to create children having parameters from these parents (we are using uniform crossover method)\n",
    "'''\n",
    "def crossover_uniform(parents, childrenSize):\n",
    "    \n",
    "    crossoverPointIndex  = np.arange(0, np.uint8(childrenSize[1]), 1, dtype= np.uint8) # get all the index\n",
    "    crossoverPointIndex1 = np.random.randint(0, np.uint8(childrenSize[1]), np.uint8(childrenSize[1]/2)) # select half  of the indexes randomly\n",
    "    crossoverPointIndex2 = np.array(list(set(crossoverPointIndex) - set(crossoverPointIndex1))) #select leftover indexes\n",
    "    \n",
    "    children = np.empty(childrenSize)\n",
    "    \n",
    "    '''\n",
    "    Create child by choosing parameters from two parents selected using new_parent_selection function. The parameter values\n",
    "    will be picked from the indexes, which were randomly selected above. \n",
    "    '''\n",
    "    for i in range(childrenSize[0]):\n",
    "        \n",
    "        #find parent 1 index \n",
    "        parent1_index = i%parents.shape[0]\n",
    "        #find parent 2 index\n",
    "        parent2_index = (i+1)%parents.shape[0]\n",
    "        #insert parameters based on random selected indexes in parent 1\n",
    "        children[i, crossoverPointIndex1] = parents[parent1_index, crossoverPointIndex1]\n",
    "        #insert parameters based on random selected indexes in parent 1\n",
    "        children[i, crossoverPointIndex2] = parents[parent2_index, crossoverPointIndex2]\n",
    "\n",
    "    return children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d549ad-a75d-4943-a89a-ea9e783054a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mutación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bb741b25-56ed-4e66-adbd-42d3b5607974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(crossover, hyperparams_to_optimize):\n",
    "    \n",
    "    # MUTATION_PROBABILITY = 1/numberOfParameters\n",
    "    \n",
    "    MUTATION_PROBABILITY = 0.4\n",
    "    number_of_parameters = len(hyperparams_to_optimize)\n",
    "\n",
    "    for idx in range(crossover.shape[0]):\n",
    "\n",
    "        mutation_probability = np.random.rand(1)\n",
    "\n",
    "        while MUTATION_PROBABILITY > mutation_probability:\n",
    "\n",
    "            mutationValue = 0\n",
    "\n",
    "            hyperparam_selected_index = np.random.randint(0, number_of_parameters)\n",
    "            hyperparam_selected_name  = list(hyperparams_to_optimize.keys())[hyperparam_selected_index]\n",
    "\n",
    "            min_limit_value = hyperparams_to_optimize[hyperparam_selected_name]['init'][0]\n",
    "            max_limit_value = hyperparams_to_optimize[hyperparam_selected_name]['init'][1]\n",
    "\n",
    "            min_mutation_value = hyperparams_to_optimize[hyperparam_selected_name]['mutation'][0]\n",
    "            max_mutation_value = hyperparams_to_optimize[hyperparam_selected_name]['mutation'][1]\n",
    "\n",
    "            data_type = hyperparams_to_optimize[hyperparam_selected_name]['type']\n",
    "            \n",
    "            if data_type == 'int':\n",
    "                step = hyperparams_to_optimize[hyperparam_selected_name]['step']\n",
    "                mutationValue = int(random.randrange(min_mutation_value, max_mutation_value, step = step))\n",
    "\n",
    "            if data_type == 'float':\n",
    "                round_to = hyperparams_to_optimize[hyperparam_selected_name]['round']\n",
    "                mutationValue = round(random.uniform(min_mutation_value, max_mutation_value), round_to)\n",
    "                \n",
    "            # print(idx, hyperparam_selected_name, mutationValue)\n",
    "\n",
    "            crossover[idx, hyperparam_selected_index] = crossover[idx,hyperparam_selected_index] + mutationValue\n",
    "\n",
    "            if(crossover[idx, hyperparam_selected_index] > max_limit_value):\n",
    "                crossover[idx, hyperparam_selected_index] = max_limit_value\n",
    "\n",
    "            if(crossover[idx, hyperparam_selected_index] < min_limit_value):\n",
    "                crossover[idx, hyperparam_selected_index] = min_limit_value\n",
    "                \n",
    "            mutation_probability = np.random.rand(1)\n",
    "\n",
    "\n",
    "    return crossover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d6d9f-8ae4-4740-9983-e51d39cdeac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reshape de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5ded491b-6d05-44f5-9ee9-44064babfd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one channel\n",
    "# https://machinelearningmastery.com/a-gentle-introduction-to-channels-first-and-channels-last-image-formats-for-deep-learning/\n",
    "\n",
    "# Add one channel to gray images depending of the number of the data\n",
    "def shape_images(X_data, gray_images):\n",
    "  images = []\n",
    "\n",
    "  for i in range(0,len(X_data)):\n",
    "      original_matrix = gray_images[:,:,i]\n",
    "      # print(original_matrix.shape)\n",
    "      shaped_image = np.expand_dims(original_matrix, axis=2)\n",
    "      # print(shaped_image.shape)\n",
    "      images.append(shaped_image)\n",
    "      # plt.matshow(shaped_image)\n",
    "\n",
    "  return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a71fa80-2c77-46a3-819c-bb7a0ff9a5a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## One-Hot Encoder/Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "81a2db8a-49a5-4a06-bf66-025a0d472001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def casualty_to_one_hot(Y_labels):\n",
    "\n",
    "    transf = {\n",
    "        'Slight': 0,\n",
    "        'Serious': 1,\n",
    "        'Fatal': 2\n",
    "    }\n",
    "\n",
    "    Y_labels.replace(transf, inplace = True)\n",
    "\n",
    "    return tf.one_hot(Y_labels, 3)\n",
    "\n",
    "def one_hot_to_casualty(Y_labels):\n",
    "\n",
    "    transf = {\n",
    "        0: 'Slight',\n",
    "        1: 'Serious',\n",
    "        2: 'Fatal'\n",
    "    }   \n",
    "\n",
    "    return Y_labels.replace(transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5d6b04e1-1d9b-4551-88d1-29fd199e2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def casualty_to_one_hot(Y_labels):\n",
    "\n",
    "    transf = {\n",
    "        'Slight': 0,\n",
    "        'Assistance': 1\n",
    "    }\n",
    "\n",
    "    Y_labels.replace(transf, inplace = True)\n",
    "\n",
    "    return tf.one_hot(Y_labels, 2)\n",
    "\n",
    "def one_hot_to_casualty(Y_labels):\n",
    "\n",
    "    transf = {\n",
    "        0: 'Slight',\n",
    "        1: 'Assistance'\n",
    "    }   \n",
    "\n",
    "    return Y_labels.replace(transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021df180-f056-4e21-ac6e-39d41369831b",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Visualización de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a4a49-64d8-4a32-abf7-e626f39d0938",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "29dfa69d-7135-476f-9c1d-4ebf5d30bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def correlation_matrix(X_data):\n",
    "    corrMatrix = X_data.corr()\n",
    "    fig,ax  = plt.subplots(1,1,figsize=(20,15))\n",
    "    sns.heatmap(corrMatrix, annot=True)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation = 30)\n",
    "    plt.savefig('saving-a-seaborn-plot-as-eps-file.svg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eaa5de-34f0-4724-ba36-0fdcf19c64e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d011694-26fe-41e3-9a39-85722f128f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca(X_train_data, X_test_data):\n",
    "    pca = PCA()\n",
    "    X_train_pca = pca.fit_transform(X_train_data)\n",
    "    X_test_pca  = pca.transform(X_test_data)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "    figure_name = plt.figure(figsize=(20, 15))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    plt.savefig('saving-a-seaborn-plot-as-eps-file.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401456b5-b7b9-421c-83db-709796ee1d8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "74c55dca-09c1-4831-a64c-bc04a9cdf73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def plot_TSNE(X_data, Y_data, n_components, output_file_name, title):\n",
    "\n",
    "    # X_data_scaled = StandardScaler().fit_transform(X_data)\n",
    "    z_data = TSNE(n_components = n_components).fit_transform(X_data)\n",
    "\n",
    "    # X_test_scaled = StandardScaler().fit_transform(X_test),\n",
    "    # z_test = TSNE(n_components=2).fit_transform(X_test_scaled),\n",
    "\n",
    "    palette = sns.color_palette('husl', 3)\n",
    "    fig,ax  = plt.subplots(1, 1, figsize=(7,4))\n",
    "    sns.scatterplot(x = z_data[:,0],\n",
    "                    y = z_data[:,1],\n",
    "                    hue = Y_data,\n",
    "                    palette = palette,\n",
    "                    legend = 'full'\n",
    "                   ).set(title = title)\n",
    "    plt.xlabel('Dimension 1', weight = 'bold').set_fontsize('10')\n",
    "    plt.ylabel('Dimension 1', weight = 'bold').set_fontsize('10')\n",
    "\n",
    "    if (output_file_name): plt.savefig(output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b4c26-5100-4723-9342-b7b9aa187d79",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0f4072a7-e2e5-4e45-9456-4bea3270a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder ():\n",
    "    input_img = Input(shape=(25,))\n",
    "\n",
    "    # definimos el encoder, que tendra una entrada de Input_img y una segunda capa con entrada de encoder1 y salida 3\n",
    "    encoder1 = layers.Dense(15, activation='sigmoid')(input_img)\n",
    "    encoder2 = layers.Dense(3, activation='sigmoid')(encoder1)\n",
    "\n",
    "    # definimos el  decoder que tendra una entrada inicial de encoder3 y una salida de 128 y finalmete una capa de salida con los mismos que Input_img\n",
    "    decoder1 = layers.Dense(15, activation='sigmoid')(encoder2)\n",
    "    decoder2 = layers.Dense(25, activation='sigmoid')(decoder1)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = tf.keras.Model(inputs=input_img, outputs=decoder2)\n",
    "    autoencoder.summary()\n",
    "\n",
    "    autoencoder.compile(optimizer='adam',\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=[tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold=0.1)],) #se usan estos dos en estas arquitecturas\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684781d-95b6-4f1d-a45f-37e7b332e085",
   "metadata": {},
   "source": [
    "## C-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1d551aa9-a234-487f-9a27-353f89d344cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc6df4-982b-49e8-8649-8da2c48a5af1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1D-Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9e0a8732-da51-49e8-92d5-e27a67fc56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "62c8eaad-10d3-46ae-89b9-be1f28028268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 12:34:13.545148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.545980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.546657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.547623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.548301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.548934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.549645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.550274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 12:34:13.550867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3329 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "lr_init = 0.1\n",
    "\n",
    "convolution_1d = models.Sequential()\n",
    "convolution_1d.add(layers.Conv1D(256, 3, strides = 1, activation='relu', padding='same', input_shape=(5, 5, 1)))\n",
    "convolution_1d.add(layers.BatchNormalization())\n",
    "convolution_1d.add(layers.Conv1D(256, 3, strides = 1, activation='relu', padding='same'))\n",
    "convolution_1d.add(layers.BatchNormalization())\n",
    "convolution_1d.add(layers.Conv1D(256, 3, strides = 1, activation='relu', padding='same'))\n",
    "convolution_1d.add(layers.BatchNormalization())\n",
    "convolution_1d.add(layers.Conv1D(256, 3, strides = 1, activation='relu', padding='same'))\n",
    "convolution_1d.add(layers.Flatten())\n",
    "convolution_1d.add(layers.BatchNormalization())\n",
    "convolution_1d.add(layers.Dense(units=128))\n",
    "convolution_1d.add(layers.BatchNormalization())\n",
    "convolution_1d.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "convolution_1d.compile(\n",
    "    optimizer=Adam(learning_rate = lr_init, epsilon=1e-06),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold=0.1)]\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8294e009-1114-46bc-b794-8e3d3e608a72",
   "metadata": {},
   "source": [
    "### 3 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "22b2924f-95ff-40c7-9f3f-f25569fc4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def get_1d_conv(fm_one, fm_two, fm_three, fm_four, dense, dropout=0.2, learnRate=0.01):\n",
    "    cnn_1d_conv = models.Sequential()\n",
    "    cnn_1d_conv.add(layers.Conv1D(fm_one, 3, strides=1, activation='relu', padding='same', input_shape=(5, 5, 1)))\n",
    "    cnn_1d_conv.add(layers.BatchNormalization())\n",
    "    cnn_1d_conv.add(layers.Conv1D(fm_two, 3, strides=1, activation='relu', padding='same'))\n",
    "    cnn_1d_conv.add(layers.BatchNormalization())\n",
    "    cnn_1d_conv.add(layers.Conv1D(fm_three, 3, strides=1, activation='relu', padding='same'))\n",
    "    cnn_1d_conv.add(layers.BatchNormalization())\n",
    "    cnn_1d_conv.add(layers.Conv1D(fm_four, 3, strides=1, activation='relu', padding='same'))\n",
    "    cnn_1d_conv.add(layers.Flatten())\n",
    "    cnn_1d_conv.add(layers.BatchNormalization())\n",
    "    cnn_1d_conv.add(layers.Dense(units=dense))\n",
    "    cnn_1d_conv.add(layers.BatchNormalization())\n",
    "    cnn_1d_conv.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    cnn_1d_conv.compile(\n",
    "        optimizer=Adam(learning_rate = learnRate, epsilon=1e-06),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold=0.1)]\n",
    "    )\n",
    "    \n",
    "    return cnn_1d_conv\n",
    "\n",
    "# convolution_1d.compile(\n",
    "#     optimizer=Adam(learning_rate = lr_init, epsilon=1e-06),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=[tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold=0.1)]\n",
    "#   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d40ff-a460-4a5b-9de9-669c7f84981d",
   "metadata": {},
   "source": [
    "### 2 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "15f48541-4d30-4fe5-ad18-60444ea823c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def get_1d_conv(fm_one, fm_two, fm_three, fm_four, dense, dropout=0.2, learnRate=0.01):\n",
    "    cnn_1d_conv = models.Sequential()\n",
    "    cnn_1d_conv.add(layers.Conv1D(fm_one, 3, strides=1, activation='relu', padding='same', input_shape=(5, 5, 1)))\n",
    "    cnn_1d_conv.add(layers.BatchNormalization())\n",
    "    cnn_1d_conv.add(layers.Conv1D(fm_two, 3, strides=1, activation='relu', padding='same'))\n",
    "    cnn_1d_conv.add(layers.BatchNormalization())\n",
    "    cnn_1d_conv.add(layers.Conv1D(fm_three, 3, strides=1, activation='relu', padding='same'))\n",
    "    cnn_1d_conv.add(layers.BatchNormalization())\n",
    "    cnn_1d_conv.add(layers.Conv1D(fm_four, 3, strides=1, activation='relu', padding='same'))\n",
    "    cnn_1d_conv.add(layers.Flatten())\n",
    "    cnn_1d_conv.add(layers.BatchNormalization())\n",
    "    cnn_1d_conv.add(layers.Dense(units=dense))\n",
    "    cnn_1d_conv.add(layers.BatchNormalization())\n",
    "    cnn_1d_conv.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    cnn_1d_conv.compile(\n",
    "        optimizer=Adam(learning_rate = learnRate, epsilon=1e-06),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold=0.1)]\n",
    "    )\n",
    "    \n",
    "    return cnn_1d_conv\n",
    "\n",
    "# convolution_1d.compile(\n",
    "#     optimizer=Adam(learning_rate = lr_init, epsilon=1e-06),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=[tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold=0.1)]\n",
    "#   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8ea062-c0b7-4486-9ebe-94ae66a58b54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TASP-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "05497b70-0400-4219-8a07-3a43005066cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_init = 0.0001\n",
    "\n",
    "tasp_cnn = models.Sequential()\n",
    "tasp_cnn.add(layers.Conv2D(128, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(5, 5, 1)))\n",
    "tasp_cnn.add(layers.Dropout(.2,  input_shape=(3, 3, 128)))\n",
    "tasp_cnn.add(layers.BatchNormalization())\n",
    "tasp_cnn.add(layers.Conv2D(1024, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(3, 3, 128)))\n",
    "tasp_cnn.add(layers.Dropout(.2,  input_shape=(3, 3, 128)))\n",
    "tasp_cnn.add(layers.BatchNormalization())\n",
    "tasp_cnn.add(layers.Conv2D(512, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(3, 3, 1024)))\n",
    "tasp_cnn.add(layers.Dropout(.2,  input_shape=(3, 3, 32)))\n",
    "tasp_cnn.add(layers.BatchNormalization())\n",
    "tasp_cnn.add(layers.Conv2D(1024, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(3, 3, 512)))\n",
    "tasp_cnn.add(layers.Dropout(.2,  input_shape=(3, 3, 1024)))\n",
    "tasp_cnn.add(layers.Flatten())\n",
    "tasp_cnn.add(layers.BatchNormalization())\n",
    "tasp_cnn.add(layers.Dense(units=32))\n",
    "tasp_cnn.add(layers.Dropout(.5))\n",
    "tasp_cnn.add(layers.BatchNormalization())\n",
    "tasp_cnn.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "tasp_cnn.compile(\n",
    "    optimizer=Adam(learning_rate = lr_init, epsilon=1e-06),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold=0.1)]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69459038-c699-4c38-b80a-60e5a99ccf3d",
   "metadata": {},
   "source": [
    "### 3 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eb18c896-28d5-4da1-877e-2e13bc20879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tasp_cnn(fm_one, fm_two, fm_three, fm_four, fm_five, fm_six, dense, dropout=0.2, learnRate=0.01):\n",
    "def get_tasp_cnn(fm_one, fm_two, fm_three, fm_four, dense, dropout=0.2, learnRate=0.01):\n",
    "    tasp_cnn = models.Sequential()\n",
    "    tasp_cnn.add(layers.Conv2D(fm_one, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(5, 5, 1)))\n",
    "    tasp_cnn.add(layers.BatchNormalization())\n",
    "    tasp_cnn.add(layers.Conv2D(fm_two, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(3, 3, fm_one)))\n",
    "    tasp_cnn.add(layers.BatchNormalization())\n",
    "    tasp_cnn.add(layers.Conv2D(fm_three, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(3, 3, fm_two)))\n",
    "    tasp_cnn.add(layers.BatchNormalization())\n",
    "    tasp_cnn.add(layers.Conv2D(fm_four, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(3, 3, fm_three)))\n",
    "    tasp_cnn.add(layers.Flatten())\n",
    "    tasp_cnn.add(layers.BatchNormalization())\n",
    "    tasp_cnn.add(layers.Dense(units=dense))\n",
    "    tasp_cnn.add(layers.BatchNormalization())\n",
    "    tasp_cnn.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    tasp_cnn.compile(\n",
    "        optimizer=Adam(learning_rate = learnRate, epsilon=1e-06),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold=0.1)]\n",
    "      )\n",
    "    \n",
    "    return tasp_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c88ab-8b6a-4b3d-b7e0-1762f847eb55",
   "metadata": {},
   "source": [
    "### 2 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b0a2871-0939-4799-86b2-237c8c0253c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tasp_cnn(fm_one, fm_two, fm_three, fm_four, fm_five, fm_six, dense, dropout=0.2, learnRate=0.01):\n",
    "def get_tasp_cnn(fm_one, fm_two, fm_three, fm_four, dense, dropout=0.2, learnRate=0.01):\n",
    "    tasp_cnn = models.Sequential()\n",
    "    tasp_cnn.add(layers.Conv2D(fm_one, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(5, 5, 1)))\n",
    "    tasp_cnn.add(layers.BatchNormalization())\n",
    "    tasp_cnn.add(layers.Conv2D(fm_two, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(3, 3, fm_one)))\n",
    "    tasp_cnn.add(layers.BatchNormalization())\n",
    "    tasp_cnn.add(layers.Conv2D(fm_three, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(3, 3, fm_two)))\n",
    "    tasp_cnn.add(layers.BatchNormalization())\n",
    "    tasp_cnn.add(layers.Conv2D(fm_four, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(3, 3, fm_three)))\n",
    "    tasp_cnn.add(layers.Flatten())\n",
    "    tasp_cnn.add(layers.BatchNormalization())\n",
    "    tasp_cnn.add(layers.Dense(units=dense))\n",
    "    tasp_cnn.add(layers.BatchNormalization())\n",
    "    tasp_cnn.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    tasp_cnn.compile(\n",
    "        optimizer=Adam(learning_rate = learnRate, epsilon=1e-06),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold=0.1)]\n",
    "      )\n",
    "    \n",
    "    return tasp_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7b99ef66-1c52-47f9-851f-2cab1406b114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 5, 5, 128)         1280      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 5, 5, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 5, 5, 1024)        1180672   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 1024)        0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 5, 5, 1024)       4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 5, 512)         4719104   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 5, 5, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 1024)        4719616   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 5, 5, 1024)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25600)             0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 25600)            102400    \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                819232    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,549,154\n",
      "Trainable params: 11,494,562\n",
      "Non-trainable params: 54,592\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tasp_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "41d457bb-2db3-4b69-b0b7-bcf867dbeb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea9112-c2a3-474d-87a5-ba64c599ab56",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5be32-4a2d-457d-bd39-5ab2da01a809",
   "metadata": {
    "tags": []
   },
   "source": [
    "### F1-Score History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6daa83e3-3b42-4e84-ae09-087c65298e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f1_score_history(f1_score_path, f1_score_name, history):\n",
    "    figure_name = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    history.history['f1_score'].insert(0, 0)\n",
    "    history.history['val_f1_score'].insert(0, 0)\n",
    "\n",
    "    plt.plot(history.history['f1_score'], label='F1 score (training data)')\n",
    "    plt.plot(history.history['val_f1_score'], label='F1 score (validation data)')\n",
    "    plt.title('F1 score')\n",
    "    plt.ylabel('F1 score value')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(f1_score_path + f1_score_name)\n",
    "    plt.show()\n",
    "    \n",
    "    print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529e0fc-6e5c-46aa-8029-d053d4df3d88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "14bcc399-bc1c-490d-b537-3fd46d4e49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def plot_classification_report(path, file_name, y_true, y_predicted):\n",
    "\n",
    "    labels = one_hot_to_casualty(y_true)\n",
    "\n",
    "    report = classification_report(y_true,\n",
    "                                   y_predicted,\n",
    "                                   target_names = labels.unique(),\n",
    "                                   output_dict  = True)\n",
    "\n",
    "    report_df = pd.DataFrame(report).transpose().round(3)\n",
    "    report_df.to_csv(path + file_name, index = True)\n",
    "\n",
    "    print(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9703d-abc2-42b0-8dff-31a2a715815e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1d46827f-b218-49c7-9902-4337c1457d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(path, file_name, y_true, y_predicted):\n",
    "\n",
    "    cm = confusion_matrix(y_true,\n",
    "                          y_predicted,\n",
    "                          labels = y_true.unique())\n",
    "\n",
    "    labels = one_hot_to_casualty(y_true)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix = cm,\n",
    "                                  display_labels = labels.unique()).plot()\n",
    "\n",
    "    plt.savefig(path + file_name, dpi = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "faf262a8-e7db-40c1-9cca-eeb101e191c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_classification_report_and_confussion_matrix(model_name, model_timestamp, y_true, y_predicted, data):\n",
    "    \n",
    "    \n",
    "    report_path = f\"{REPORTS_PATH}{model_name}/{data}/\"\n",
    "    report_name = f\"{city_name}_{MODEL_NAME}_report_{model_timestamp}.csv\"\n",
    "\n",
    "\n",
    "    plot_classification_report(path = report_path,\n",
    "                               file_name = report_name,\n",
    "                               y_true = y_true,\n",
    "                               y_predicted = y_predicted)\n",
    "\n",
    "\n",
    "    confussion_matrix_path = f\"{CONFUSIONS_MATRIX_PATH}{model_name}/{data}/\"\n",
    "    confussion_matrix_name = f\"{city_name}_{MODEL_NAME}_confusion_matrix_{model_timestamp}.svg\"\n",
    "\n",
    "    plot_confusion_matrix(path = confussion_matrix_path,\n",
    "                          file_name = confussion_matrix_name,\n",
    "                          y_true = y_true,\n",
    "                          y_predicted = y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "271fbe6a-965a-48b3-902d-384140c96fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oMQbX1j_zVOO",
   "metadata": {
    "id": "oMQbX1j_zVOO",
    "tags": []
   },
   "source": [
    "# Madrid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pG-PDMY6zdqE",
   "metadata": {
    "id": "pG-PDMY6zdqE",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Importación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wlkJKFfzBd8g",
   "metadata": {
    "id": "wlkJKFfzBd8g"
   },
   "source": [
    "- [Web Dataset](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=7c2843010d9c3610VgnVCM2000001f4a900aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default)\n",
    "\n",
    "- [Web documentación](https://datos.madrid.es/FWProjects/egob/Catalogo/Seguridad/Ficheros/Estructura_DS_Accidentes_trafico_desde_2019.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "283f204c-3787-4461-8a0d-b787570d7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_timestamp = '2022-05-24-11:01:39'\n",
    "model_version = '2022-05-17-20:07:36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "Ic0tgQy47zEr",
   "metadata": {
    "id": "Ic0tgQy47zEr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "city_name = 'madrid'\n",
    "city = madrid\n",
    "\n",
    "# root_path = '/content/drive/Othercomputers/Mi portátil/Drive/Master UA/TFM/Incidentes de Trafico/Datasets/Madrid/'\n",
    "\n",
    "root_path = './Data/Madrid/'\n",
    "\n",
    "file_name_2019 = '2019_Accidentalidad.csv'\n",
    "file_name_2020 = '2020_Accidentalidad.csv'\n",
    "file_name_2021 = '2021_Accidentalidad.csv'\n",
    "file_name_2022 = '2022_Accidentalidad.csv'\n",
    "\n",
    "file_2019 = pd.read_csv(root_path + file_name_2019, sep=';')\n",
    "file_2020 = pd.read_csv(root_path + file_name_2020, sep=';')\n",
    "file_2021 = pd.read_csv(root_path + file_name_2021, sep=';')\n",
    "file_2022 = pd.read_csv(root_path + file_name_2022, sep=';')\n",
    "\n",
    "# print(len(file_2019[file_2019.cod_lesividad == 4]))\n",
    "# print(len(file_2020[file_2020.cod_lesividad == 4]))\n",
    "# print(len(file_2021[file_2021.lesividad == '4']))\n",
    "# print(len(file_2022[file_2022.lesividad == '4']))\n",
    "\n",
    "COLUMNS_TO_REMOVE = ['cod_distrito',\n",
    "                     'tipo_lesividad'\n",
    "                    ]\n",
    "\n",
    "data_frame = file_2019\n",
    "data_frame = pd.concat([data_frame, file_2020])\n",
    "\n",
    "data_frame.rename(columns={\"cod_lesividad\": \"lesividad\"}, inplace = True)\n",
    "data_frame.rename(columns={\"tipo_vehículo\": \"tipo_vehiculo\"}, inplace = True)\n",
    "data_frame = data_frame.drop(COLUMNS_TO_REMOVE, axis=1)\n",
    "\n",
    "data_frame = pd.concat([data_frame, file_2021])\n",
    "\n",
    "data_frame.dropna(subset=['lesividad'], inplace = True)\n",
    "data_frame.lesividad = data_frame.lesividad.replace(' ', 14).astype(int)\n",
    "data_frame = data_frame.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5PmJpoCCcxMJ",
   "metadata": {
    "id": "5PmJpoCCcxMJ"
   },
   "source": [
    "### Calcular Vehículos implicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utgDSVryALnm",
   "metadata": {
    "id": "utgDSVryALnm"
   },
   "source": [
    "A partir del número de expediente (un mismo expediente en varias filas quiere decir que se trata del mismo accidente) se hace un `groupby` a partir de él. Como el atributo `positiva_alcohol` no tiene valores nulos en ninguna de las filas, hacemos un conteo a partir de él y se asigna a una nueva columna `positiva_alcohol_rename` que posteriormente será renombrada como `vehiculos_implicados`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "qy9UBWGFan1j",
   "metadata": {
    "id": "qy9UBWGFan1j"
   },
   "outputs": [],
   "source": [
    "data_frame = data_frame.join(data_frame.groupby('num_expediente')['positiva_alcohol'].count(), on='num_expediente', rsuffix='_rename')\n",
    "data_frame.rename(columns={\"positiva_alcohol_rename\": \"vehiculos_implicados\"}, errors=\"raise\", inplace=True)\n",
    "data_frame = data_frame.reset_index(drop=True)\n",
    "# data_frame.localizacion.unique()[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3lX-EnJ1aby",
   "metadata": {
    "id": "e3lX-EnJ1aby",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ybjvOI7x0PKz",
   "metadata": {
    "id": "ybjvOI7x0PKz",
    "tags": []
   },
   "source": [
    "### Clasificación de carreteras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "38c43193-d332-4c5e-a173-ce0877ad9ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PK|P.K|parking\n",
      "1907\n",
      "AEROPUERTO|AEROP\n",
      "157\n",
      "CUSTA|CUESTA\n",
      "237\n",
      "PASEO|paseo\n",
      "5677\n",
      "PARQUE|PQUE|RETIRO\n",
      "265\n",
      "TUNEL|TÚNEL\n",
      "382\n",
      "POLIGONO\n",
      "4\n",
      "CMNO|CAMINO\n",
      "838\n",
      "RONDA\n",
      "445\n",
      "GTA|gta|GLORIETA|glorieta|ROTONDA|FUENT\n",
      "1972\n",
      "PUERTA|PTA|Puerta\n",
      "93\n",
      "PNTE|PUENTE\n",
      "148\n",
      "PLAZA|PZA\n",
      "2416\n",
      "BULE\n",
      "82\n",
      "TRVA\n",
      "102\n",
      "CALZADA\n",
      "626\n",
      "CTRA.|CARRETERA|carretera|CRA.\n",
      "942\n",
      "AVDA|AV|AVENIDA|AVDA|avenida|Avda.\n",
      "13701\n",
      "AUTOV.|autovia|A-|M-|M 30|m 30|A\\d|M 23|M23|KILOMETRO\n",
      "3698\n",
      "CALL.|Calle|CALLE|c/|C/|C.|calle\n",
      "27146\n"
     ]
    }
   ],
   "source": [
    "# ######################### SIGUIENTE CELDA #########################\n",
    "\n",
    "# # Unclassified: Carreteras locales sin destino definido. Sin embargo, los destinos locales pueden estar señalizados a lo largo de ellos.\n",
    "# # A, A(M) y Motorway lo mismo?\n",
    "# # B:            De carácter regional y utilizado para conectar zonas de menor importancia.\n",
    "# #               Por lo general, se muestran de color marrón o amarillo en los mapas y tienen las mismas señales blancas que las rutas de clase A que no son primarias.\n",
    "# #               Si la ruta es primaria, como la B6261, se mostrará igual que una ruta Clase A primaria.\n",
    "# #               ¿Carretera como tal?\n",
    "\n",
    "# # C:            Designaciones de autoridades locales para rutas dentro de su área con fines administrativos.\n",
    "# #               Estas rutas no se muestran en mapas de carreteras a pequeña escala, pero se sabe que ocasionalmente aparecen en las señales de tráfico.\n",
    "\n",
    "# # Unclassified\n",
    "\n",
    "\n",
    "regex = {}\n",
    "regex['parking'] = 'PK|P.K|parking'\n",
    "regex['aeropuerto_regex'] = 'AEROPUERTO|AEROP'\n",
    "regex['cuesta_regex'] = 'CUSTA|CUESTA'\n",
    "regex['paseo_regex'] = 'PASEO|paseo'\n",
    "regex['parque_regex'] = 'PARQUE|PQUE|RETIRO'\n",
    "regex['tunel_regex'] = 'TUNEL|TÚNEL'\n",
    "regex['poligono_regex'] ='POLIGONO'\n",
    "regex['camino_regex']= 'CMNO|CAMINO'\n",
    "regex['ronda_regex'] = 'RONDA'\n",
    "regex['rotonda_regex'] = 'GTA|gta|GLORIETA|glorieta|ROTONDA|FUENT'\n",
    "regex['puerta_regex'] = 'PUERTA|PTA|Puerta'\n",
    "regex['puente_regex'] = 'PNTE|PUENTE'\n",
    "regex['plaza_regex'] = 'PLAZA|PZA'\n",
    "regex['bulevard_regex'] = 'BULE'\n",
    "regex['travesia_regex'] = 'TRVA'\n",
    "regex['calzada_regex'] = 'CALZADA'\n",
    "regex['road_regex'] = 'CTRA.|CARRETERA|carretera|CRA.' # B\n",
    "regex['avenida_regex'] = 'AVDA|AV|AVENIDA|AVDA|avenida|Avda.'\n",
    "regex['highway_regex'] = 'AUTOV.|autovia|A-|M-|M 30|m 30|A\\\\d|M 23|M23|KILOMETRO' # A,A(M),Motorway\n",
    "regex['calle_regex']  = 'CALL.|Calle|CALLE|c/|C/|C.|calle'\n",
    "\n",
    "data_frame['tipo_via'] = 'N/A'\n",
    "\n",
    "for index,regex_values in enumerate(regex.values()):\n",
    "    \n",
    "    print(regex_values)\n",
    "    regex_indexes = data_frame[data_frame.localizacion.str.contains(regex_values,  case = True, regex=True)].index\n",
    "    print(len(regex_indexes))\n",
    "    data_frame.iloc[regex_indexes, data_frame.columns.get_loc('tipo_via')] = str(index)\n",
    "    data_frame.iloc[regex_indexes, data_frame.columns.get_loc('localizacion')] = str(index)\n",
    "    \n",
    "    \n",
    "    \n",
    "# # street_indexes  = data_frame[data_frame.localizacion.str.contains('CALL.|Calle|CALLE|c/|C/|C.|calle', case = True, regex=True)].index\n",
    "# # highway_indexes = data_frame[data_frame.localizacion.str.contains(highway_regex, case = True, regex=True)].index\n",
    "# # road_indexes    = data_frame[data_frame.localizacion.str.contains(road_regex, case = True, regex=True)].index\n",
    "# # # avenue_indexes  = data_frame[data_frame.localizacion.str.contains(avenue_regex,  case = True, regex=True)].index\n",
    "# # # ride_indexes    = data_frame[data_frame.localizacion.str.contains(ride_regex, case = True, regex=True)].index\n",
    "\n",
    "# # data_frame['tipo_via'] = 'N/A'\n",
    "\n",
    "# # data_frame.iloc[street_indexes,  data_frame.columns.get_loc('tipo_via')] = 'Unclassified'\n",
    "# # data_frame.iloc[highway_indexes, data_frame.columns.get_loc('tipo_via')] = 'A'\n",
    "# # data_frame.iloc[road_indexes, data_frame.columns.get_loc('tipo_via')] = 'B'\n",
    "# # # data_frame.iloc[ride_indexes, data_frame.columns.get_loc('tipo_via')] = 'AVENIDA'\n",
    "# # # data_frame.iloc[avenue_indexes,  data_frame.columns.get_loc('tipo_via')] = 'AVENIDA'\n",
    "\n",
    "\n",
    "# # data_frame.iloc[highway_indexes, data_frame.columns.get_loc('localizacion')] = 1\n",
    "# # data_frame.iloc[road_indexes, data_frame.columns.get_loc('localizacion')] = 2\n",
    "# # data_frame.iloc[street_indexes,  data_frame.columns.get_loc('localizacion')] = 3\n",
    "# # # data_frame.iloc[avenue_indexes,  data_frame.columns.get_loc('localizacion')] = '3'\n",
    "# # # data_frame.iloc[ride_indexes, data_frame.columns.get_loc('localizacion')] = '5'\n",
    "\n",
    "# positive_drug_indexes = data_frame[data_frame.positiva_droga == 1].index\n",
    "# data_frame.iloc[positive_drug_indexes, data_frame.columns.get_loc('positiva_alcohol')] = 'S'\n",
    "\n",
    "# data_frame = data_frame[~(data_frame.tipo_via == 'N/A')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c2095094-b3b4-46ba-ae44-2225d3068135",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_assigned_location_values = data_frame[~data_frame.localizacion.str.isnumeric()].index\n",
    "data_frame.loc[index_of_assigned_location_values, 'localizacion'] = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2eed4b67-287c-4c40-927c-0f3f71bf74f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    27146\n",
       "17    13701\n",
       "3      5677\n",
       "18     3698\n",
       "12     2416\n",
       "9      1972\n",
       "0      1907\n",
       "16      942\n",
       "7       838\n",
       "15      628\n",
       "8       445\n",
       "5       382\n",
       "4       265\n",
       "2       237\n",
       "1       159\n",
       "11      148\n",
       "19      124\n",
       "14      102\n",
       "10       93\n",
       "13       82\n",
       "6         4\n",
       "Name: localizacion, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.localizacion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7da252aZ0N3n",
   "metadata": {
    "id": "7da252aZ0N3n"
   },
   "outputs": [],
   "source": [
    "# ######################### SIGUIENTE CELDA #########################\n",
    "\n",
    "# # Unclassified: Carreteras locales sin destino definido. Sin embargo, los destinos locales pueden estar señalizados a lo largo de ellos.\n",
    "# # A, A(M) y Motorway lo mismo?\n",
    "# # B:            De carácter regional y utilizado para conectar zonas de menor importancia.\n",
    "# #               Por lo general, se muestran de color marrón o amarillo en los mapas y tienen las mismas señales blancas que las rutas de clase A que no son primarias.\n",
    "# #               Si la ruta es primaria, como la B6261, se mostrará igual que una ruta Clase A primaria.\n",
    "# #               ¿Carretera como tal?\n",
    "\n",
    "# # C:            Designaciones de autoridades locales para rutas dentro de su área con fines administrativos.\n",
    "# #               Estas rutas no se muestran en mapas de carreteras a pequeña escala, pero se sabe que ocasionalmente aparecen en las señales de tráfico.\n",
    "\n",
    "# # Unclassified\n",
    "# street_regex  = ('CALL.|Calle|CALLE|c/|C/|C.|calle|'\n",
    "#                  'AVDA|AV|AVENIDA|AVDA|avenida|Avda.|'\n",
    "#                  'PASEO|paseo|'\n",
    "#                  'PARQUE|PQUE|'\n",
    "#                  'RONDA|'\n",
    "#                  'PUERTA|PTA|Puerta|'\n",
    "#                  'PNTE|PUENTE|'\n",
    "#                  'PLAZA|PZA|'\n",
    "#                  'CMNO|CAMINO|'\n",
    "#                  'BULE|'\n",
    "#                  'TRVA|'\n",
    "#                  'CUSTA|CUESTA|'\n",
    "#                  'GTA|gta|GLORIETA|glorieta|ROTONDA|'\n",
    "#                  'AEROPUERTO|AEROP'\n",
    "# )\n",
    "\n",
    "# highway_regex = 'AUTOV.|autovia|A-|M-|M 30|m 30|A\\\\d|M 23|M23' # A,A(M),Motorway\n",
    "# road_regex = 'CTRA.|CARRETERA|carretera|CRA.|CALZADA|POLIGONO' # B\n",
    "\n",
    "# street_indexes  = data_frame[data_frame.localizacion.str.contains(street_regex,  case = True, regex=True)].index\n",
    "# highway_indexes = data_frame[data_frame.localizacion.str.contains(highway_regex, case = True, regex=True)].index\n",
    "# road_indexes    = data_frame[data_frame.localizacion.str.contains(road_regex, case = True, regex=True)].index\n",
    "# # avenue_indexes  = data_frame[data_frame.localizacion.str.contains(avenue_regex,  case = True, regex=True)].index\n",
    "# # ride_indexes    = data_frame[data_frame.localizacion.str.contains(ride_regex, case = True, regex=True)].index\n",
    "\n",
    "# data_frame['tipo_via'] = 'N/A'\n",
    "\n",
    "# data_frame.iloc[street_indexes,  data_frame.columns.get_loc('tipo_via')] = 'Unclassified'\n",
    "# data_frame.iloc[highway_indexes, data_frame.columns.get_loc('tipo_via')] = 'A'\n",
    "# data_frame.iloc[road_indexes, data_frame.columns.get_loc('tipo_via')] = 'B'\n",
    "# # data_frame.iloc[ride_indexes, data_frame.columns.get_loc('tipo_via')] = 'AVENIDA'\n",
    "# # data_frame.iloc[avenue_indexes,  data_frame.columns.get_loc('tipo_via')] = 'AVENIDA'\n",
    "\n",
    "\n",
    "# data_frame.iloc[highway_indexes, data_frame.columns.get_loc('localizacion')] = 1\n",
    "# data_frame.iloc[road_indexes, data_frame.columns.get_loc('localizacion')] = 2\n",
    "# data_frame.iloc[street_indexes,  data_frame.columns.get_loc('localizacion')] = 3\n",
    "# # data_frame.iloc[avenue_indexes,  data_frame.columns.get_loc('localizacion')] = '3'\n",
    "# # data_frame.iloc[ride_indexes, data_frame.columns.get_loc('localizacion')] = '5'\n",
    "\n",
    "# # positive_drug_indexes = data_frame[data_frame.positiva_droga == 1].index\n",
    "# # data_frame.iloc[positive_drug_indexes, data_frame.columns.get_loc('positiva_alcohol')] = 'S'\n",
    "\n",
    "# data_frame = data_frame[~(data_frame.tipo_via == 'N/A')]\n",
    "# # print(data_frame.localizacion.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "150ab043-51a7-44ef-ab42-2e46804ef17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_expediente</th>\n",
       "      <th>fecha</th>\n",
       "      <th>hora</th>\n",
       "      <th>localizacion</th>\n",
       "      <th>numero</th>\n",
       "      <th>distrito</th>\n",
       "      <th>tipo_accidente</th>\n",
       "      <th>estado_meteorológico</th>\n",
       "      <th>tipo_vehiculo</th>\n",
       "      <th>tipo_persona</th>\n",
       "      <th>rango_edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>lesividad</th>\n",
       "      <th>coordenada_x_utm</th>\n",
       "      <th>coordenada_y_utm</th>\n",
       "      <th>positiva_alcohol</th>\n",
       "      <th>positiva_droga</th>\n",
       "      <th>vehiculos_implicados</th>\n",
       "      <th>tipo_via</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018S017842</td>\n",
       "      <td>04/02/2019</td>\n",
       "      <td>9:10:00</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Motocicleta &gt; 125cc</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>De 45 a 49 años</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>7</td>\n",
       "      <td>440.068.049</td>\n",
       "      <td>4.475.679.170</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018S017842</td>\n",
       "      <td>04/02/2019</td>\n",
       "      <td>9:10:00</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>Colisión lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>De 30 a 34 años</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>7</td>\n",
       "      <td>440.068.049</td>\n",
       "      <td>4.475.679.170</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019S000002</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>3:50:00</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>LATINA</td>\n",
       "      <td>Choque contra obstáculo fijo</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>De 21 a 24 años</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>2</td>\n",
       "      <td>436.473.789</td>\n",
       "      <td>4.472.030.489</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019S000006</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>8:10:00</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>CARABANCHEL</td>\n",
       "      <td>Choque contra obstáculo fijo</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>De 21 a 24 años</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>14</td>\n",
       "      <td>438.116.128</td>\n",
       "      <td>4.471.171.190</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019S000006</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>8:10:00</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>CARABANCHEL</td>\n",
       "      <td>Choque contra obstáculo fijo</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>De 55 a 59 años</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>14</td>\n",
       "      <td>438.116.128</td>\n",
       "      <td>4.471.171.190</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60961</th>\n",
       "      <td>2021S015803</td>\n",
       "      <td>31/08/2021</td>\n",
       "      <td>13:50:00</td>\n",
       "      <td>19</td>\n",
       "      <td>168</td>\n",
       "      <td>USERA</td>\n",
       "      <td>Alcance</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>De 55 a 59 años</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>14</td>\n",
       "      <td>439279</td>\n",
       "      <td>4470784,77</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60962</th>\n",
       "      <td>2021S015803</td>\n",
       "      <td>31/08/2021</td>\n",
       "      <td>13:50:00</td>\n",
       "      <td>19</td>\n",
       "      <td>168</td>\n",
       "      <td>USERA</td>\n",
       "      <td>Alcance</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Pasajero</td>\n",
       "      <td>De 35 a 39 años</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>2</td>\n",
       "      <td>439279</td>\n",
       "      <td>4470784,77</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60963</th>\n",
       "      <td>2021S016898</td>\n",
       "      <td>31/08/2021</td>\n",
       "      <td>22:56:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>MORATALAZ</td>\n",
       "      <td>Colisión fronto-lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Motocicleta hasta 125cc</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>De 25 a 29 años</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>7</td>\n",
       "      <td>443959,86</td>\n",
       "      <td>4473579,83</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60964</th>\n",
       "      <td>2021S016898</td>\n",
       "      <td>31/08/2021</td>\n",
       "      <td>22:56:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>MORATALAZ</td>\n",
       "      <td>Colisión fronto-lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Conductor</td>\n",
       "      <td>De 25 a 29 años</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>14</td>\n",
       "      <td>443959,86</td>\n",
       "      <td>4473579,83</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60965</th>\n",
       "      <td>2021S016898</td>\n",
       "      <td>31/08/2021</td>\n",
       "      <td>22:56:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>MORATALAZ</td>\n",
       "      <td>Colisión fronto-lateral</td>\n",
       "      <td>Despejado</td>\n",
       "      <td>Turismo</td>\n",
       "      <td>Pasajero</td>\n",
       "      <td>De 25 a 29 años</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>14</td>\n",
       "      <td>443959,86</td>\n",
       "      <td>4473579,83</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60966 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_expediente       fecha      hora localizacion numero     distrito  \\\n",
       "0        2018S017842  04/02/2019   9:10:00           19      1       CENTRO   \n",
       "1        2018S017842  04/02/2019   9:10:00           19      1       CENTRO   \n",
       "2        2019S000002  01/01/2019   3:50:00           19     65       LATINA   \n",
       "3        2019S000006  01/01/2019   8:10:00           19     16  CARABANCHEL   \n",
       "4        2019S000006  01/01/2019   8:10:00           19     16  CARABANCHEL   \n",
       "...              ...         ...       ...          ...    ...          ...   \n",
       "60961    2021S015803  31/08/2021  13:50:00           19    168        USERA   \n",
       "60962    2021S015803  31/08/2021  13:50:00           19    168        USERA   \n",
       "60963    2021S016898  31/08/2021  22:56:00            7      1    MORATALAZ   \n",
       "60964    2021S016898  31/08/2021  22:56:00            7      1    MORATALAZ   \n",
       "60965    2021S016898  31/08/2021  22:56:00            7      1    MORATALAZ   \n",
       "\n",
       "                     tipo_accidente estado_meteorológico  \\\n",
       "0                  Colisión lateral            Despejado   \n",
       "1                  Colisión lateral            Despejado   \n",
       "2      Choque contra obstáculo fijo            Despejado   \n",
       "3      Choque contra obstáculo fijo            Despejado   \n",
       "4      Choque contra obstáculo fijo            Despejado   \n",
       "...                             ...                  ...   \n",
       "60961                       Alcance            Despejado   \n",
       "60962                       Alcance            Despejado   \n",
       "60963       Colisión fronto-lateral            Despejado   \n",
       "60964       Colisión fronto-lateral            Despejado   \n",
       "60965       Colisión fronto-lateral            Despejado   \n",
       "\n",
       "                 tipo_vehiculo tipo_persona       rango_edad    sexo  \\\n",
       "0          Motocicleta > 125cc    Conductor  De 45 a 49 años  Hombre   \n",
       "1                      Turismo    Conductor  De 30 a 34 años   Mujer   \n",
       "2                      Turismo    Conductor  De 21 a 24 años  Hombre   \n",
       "3                      Turismo    Conductor  De 21 a 24 años  Hombre   \n",
       "4                      Turismo    Conductor  De 55 a 59 años  Hombre   \n",
       "...                        ...          ...              ...     ...   \n",
       "60961                  Turismo    Conductor  De 55 a 59 años  Hombre   \n",
       "60962                  Turismo     Pasajero  De 35 a 39 años   Mujer   \n",
       "60963  Motocicleta hasta 125cc    Conductor  De 25 a 29 años  Hombre   \n",
       "60964                  Turismo    Conductor  De 25 a 29 años   Mujer   \n",
       "60965                  Turismo     Pasajero  De 25 a 29 años  Hombre   \n",
       "\n",
       "       lesividad coordenada_x_utm coordenada_y_utm positiva_alcohol  \\\n",
       "0              7      440.068.049    4.475.679.170                N   \n",
       "1              7      440.068.049    4.475.679.170                N   \n",
       "2              2      436.473.789    4.472.030.489                N   \n",
       "3             14      438.116.128    4.471.171.190                S   \n",
       "4             14      438.116.128    4.471.171.190                N   \n",
       "...          ...              ...              ...              ...   \n",
       "60961         14           439279       4470784,77                N   \n",
       "60962          2           439279       4470784,77                N   \n",
       "60963          7        443959,86       4473579,83                N   \n",
       "60964         14        443959,86       4473579,83                N   \n",
       "60965         14        443959,86       4473579,83                N   \n",
       "\n",
       "       positiva_droga  vehiculos_implicados tipo_via  \n",
       "0                 NaN                     2       19  \n",
       "1                 NaN                     2       19  \n",
       "2                 NaN                     1       19  \n",
       "3                 NaN                     2       19  \n",
       "4                 NaN                     2       19  \n",
       "...               ...                   ...      ...  \n",
       "60961             NaN                     3       19  \n",
       "60962             NaN                     3       19  \n",
       "60963             NaN                     3        7  \n",
       "60964             NaN                     3        7  \n",
       "60965             NaN                     3        7  \n",
       "\n",
       "[60966 rows x 19 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc350245-b09e-4de1-9ecb-3d2f8d60ba7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Consideraciones:\n",
    "\n",
    "- Los patinetes se han considerado como ciclomotres de menos de 50cc.\n",
    "- Las furgonetas se consideran como vehículos de menos de 3.5 toneladas.\n",
    "- Maquinaria de obras se considera la misma tipología que maquinaria agrícola.\n",
    "- Cuadriciclos ligeros y no ligeros se consideran como `Motorcycle-Unknown CC`.\n",
    "- Patinetes y Vehículos de Mobilidad Urbana se consideran como `Mobility Scooters`.\n",
    "- `Vehículo articulado` se considera como un vehículo de más de 7.5 toneladas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "RwdUhUHc1Up4",
   "metadata": {
    "id": "RwdUhUHc1Up4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado meteorológico: \n",
      " 1.0    50915\n",
      "3.0     3948\n",
      "2.0     2942\n",
      "7.0      919\n",
      "4.0      804\n",
      "6.0       81\n",
      "5.0       18\n",
      "Name: estado_meteorológico, dtype: int64\n",
      "Tipo vehículo: \n",
      " 5.0     39050\n",
      "3.0      5655\n",
      "4.0      4877\n",
      "9.0      3561\n",
      "1.0      2154\n",
      "6.0      1913\n",
      "2.0      1429\n",
      "12.0     1188\n",
      "13.0      513\n",
      "15.0      396\n",
      "8.0       115\n",
      "14.0       43\n",
      "11.0        9\n",
      "10.0        2\n",
      "7.0         1\n",
      "Name: tipo_vehiculo, dtype: int64\n",
      "Tipo de persona: \n",
      " 1.0    46022\n",
      "2.0    11409\n",
      "3.0     3530\n",
      "Name: tipo_persona, dtype: int64\n",
      "Sexo: \n",
      " 1    40374\n",
      "2    20348\n",
      "3      244\n",
      "Name: sexo, dtype: int64\n",
      "Positivo Alcohol: \n",
      " 2    59616\n",
      "1     1350\n",
      "Name: positiva_alcohol, dtype: int64\n",
      "Gravedad: \n",
      " Slight     59593\n",
      "Serious     1284\n",
      "Fatal         84\n",
      "77             5\n",
      "Name: lesividad, dtype: int64\n",
      "Edad: \n",
      " 3    47132\n",
      "2     6859\n",
      "4     3958\n",
      "1     2699\n",
      "5      318\n",
      "Name: rango_edad, dtype: int64\n",
      "hora: 1    37079\n",
      "2    23887\n",
      "Name: hora, dtype: int64\n",
      "Distrito: \n",
      " 4.0     5189\n",
      "7.0     4429\n",
      "19.0    4319\n",
      "2.0     3930\n",
      "12.0    3705\n",
      "14.0    3418\n",
      "15.0    3341\n",
      "0.0     3203\n",
      "20.0    3192\n",
      "6.0     3188\n",
      "10.0    3039\n",
      "9.0     2973\n",
      "1.0     2796\n",
      "17.0    2722\n",
      "8.0     2478\n",
      "16.0    2158\n",
      "11.0    1778\n",
      "3.0     1647\n",
      "5.0     1604\n",
      "13.0     972\n",
      "18.0     880\n",
      "Name: distrito, dtype: int64\n",
      "Tipo Accidente: \n",
      " 2     17049\n",
      "4     15076\n",
      "6      6723\n",
      "0      6462\n",
      "3      6134\n",
      "8      4060\n",
      "1      3061\n",
      "5      1503\n",
      "11      442\n",
      "7       207\n",
      "10      176\n",
      "9        69\n",
      "12        4\n",
      "Name: tipo_accidente, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "weather_conditions_replace = {\n",
    "    'Despejado': 1,\n",
    "    'Nublado': 2,\n",
    "    'Lluvia débil': 3,\n",
    "    'LLuvia intensa': 4,\n",
    "    'Granizando':  5,\n",
    "    'Nevando': 6,\n",
    "    'Se desconoce': 7 \n",
    "}\n",
    "\n",
    "## CUIDADO CON Motocicleta hasta 125cc!!! HEMOS SUPUESTO QUE LOS CICLOMOTORES SON HASTA 50CC!!\n",
    "type_of_vehicle_replace = {\n",
    "    'Bicicleta': 1,\n",
    "    'Ciclo': 1,\n",
    "    'Bicicleta EPAC (pedaleo asistido)': 1,\n",
    "    'Ciclomotor': 2,\n",
    "    'Ciclomotor de dos ruedas L1e-B': 2,\n",
    "    'Ciclomotor de tres ruedas': 2,\n",
    "    'Motocicleta hasta 125cc': 3,\n",
    "    'Moto de tres ruedas hasta 125cc': 3,\n",
    "    'Motocicleta > 125cc': 4,\n",
    "    'Moto de tres ruedas > 125cc': 4,\n",
    "    'Turismo': 5,\n",
    "    'Todo terreno': 5,\n",
    "    'Microbús <= 17 plazas': 5,\n",
    "    'Autobús': 6,\n",
    "    'Autobus EMT': 6,\n",
    "    'Autobús articulado': 6,\n",
    "    'Autobús articulado EMT': 6,\n",
    "    'Maquinaria agrícola': 7,\n",
    "    'Maquinaria de obras': 8,\n",
    "    'Furgoneta': 9,        # Menos de 3.5 toneladas.\n",
    "    'Ambulancia SAMUR': 10,\n",
    "    'Autocaravana': 11,     # Entre 3.5 y 7.5 toneladas.\n",
    "    'Camión rígido': 12,    # Mayor que 7.5 toneladas.\n",
    "    'Tractocamión': 12,\n",
    "    'Vehículo articulado': 12,\n",
    "    'Camión de bomberos': 12,\n",
    "    'VMU eléctrico': 13,\n",
    "    'Patinete': 13,\n",
    "    'Sin especificar': 14,\n",
    "    'Otros vehículos sin motor': 14,\n",
    "    'Remolque': 14,\n",
    "    'Semiremolque': 14,\n",
    "    'Otros vehículos con motor': 15,\n",
    "    'Cuadriciclo ligero': 15,\n",
    "    'Cuadriciclo no ligero': 15,\n",
    "    'Motorcycle - Unknown CC': 15\n",
    "}\n",
    "\n",
    "# type_of_vehicle_replace = {}\n",
    "# for index,tipo_vehiculo in enumerate(data_frame.tipo_vehiculo.unique()):\n",
    "#     if not pd.isna(tipo_vehiculo): type_of_vehicle_replace[tipo_vehiculo] = index\n",
    "\n",
    "casualty_class_replace = {\n",
    "    'Conductor': 1,\n",
    "    'Pasajero': 2,\n",
    "    'Peatón': 3\n",
    "}\n",
    "\n",
    "### CUIDADO CON DESCONOCIDO!!! MEJOR HACER IMPUTACIÓN PARA RELLENENAR LOS DESCONOCIDOS?\n",
    "sex_of_casualty_replace = {\n",
    "    'Hombre': 1,\n",
    "    'Mujer': 2,\n",
    "    'Desconocido': 3\n",
    "}\n",
    "\n",
    "accident_type_replace = {\n",
    "    'Colisión fronto-lateral': 1,\n",
    "    'Alcance': 2,\n",
    "    'Colisión lateral': 3,\n",
    "    'Choque contra obstáculo fijo': 4,\n",
    "    'Colisión múltiple': 5,\n",
    "    'Caída': 5,\n",
    "    'Atropello a persona': 7,\n",
    "    'Colisión frontal': 8,\n",
    "    'Otro': 9,\n",
    "    'Solo salida de la vía': 10,\n",
    "    'Vuelco': 11,\n",
    "    'Atropello a animal': 12,\n",
    "    'Despeñamiento': 13\n",
    "}\n",
    "\n",
    "alcohol_replace = {\n",
    "    'S': 1,\n",
    "    'N': 2,\n",
    "}\n",
    "\n",
    "accident_class_replace = {\n",
    "    1:  'Slight',  # Atención en urgencias sin posterior ingreso. - LEVE\n",
    "    2:  'Slight',  # Ingreso inferior o igual a 24 horas - LEVE\n",
    "    5:  'Slight',  # Asistencia sanitaria ambulatoria con posterioridad - LEVE\n",
    "    6:  'Slight',  # Asistencia sanitaria inmediata en centro de salud o mutua - LEVE\n",
    "    7:  'Slight',  # Asistencia sanitaria sólo en el lugar del accidente - LEVE\n",
    "    14: 'Slight',  # Sin asistencia sanitaria - LEVE O NADA\n",
    "    3:  'Serious', # Ingreso superior a 24 horas. - GRAVE\n",
    "    4:  'Fatal'    # Fallecido 24 horas - FALLECIDO \n",
    "}\n",
    "###################### REEMPLAZOS ######################\n",
    "\n",
    "# ### OJO QUE ESTAMOS REPLICANDO LA ESTRUCTURA DEL DATASET DE LEEDS\n",
    "age_replace = {\n",
    "    'Menor de 5 años': 1,\n",
    "    'De 6 a 9 años': 1,\n",
    "    'De 6  a  9 años': 1,\n",
    "    'De 10 a 14 años': 1,\n",
    "    'De 15 a 17 años': 1,\n",
    "    'De 18 a 20 años': 2,\n",
    "    'De 21 a 24 años': 2,\n",
    "    'De 25 a 29 años': 3,\n",
    "    'De 30 a 34 años': 3,\n",
    "    'De 35 a 39 años': 3,\n",
    "    'De 40 a 44 años': 3,\n",
    "    'De 45 a 49 años': 3,\n",
    "    'De 50 a 54 años': 3,\n",
    "    'De 55 a 59 años': 3,\n",
    "    'De 60 a 64 años': 3,\n",
    "    'De 65 a 69 años': 4,\n",
    "    'De 70 a 74 años': 4,\n",
    "    'Más de 74 años': 4,\n",
    "    'Desconocido': 5,\n",
    "}\n",
    "\n",
    "# age_replace = {\n",
    "#     'Menor de 5 años': 1,\n",
    "#     'De 6 a 9 años': 2,\n",
    "#     'De 6  a  9 años': 3,\n",
    "#     'De 10 a 14 años': 4,\n",
    "#     'De 15 a 17 años': 5,\n",
    "#     'De 18 a 20 años': 6,\n",
    "#     'De 21 a 24 años': 7,\n",
    "#     'De 25 a 29 años': 8,\n",
    "#     'De 30 a 34 años': 9,\n",
    "#     'De 35 a 39 años': 10,\n",
    "#     'De 40 a 44 años': 11,\n",
    "#     'De 45 a 49 años': 12,\n",
    "#     'De 50 a 54 años': 13,\n",
    "#     'De 55 a 59 años': 14,\n",
    "#     'De 60 a 64 años': 15,\n",
    "#     'De 65 a 69 años': 16,\n",
    "#     'De 70 a 74 años': 17,\n",
    "#     'Más de 74 años': 18,\n",
    "#     'Desconocido': 19,\n",
    "# }\n",
    "\n",
    "data_frame['estado_meteorológico'].replace(weather_conditions_replace, inplace = True)\n",
    "print('Estado meteorológico: \\n', data_frame['estado_meteorológico'].value_counts())\n",
    "\n",
    "data_frame['tipo_vehiculo'].replace(type_of_vehicle_replace, inplace = True)\n",
    "print('Tipo vehículo: \\n', data_frame['tipo_vehiculo'].value_counts())\n",
    "\n",
    "data_frame['tipo_persona'].replace(casualty_class_replace, inplace = True)\n",
    "print('Tipo de persona: \\n', data_frame['tipo_persona'].value_counts())\n",
    "\n",
    "data_frame['sexo'].replace(sex_of_casualty_replace, inplace = True)\n",
    "print('Sexo: \\n', data_frame['sexo'].value_counts())\n",
    "\n",
    "data_frame['positiva_alcohol'].replace(alcohol_replace, inplace = True)\n",
    "print('Positivo Alcohol: \\n', data_frame['positiva_alcohol'].value_counts())\n",
    "\n",
    "data_frame['lesividad'].replace(accident_class_replace, inplace = True)\n",
    "print('Gravedad: \\n', data_frame['lesividad'].value_counts())\n",
    "\n",
    "data_frame['rango_edad'].replace(age_replace, inplace = True)\n",
    "print('Edad: \\n', data_frame['rango_edad'].value_counts())\n",
    "\n",
    "data_frame.hora = data_frame.hora.mask(pd.to_datetime(data_frame.hora) < '06:00:00', 2)\n",
    "data_frame.hora = data_frame.hora.mask(pd.to_datetime(data_frame.hora) > '18:00:00', 2)\n",
    "data_frame.hora = data_frame.hora.mask(pd.to_datetime(data_frame.hora).between('06:00:00', '18:00:00'), 1)\n",
    "print('hora:', data_frame['hora'].value_counts())\n",
    "\n",
    "district_replace = {}\n",
    "for index,distrito in enumerate(data_frame.distrito.unique()):\n",
    "  if not pd.isna(distrito): district_replace[distrito] = int(index)\n",
    "\n",
    "accident_type_replace = {}\n",
    "for index,accident_type in enumerate(data_frame.tipo_accidente.unique()):\n",
    "    if not pd.isna(accident_type): accident_type_replace[accident_type] = int(index)\n",
    "\n",
    "data_frame['distrito'].replace(district_replace, inplace = True)\n",
    "print('Distrito: \\n', data_frame['distrito'].value_counts())\n",
    "\n",
    "data_frame['tipo_accidente'].replace(accident_type_replace, inplace = True)\n",
    "print('Tipo Accidente: \\n', data_frame['tipo_accidente'].value_counts())\n",
    "\n",
    "# Eliminamos aquellas lesividades desconocidas i.e. 77.\n",
    "data_frame = data_frame[data_frame.lesividad != 77]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pVPFGQ0AoNRD",
   "metadata": {
    "id": "pVPFGQ0AoNRD",
    "tags": []
   },
   "source": [
    "### Coordenadas UTM a números enteros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nabg28LMAHhW",
   "metadata": {
    "id": "nabg28LMAHhW"
   },
   "source": [
    "Las coordenadas UTM son coordenads que están expresadas en término de X e Y partiendo de la base de que parten desde una determinada localización. Estas coordenadas constan de una parte entera y una decimal.\n",
    "\n",
    "En este dataset el formato que presentan estas coordenadas pueden ser de tres tipos:\n",
    "\n",
    "- **XXX.XXX.XXX**: en este caso los seis primeros dígitos forman la parte entera y los tres útlimos la parte decimal.\n",
    "- **XXXXXX,XX**: los seis primeros dígitos indican la parte entera, mientras que tras la coma aparecen dos dígitos de la parte decimal que habrá que completar añadiendo uno más.\n",
    "- **XXXXXX**: indican la parte entera, sin contar con la parte decimal.\n",
    "\n",
    "Por lo que el objetivo es estandarizar todos los formatos convirtiendo cada una de las coordenadas a un número entero, siendo necesario tratar con cada una de las casuísticas para añadir ceros a la derecha en caso de que falten para que cada una de las coordenadas tenga la misma longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "sgVHBwC0Fd1N",
   "metadata": {
    "id": "sgVHBwC0Fd1N",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9521/1802693479.py:38: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  selected_rows_x1.Integer = selected_rows_x1.Integer.str.replace('.','')\n",
      "/tmp/ipykernel_9521/1802693479.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_x1.Integer = selected_rows_x1.Integer.str.replace('.','')\n",
      "/tmp/ipykernel_9521/1802693479.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_x2.Number  = selected_rows_x2.Number.str.replace(',','.')\n",
      "/tmp/ipykernel_9521/1802693479.py:41: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  selected_rows_y1.Integer = selected_rows_y1.Integer.str.replace('.','')\n",
      "/tmp/ipykernel_9521/1802693479.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_y1.Integer = selected_rows_y1.Integer.str.replace('.','')\n",
      "/tmp/ipykernel_9521/1802693479.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_y2.Number  = selected_rows_y2.Number.str.replace(',','.')\n",
      "/tmp/ipykernel_9521/1802693479.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_x1['processed_x_utm'] = selected_rows_x1.Integer + selected_rows_x1.Float\n",
      "/tmp/ipykernel_9521/1802693479.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_x2['processed_x_utm'] = selected_rows_x2.Number\n",
      "/tmp/ipykernel_9521/1802693479.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_x3['processed_x_utm'] = selected_rows_x3.Number\n",
      "/tmp/ipykernel_9521/1802693479.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_y1['processed_y_utm'] = selected_rows_y1.Integer + selected_rows_y1.Float\n",
      "/tmp/ipykernel_9521/1802693479.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_y2['processed_y_utm'] = selected_rows_y2.Number\n",
      "/tmp/ipykernel_9521/1802693479.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_y3['processed_y_utm'] = selected_rows_y3.Number\n",
      "/tmp/ipykernel_9521/1802693479.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_x_utm'] = 'N/A'\n",
      "/tmp/ipykernel_9521/1802693479.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_y_utm'] = 'N/A'\n",
      "/tmp/ipykernel_9521/1802693479.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_x2.processed_x_utm = selected_rows_x2.processed_x_utm.transform(lambda x: x + '0'*(10-len(x)))\n",
      "/tmp/ipykernel_9521/1802693479.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_x3.processed_x_utm = selected_rows_x3.processed_x_utm.transform(lambda x: x + '.000')\n",
      "/tmp/ipykernel_9521/1802693479.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_y2.processed_y_utm = selected_rows_y2.processed_y_utm.transform(lambda x: x + '0'*(11-len(x)))\n",
      "/tmp/ipykernel_9521/1802693479.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows_y3.processed_y_utm = selected_rows_y3.processed_y_utm.transform(lambda x: x + '.000')\n",
      "/tmp/ipykernel_9521/1802693479.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_x_utm'][selected_rows_x1.index] = selected_rows_x1['processed_x_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_x_utm'][selected_rows_x1.index] = selected_rows_x1['processed_x_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_x_utm'][selected_rows_x2.index] = selected_rows_x2['processed_x_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_x_utm'][selected_rows_x2.index] = selected_rows_x2['processed_x_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_x_utm'][selected_rows_x3.index] = selected_rows_x3['processed_x_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_x_utm'][selected_rows_x3.index] = selected_rows_x3['processed_x_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_y_utm'][selected_rows_y1.index] = selected_rows_y1['processed_y_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_y_utm'][selected_rows_y1.index] = selected_rows_y1['processed_y_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_y_utm'][selected_rows_y2.index] = selected_rows_y2['processed_y_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_y_utm'][selected_rows_y2.index] = selected_rows_y2['processed_y_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_y_utm'][selected_rows_y3.index] = selected_rows_y3['processed_y_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['processed_y_utm'][selected_rows_y3.index] = selected_rows_y3['processed_y_utm']\n",
      "/tmp/ipykernel_9521/1802693479.py:77: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data_frame.processed_x_utm = data_frame.processed_x_utm.str.replace('.','')\n",
      "/tmp/ipykernel_9521/1802693479.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame.processed_x_utm = data_frame.processed_x_utm.str.replace('.','')\n",
      "/tmp/ipykernel_9521/1802693479.py:78: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data_frame.processed_y_utm = data_frame.processed_y_utm.str.replace('.','')\n",
      "/tmp/ipykernel_9521/1802693479.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame.processed_y_utm = data_frame.processed_y_utm.str.replace('.','')\n",
      "/tmp/ipykernel_9521/1802693479.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame.processed_x_utm = data_frame.processed_x_utm.astype(int)\n",
      "/tmp/ipykernel_9521/1802693479.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame.processed_y_utm = data_frame.processed_y_utm.astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Todos las comas a puntos\n",
    "\n",
    "import re\n",
    "\n",
    "s = data_frame.coordenada_x_utm.str\n",
    "s_y = data_frame.coordenada_y_utm.str\n",
    "\n",
    "# Regex que hace match para dos grupos, la parte entera y la parte decimal.\n",
    "group_integer_and_float_pattern = '(?P<Integer>\\d{3}\\.\\d{3})(?P<Float>\\.\\d{2,3})'\n",
    "all_float_pattern   = '(?P<Number>\\d{6},\\d+)'\n",
    "all_integer_pattern = '(?P<Number>\\d{6}$)'\n",
    "\n",
    "group_integer_and_float_pattern_y = '(?P<Integer>\\d\\.\\d{3}\\.\\d{3})(?P<Float>\\.\\d{2,3})'\n",
    "all_float_pattern_y   = '(?P<Number>\\d{7},\\d+)'\n",
    "all_integer_pattern_y = '(?P<Number>\\d{7}$)'\n",
    "\n",
    "# Se extraen en un dataframe independiente ambas partes, la entera y la decimal\n",
    "index_and_extracted_x1 = s.extract(group_integer_and_float_pattern)\n",
    "index_and_extracted_x2 = s.extract(all_float_pattern)\n",
    "index_and_extracted_x3 = s.extract(all_integer_pattern)\n",
    "\n",
    "index_and_extracted_y1 = s_y.extract(group_integer_and_float_pattern_y)\n",
    "index_and_extracted_y2 = s_y.extract(all_float_pattern_y)\n",
    "index_and_extracted_y3 = s_y.extract(all_integer_pattern_y)\n",
    "\n",
    "# Se seleccionan aquellas que no continenen valores nulos el Float.\n",
    "# Es decir, aquellos con los que el match ha tenido éxito (los que llevan punto)\n",
    "# en lugar de comas.\n",
    "selected_rows_x1 = index_and_extracted_x1[~index_and_extracted_x1['Float'].isnull()]\n",
    "selected_rows_x2 = index_and_extracted_x2[~index_and_extracted_x2['Number'].isnull()]\n",
    "selected_rows_x3 = index_and_extracted_x3[~index_and_extracted_x3['Number'].isnull()]\n",
    "\n",
    "selected_rows_y1 = index_and_extracted_y1[~index_and_extracted_y1['Float'].isnull()]\n",
    "selected_rows_y2 = index_and_extracted_y2[~index_and_extracted_y2['Number'].isnull()]\n",
    "selected_rows_y3 = index_and_extracted_y3[~index_and_extracted_y3['Number'].isnull()]\n",
    "\n",
    "# Se cambia el string de la parte entera a un string sin puntos.\n",
    "selected_rows_x1.Integer = selected_rows_x1.Integer.str.replace('.','')\n",
    "selected_rows_x2.Number  = selected_rows_x2.Number.str.replace(',','.')\n",
    "\n",
    "selected_rows_y1.Integer = selected_rows_y1.Integer.str.replace('.','')\n",
    "selected_rows_y2.Number  = selected_rows_y2.Number.str.replace(',','.')\n",
    "\n",
    "# Se crea una nueva columna en el nuevo dataframe con la unión de la parte\n",
    "# entera y la parte decimal.\n",
    "selected_rows_x1['processed_x_utm'] = selected_rows_x1.Integer + selected_rows_x1.Float\n",
    "selected_rows_x2['processed_x_utm'] = selected_rows_x2.Number\n",
    "selected_rows_x3['processed_x_utm'] = selected_rows_x3.Number\n",
    "\n",
    "selected_rows_y1['processed_y_utm'] = selected_rows_y1.Integer + selected_rows_y1.Float\n",
    "selected_rows_y2['processed_y_utm'] = selected_rows_y2.Number\n",
    "selected_rows_y3['processed_y_utm'] = selected_rows_y3.Number\n",
    "\n",
    "data_frame['processed_x_utm'] = 'N/A'\n",
    "data_frame['processed_y_utm'] = 'N/A'\n",
    "\n",
    "# Si la longitud de alguno de los números es menor a diez, hay que añadirle x 0s\n",
    "# de diferencia\n",
    "selected_rows_x2.processed_x_utm = selected_rows_x2.processed_x_utm.transform(lambda x: x + '0'*(10-len(x)))\n",
    "selected_rows_x3.processed_x_utm = selected_rows_x3.processed_x_utm.transform(lambda x: x + '.000')\n",
    "\n",
    "selected_rows_y2.processed_y_utm = selected_rows_y2.processed_y_utm.transform(lambda x: x + '0'*(11-len(x)))\n",
    "selected_rows_y3.processed_y_utm = selected_rows_y3.processed_y_utm.transform(lambda x: x + '.000')\n",
    "\n",
    "data_frame['processed_x_utm'][selected_rows_x1.index] = selected_rows_x1['processed_x_utm']\n",
    "data_frame['processed_x_utm'][selected_rows_x2.index] = selected_rows_x2['processed_x_utm']\n",
    "data_frame['processed_x_utm'][selected_rows_x3.index] = selected_rows_x3['processed_x_utm']\n",
    "\n",
    "data_frame['processed_y_utm'][selected_rows_y1.index] = selected_rows_y1['processed_y_utm']\n",
    "data_frame['processed_y_utm'][selected_rows_y2.index] = selected_rows_y2['processed_y_utm']\n",
    "data_frame['processed_y_utm'][selected_rows_y3.index] = selected_rows_y3['processed_y_utm']\n",
    "\n",
    "# Eliminamos aquellas filas que no tienen coordenadas\n",
    "data_frame = data_frame[data_frame['coordenada_y_utm'] != '0.000']\n",
    "\n",
    "# Eliminamos el punto de la parte decimal para convertirlo a entero\n",
    "data_frame.processed_x_utm = data_frame.processed_x_utm.str.replace('.','')\n",
    "data_frame.processed_y_utm = data_frame.processed_y_utm.str.replace('.','')\n",
    "\n",
    "# Lo convertimos en entero\n",
    "data_frame.processed_x_utm = data_frame.processed_x_utm.astype(int)\n",
    "data_frame.processed_y_utm = data_frame.processed_y_utm.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_Z4nz3ioxtXb",
   "metadata": {
    "id": "_Z4nz3ioxtXb",
    "tags": []
   },
   "source": [
    "### Renombrado y eliminación de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "tqnlSOcN71Ah",
   "metadata": {
    "id": "tqnlSOcN71Ah"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9521/2844866448.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame.rename(columns={\"localizacion\": \"tipo_carretera\"}, errors=\"raise\", inplace=True)\n",
      "/tmp/ipykernel_9521/2844866448.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame.rename(columns={\"processed_x_utm\": \"coordenada_x_utm\"}, errors=\"raise\", inplace=True)\n",
      "/tmp/ipykernel_9521/2844866448.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame.rename(columns={\"processed_y_utm\": \"coordenada_y_utm\"}, errors=\"raise\", inplace=True)\n",
      "/tmp/ipykernel_9521/2844866448.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame.rename(columns={\"positiva_alcohol\": \"drogas_alcohol_positivo\"}, errors=\"raise\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# COLUMNS_TO_REMOVE = ['num_expediente', 'fecha', 'tipo_via', 'numero', 'positiva_droga', 'coordenada_x_utm', 'coordenada_y_utm', 'positiva_droga']\n",
    "# SIN LOCALIZACION COLUMNS_TO_REMOVE = ['num_expediente', 'fecha', 'tipo_via', 'localizacion', 'numero', 'positiva_droga', 'coordenada_x_utm', 'coordenada_y_utm', 'positiva_droga']\n",
    "COLUMNS_TO_REMOVE = ['num_expediente', 'fecha', 'tipo_via', 'numero', 'positiva_droga', 'coordenada_x_utm', 'coordenada_y_utm']\n",
    "\n",
    "data_frame = data_frame.loc[:, ~data_frame.columns.isin(COLUMNS_TO_REMOVE)]\n",
    "\n",
    "data_frame.rename(columns={\"localizacion\": \"tipo_carretera\"}, errors=\"raise\", inplace=True)\n",
    "data_frame.rename(columns={\"processed_x_utm\": \"coordenada_x_utm\"}, errors=\"raise\", inplace=True)\n",
    "data_frame.rename(columns={\"processed_y_utm\": \"coordenada_y_utm\"}, errors=\"raise\", inplace=True)\n",
    "data_frame.rename(columns={\"positiva_alcohol\": \"drogas_alcohol_positivo\"}, errors=\"raise\", inplace=True)\n",
    "\n",
    "data_frame = data_frame.drop_duplicates()\n",
    "data_frame = data_frame.dropna()\n",
    "data_frame = data_frame.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5ae87450-809a-4958-b9cb-422a3e91effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data_frame = data_frame.loc[:, ~data_frame.columns.isin(['lesividad'])]\n",
    "# Y_data_frame = data_frame['lesividad']\n",
    "\n",
    "# X_data_frame  = X_data_frame.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8c589-4e2b-4340-8dd5-44c665a642e0",
   "metadata": {},
   "source": [
    "## Eliminar regiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2510c89-0dac-44f9-8e15-ad1b6c61034f",
   "metadata": {},
   "source": [
    "Se proyectarán los accidentes en dos dimensiones en función de sus coordenadas. Esta proyección se dividirá en n sub-áreas iguales en función de las coordenadas que estas presenten.\n",
    "Se eliminarán todos aquellos accidentes leves que no estén contenidos en algún sub-área en la que se encuentre algún accidente leve o serio, de tal forma que se reducirá considerablemente el número de accidentes leves, evitando así el sobreajuste de la red sobre esta clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "507cd993-ab79-408f-b49c-bdfba9da1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slight = data_frame[data_frame.lesividad == 'Slight'][:1000]\n",
    "# serious = data_frame[data_frame.lesividad == 'Serious'][:100]\n",
    "# fatal = data_frame[data_frame.lesividad == 'Fatal']\n",
    "\n",
    "# import matplotlib\n",
    "\n",
    "# matplotlib.rc('figure', figsize=(30, 15))\n",
    "\n",
    "# x = fatal.coordenada_x_utm\n",
    "# y = fatal.coordenada_y_utm\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# colour = np.arctan2(x, y)\n",
    "\n",
    "\n",
    "# plt.scatter(slight.coordenada_x_utm, slight.coordenada_y_utm, s = 50, alpha = 1)\n",
    "# plt.scatter(serious.coordenada_x_utm, serious.coordenada_y_utm, s = 50, alpha = 1)\n",
    "# plt.scatter(x, y, s = 50, alpha = 1)\n",
    "\n",
    "\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7eabeed7-dc54-4780-b812-0f2dc98f2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_x = data_frame.coordenada_x_utm.min()\n",
    "# max_x = data_frame.coordenada_x_utm.max()\n",
    "\n",
    "# min_y = data_frame.coordenada_y_utm.min()\n",
    "# max_y = data_frame.coordenada_y_utm.max()\n",
    "\n",
    "# interval_x = (max_x - min_x)\n",
    "# interval_y = (max_y - min_y)\n",
    "# interval_x, interval_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "08ef2a42-ad28-4b28-b013-af9165830eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Se ejecuta 2 veces\n",
    "\n",
    "# data_frame = data_frame[data_frame.coordenada_x_utm != min_x]\n",
    "# min_x = data_frame.coordenada_x_utm.min()\n",
    "\n",
    "# data_frame = data_frame[data_frame.coordenada_x_utm != min_x]\n",
    "# min_x = data_frame.coordenada_x_utm.min()\n",
    "\n",
    "# max_x = data_frame.coordenada_x_utm.max()\n",
    "\n",
    "# min_y = data_frame.coordenada_y_utm.min()\n",
    "# max_y = data_frame.coordenada_y_utm.max()\n",
    "\n",
    "# interval_x = (max_x - min_x)\n",
    "# interval_y = (max_y - min_y)\n",
    "# interval_x, interval_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8c1b387d-a92a-459c-a0a5-97b2c7aca797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_divisible_numbers(number):\n",
    "#     for i in range (1, number):\n",
    "#         zero = number%i\n",
    "#         if zero == 0: print(f\"Divisible by: {i}, regions: {number/i}\")\n",
    "\n",
    "# # Number: 1831.0, divisible number: 14311\n",
    "# # get_divisible_numbers(interval_x)\n",
    "# # Number of regions: 1810.0, divisible number: 17335\n",
    "# # get_divisible_numbers(interval_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cb6e14d2-ee1d-44d0-bfdb-ca3b9a8207fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_x = min_x\n",
    "# initial_y = max_y\n",
    "\n",
    "# x_offset = 14311\n",
    "# y_offset = 17335\n",
    "\n",
    "# X_vertices = [x_vertice for x_vertice in range(min_x, max_x, x_offset)]\n",
    "# Y_vertices = [y_vertice for y_vertice in range(min_y, max_y, y_offset)]\n",
    "\n",
    "# # for box in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1607b650-8adc-44d8-8672-d0e902879980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_rows_by_removing_areas():\n",
    "\n",
    "    new_dataframe = pd.DataFrame()\n",
    "\n",
    "    serious_and_fatal_dataframe = data_frame[data_frame.lesividad.isin(['Fatal', 'Serious'])]\n",
    "\n",
    "    for y_vertice in tqdm(Y_vertices):\n",
    "        box_y_min = y_vertice\n",
    "        box_y_max = y_vertice + y_offset\n",
    "\n",
    "        serious_and_fatal_on_this_height = serious_and_fatal_dataframe[serious_and_fatal_dataframe.coordenada_y_utm.between(box_y_min, box_y_max)]\n",
    "\n",
    "        all_entries = data_frame[data_frame.coordenada_y_utm.between(box_y_min, box_y_max)]\n",
    "\n",
    "        if serious_and_fatal_on_this_height.empty: continue\n",
    "\n",
    "        for x_vertice in X_vertices:\n",
    "            box_x_min = x_vertice\n",
    "            box_x_max = x_vertice + x_offset\n",
    "\n",
    "            serious_and_fatal_on_this_box = serious_and_fatal_on_this_height[serious_and_fatal_on_this_height.coordenada_x_utm.between(box_x_min, box_x_max)]\n",
    "\n",
    "            if serious_and_fatal_on_this_box.empty: continue\n",
    "\n",
    "            all_entries = all_entries[all_entries.coordenada_x_utm.between(box_x_min, box_x_max)]\n",
    "\n",
    "            new_dataframe = pd.concat([new_dataframe, all_entries])\n",
    "            # print(len(new_dataframe))\n",
    "\n",
    "    return new_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7f22fddf-171c-45a1-81ab-ad91d3c3a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('Data/Madrid/filtered_areas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "de3882ab-b368-4e71-9a4e-1365add2dbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='lesividad', ylabel='Count'>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.histplot(data=data_frame.lesividad,stat='count')\n",
    "# plt.savefig('histograms_images/original.svg')\n",
    "# one_hot_to_casualty(Y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "755814a8-cd7a-4dee-a7e3-8c15b3932b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = {'Serious': 'Assistance',\n",
    "          'Fatal': 'Assistance'}\n",
    "\n",
    "data_frame.replace(transf, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qKuGQ1I8078E",
   "metadata": {
    "id": "qKuGQ1I8078E",
    "tags": []
   },
   "source": [
    "## Split de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce67dd-a875-441f-9ba1-4f276cd34ea5",
   "metadata": {},
   "source": [
    "Histograma de desbalanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "NCcJF3i8s3dD",
   "metadata": {
    "id": "NCcJF3i8s3dD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train, test = train_test_split(data_frame, test_size=0.2, random_state = 2)\n",
    "X_train = X_train_original = train.loc[:, ~train.columns.isin(['lesividad'])]\n",
    "\n",
    "X_train = X_train.astype(int)\n",
    "X_train_original = X_train_original.astype(int)\n",
    "\n",
    "Y_train = Y_train_original = train['lesividad']\n",
    "\n",
    "X_test = test.loc[:, ~test.columns.isin(['lesividad'])]\n",
    "X_test = X_test.astype(int)\n",
    "Y_test = test['lesividad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "833572d7-b380-4b6e-ae9b-ed5b13c0cc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Slight        1310\n",
       "Assistance     538\n",
       "Name: lesividad, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.histplot(data=one_hot_to_casualty(Y_train),stat='count')\n",
    "plt.savefig('histograms_images/original.svg')\n",
    "one_hot_to_casualty(Y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e78a6-c3ca-4b61-b641-8e88dcf62931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "x2PcFjlBmTlC",
   "metadata": {
    "id": "x2PcFjlBmTlC"
   },
   "outputs": [],
   "source": [
    "# # FILE_NAME = f\"{city_name}_calculated_weights.json\"\n",
    "# FILE_NAME = 'madrid_adapted_leeds_default_weights.json'\n",
    "\n",
    "# feature_vector = load_json(WEIGHTS_PATH, FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bde99d2d-727a-4e30-90b3-67dc859075bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# feature_vector = {}\n",
    "\n",
    "# feature_vector['Accident Features'] = {\n",
    "#     'feature_childs': ['coordenada_x_utm', 'coordenada_y_utm', 'distrito', 'hora', 'vehiculos_implicados'],\n",
    "#     'feature_weights': [0.165774538, 0.171530785, 0.082228259, 0.047771472, 0.060763375]\n",
    "# } \n",
    "\n",
    "# feature_vector['Roadway Features'] = {\n",
    "#     'feature_childs': ['tipo_accidente'], # Road Surface \n",
    "#     'feature_weights': [0.07036541]\n",
    "# }\n",
    "\n",
    "# feature_vector['Environmental Features'] = {\n",
    "#     'feature_childs': ['estado_meteorológico'],\n",
    "#     'feature_weights': [0.04354843]\n",
    "# }\n",
    "\n",
    "# feature_vector['Vehicle Features'] = {\n",
    "#     'feature_childs': ['tipo_vehiculo'],\n",
    "#     'feature_weights': [0.126314657]\n",
    "# }\n",
    "\n",
    "# feature_vector['Casualty Features'] = {\n",
    "#     'feature_childs': ['tipo_persona', 'sexo', 'rango_edad', 'drogas_alcohol_positivo'],\n",
    "#     'feature_weights': [0.067057589, 0.049116389, 0.095220163, 0.059951354]\n",
    "# } \n",
    "# matrix_indexes = fv2gi(feature_vector)\n",
    "\n",
    "# # {'Accident Features': {'feature_childs': ['Easting',\n",
    "# #    'Northing',\n",
    "# #    '1st Road Class',\n",
    "# #    'Accident Time',\n",
    "# #    'Number of Vehicles'],\n",
    "# #   'feature_weights': [0.165774538,\n",
    "# #    0.171530785,\n",
    "# #    0.082228259,\n",
    "# #    0.047771472,\n",
    "# #    0.060763375],\n",
    "# #   'wpi': 0.528068429},\n",
    "# #  'Roadway Features': {'feature_childs': ['Road Surface'],\n",
    "# #   'feature_weights': [0.048847406],\n",
    "# #   'wpi': 0.048847406},\n",
    "# #  'Environmental Features': {'feature_childs': ['Lighting Conditions',\n",
    "# #    'Weather Conditions'],\n",
    "# #   'feature_weights': [0.041826936, 0.04354843],\n",
    "# #   'wpi': 0.08537536600000001},\n",
    "# #  'Vehicle Features': {'feature_childs': ['Type of Vehicle'],\n",
    "# #   'feature_weights': [0.126314657],\n",
    "# #   'wpi': 0.126314657},\n",
    "# #  'Casualty Features': {'feature_childs': ['Casualty Class',\n",
    "# #    'Sex of Casualty',\n",
    "# #    'Age of Casualty'],\n",
    "# #   'feature_weights': [0.067057589, 0.049116389, 0.095220163],\n",
    "# #   'wpi': 0.211394141}}\n",
    "# feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5W4MXdIis6vn",
   "metadata": {
    "id": "5W4MXdIis6vn",
    "tags": []
   },
   "source": [
    "## Normalización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "tHUfNlw8sdxS",
   "metadata": {
    "id": "tHUfNlw8sdxS"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype(int)\n",
    "X_test  = X_test.astype(int)\n",
    "\n",
    "X_train_original = X_train_original.astype(int)\n",
    "\n",
    "X_train = normalize_data(X_train)\n",
    "X_train_original = normalize_data(X_train_original)\n",
    "X_test  = normalize_data(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kr_UChBJ21Cu",
   "metadata": {
    "id": "kr_UChBJ21Cu",
    "tags": []
   },
   "source": [
    "## Oversampling de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7ec60-725f-45c0-bedb-cd26f543ac9f",
   "metadata": {},
   "source": [
    "### SMOTE-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "rXwHLi842zLs",
   "metadata": {
    "id": "rXwHLi842zLs"
   },
   "outputs": [],
   "source": [
    "# print('********** Before OverSampling **********')\n",
    "# print('Slight: ', (Y_train == 'Slight').sum())\n",
    "# print('Serious:', (Y_train == 'Serious').sum())\n",
    "# print('Fatal:  ', (Y_train == 'Fatal').sum())\n",
    "# print('\\n Total X:', len(X_train), ' Total Y:', len(Y_train), '\\n')\n",
    "\n",
    "# X_train, Y_train = oversample_data(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bfb8d95-7e6a-4f25-aa33-ee9aa6e82530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Slight        1310\n",
       "Assistance    1309\n",
       "Name: lesividad, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.histplot(data=one_hot_to_casualty(Y_train),stat='count')\n",
    "plt.savefig('histograms_images/smote-ii.svg')\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06540ce8-f30e-45fb-b44f-55e1632951d2",
   "metadata": {},
   "source": [
    "## Downsampling de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f52a26-b2a4-4f5e-a31f-bffaefb8c73d",
   "metadata": {},
   "source": [
    "### Two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cdcf96a1-04f5-4c28-89ff-a69bb6ecc792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "slight_data  = test[test['lesividad'] == 'Slight']\n",
    "serious_data = test[test['lesividad'] == 'Assistance']\n",
    "# fatal_data   = test[test['lesividad'] == 'Fatal']\n",
    "\n",
    "X_slight_downsampled = resample(slight_data,\n",
    "                                replace = True,\n",
    "                                n_samples = len(serious_data))\n",
    "\n",
    "# X_serious_downsampled = resample(serious_data,\n",
    "#                                  replace = True,\n",
    "#                                  n_samples = len(fatal_data))\n",
    "\n",
    "\n",
    "downsampled_dataset = pd.concat([X_slight_downsampled, serious_data])\n",
    "\n",
    "downsampled_train, downsampled_test = train_test_split(downsampled_dataset, test_size=0.2)\n",
    "\n",
    "X_train_downsampled = downsampled_train.loc[:, ~downsampled_train.columns.isin(['lesividad'])]\n",
    "Y_train_downsampled = downsampled_train['lesividad']\n",
    "\n",
    "X_test_downsampled = downsampled_test.loc[:, ~downsampled_test.columns.isin(['lesividad'])]\n",
    "Y_test_downsampled = downsampled_test['lesividad']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f5158-bbc7-4205-88ac-d3b0921130b9",
   "metadata": {},
   "source": [
    "### Three Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62a11f0e-a930-4fe5-9c60-a12973ac9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.utils import resample\n",
    "\n",
    "# slight_data  = test[test['lesividad'] == 'Slight']\n",
    "# serious_data = test[test['lesividad'] == 'Serious']\n",
    "# fatal_data   = test[test['lesividad'] == 'Fatal']\n",
    "\n",
    "# X_slight_downsampled = resample(slight_data,\n",
    "#                                 replace = True,\n",
    "#                                 n_samples = len(fatal_data))\n",
    "\n",
    "# X_serious_downsampled = resample(serious_data,\n",
    "#                                  replace = True,\n",
    "#                                  n_samples = len(fatal_data))\n",
    "\n",
    "\n",
    "# downsampled_dataset = pd.concat([X_slight_downsampled, X_serious_downsampled, fatal_data])\n",
    "\n",
    "# downsampled_train, downsampled_test = train_test_split(downsampled_dataset, test_size=0.2)\n",
    "\n",
    "# X_train_downsampled = downsampled_train.loc[:, ~downsampled_train.columns.isin(['lesividad'])]\n",
    "# Y_train_downsampled = downsampled_train['lesividad']\n",
    "\n",
    "# X_test_downsampled = downsampled_test.loc[:, ~downsampled_test.columns.isin(['lesividad'])]\n",
    "# Y_test_downsampled = downsampled_test['lesividad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbcdf9bd-bcdf-4407-a199-87674d07267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 10))\n",
    "\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "# sns.histplot(data=one_hot_to_casualty(Y_test_downsampled),stat='count')\n",
    "# plt.savefig('histograms_images/downsampled-test.svg')\n",
    "# Y_test_downsampled.value_counts()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "# sns.histplot(data=one_hot_to_casualty(Y_train_downsampled),stat='count')\n",
    "# plt.savefig('histograms_images/downsampled-train.svg')\n",
    "# Y_train_downsampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ec4e4df-7c2d-48fb-b867-0a7066a57076",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(int)\n",
    "X_test  = X_test.astype(int)\n",
    "\n",
    "X_train_original = X_train_original.astype(int)\n",
    "\n",
    "X_train_downsampled = X_train_downsampled.astype(int)\n",
    "X_test_downsampled  = X_test_downsampled.astype(int)\n",
    "\n",
    "X_train = normalize_data(X_train)\n",
    "X_test  = normalize_data(X_test)\n",
    "X_train_downsampled = normalize_data(X_train_downsampled)\n",
    "X_test_downsampled  = normalize_data(X_test_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c32ac202-7211-4fd1-837a-6c41752ebefd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5eb99c-7ac9-425b-af2e-735ae2155e03",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d525349f-2832-457b-833f-e4f2d549ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ccda69-9c08-4e7c-b1fb-20ce276379ae",
   "metadata": {},
   "source": [
    "### Genético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b3e8a6fb-aef6-4186-aae1-89981e83bd3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if calculate_weights:\n",
    "    Y_train_downsampled_copy = Y_train_downsampled.copy()\n",
    "    Y_test_downsampled_copy  = Y_test_downsampled.copy()\n",
    "    Y_test_copy = Y_test.copy()\n",
    "    Y_val_copy  = Y_val.copy()\n",
    "    Y_train_copy = Y_train.copy()\n",
    "\n",
    "    Y_train_downsampled_onehot = casualty_to_one_hot(Y_train_downsampled_copy)\n",
    "    Y_test_downsampled_onehot  = casualty_to_one_hot(Y_test_downsampled_copy)\n",
    "    Y_val_onehot  = casualty_to_one_hot(Y_val_copy)\n",
    "    Y_test_onehot  = casualty_to_one_hot(Y_test_copy)\n",
    "    Y_train_onehot  = casualty_to_one_hot(Y_train_copy)\n",
    "\n",
    "    populationSize = (number_of_individuals, number_of_hyperparams)\n",
    "    population = initialize_population(number_of_individuals   = number_of_individuals,\n",
    "                                       hyperparams_to_optimize = HYPERPARAMS_TO_OPTIMIZE)\n",
    "\n",
    "    fitnessHistory = np.empty([number_of_generations+1, number_of_individuals]) # Define an array to store the value of each parameter for each parent and generation\n",
    "    populationHistory = np.empty([(number_of_generations+1)*number_of_individuals, number_of_hyperparams]) # Insert the value of initial parameters in history\n",
    "\n",
    "    best_solution_history = np.empty([(number_of_generations), number_of_hyperparams+1])\n",
    "    populationHistory[0:number_of_individuals,:] = population\n",
    "\n",
    "    dtrain = xgb.DMatrix(data  = X_train,\n",
    "                         label = Y_train_copy)\n",
    "\n",
    "    dtest  = xgb.DMatrix(data  = X_test, \n",
    "                         label = Y_test_copy)\n",
    "\n",
    "    for generation in range(number_of_generations):\n",
    "\n",
    "        print(\"This is number %s generation\" % (generation))\n",
    "\n",
    "        new_population = []\n",
    "\n",
    "        unique_individuals = np.unique(population, axis=0)\n",
    "\n",
    "        new_individuals_to_create = number_of_individuals - len(unique_individuals)\n",
    "\n",
    "        for i in range(new_individuals_to_create):\n",
    "            new_individual = generate_individual(hyperparams_to_optimize = HYPERPARAMS_TO_OPTIMIZE)\n",
    "            new_population.append(new_individual)\n",
    "\n",
    "        new_population = np.array(new_population)\n",
    "\n",
    "        if (new_individuals_to_create):\n",
    "            population = np.concatenate((unique_individuals, new_population), axis=0)\n",
    "\n",
    "        # print(f'Current population is {population}')\n",
    "        print(f'New population is {len(new_population)}')\n",
    "\n",
    "        # Train the dataset and obtain fitness\n",
    "        fitnessValue = train_population(population = population,\n",
    "                                        hyperparams_to_optimize = HYPERPARAMS_TO_OPTIMIZE,\n",
    "                                        dMatrixTrain = dtrain,\n",
    "                                        dMatrixTest = dtest,\n",
    "                                        Y_test = Y_test_copy)\n",
    "\n",
    "        fitnessHistory[generation,:] = fitnessValue\n",
    "\n",
    "        # Best score in the current iteration\n",
    "        max_score_index = np.argmax(fitnessHistory[generation,:])\n",
    "        max_score_value = np.max(fitnessHistory[generation,:])\n",
    "        max_score_solution = population[max_score_index]\n",
    "\n",
    "        max_solution_with_score = []\n",
    "        max_solution_with_score = np.append(max_score_solution, max_score_value)\n",
    "        best_solution_history[generation] = max_solution_with_score\n",
    "\n",
    "        print(f\"Best F1 score in the this iteration = {max_score_value}, best solution {max_score_solution}\") # Survival of the fittest - take the top parents, based on the fitness value and number of parents needed to be selected\n",
    "\n",
    "        parents = new_parents_selection(population = population,\n",
    "                                        fitness = fitnessValue,\n",
    "                                        numParents = numberOfParentsMating)\n",
    "\n",
    "        # Mate these parents to create children having parameters from these parents (we are using uniform crossover)\n",
    "        children = crossover_uniform(parents = parents,\n",
    "                                     childrenSize = (populationSize[0] - parents.shape[0], number_of_hyperparams))\n",
    "\n",
    "        # Add mutation to create genetic diversity\n",
    "        children_mutated = mutation(children,\n",
    "                                    hyperparams_to_optimize = HYPERPARAMS_TO_OPTIMIZE)\n",
    "\n",
    "        '''\n",
    "        We will create new population, which will contain parents that where selected previously based on the\n",
    "        fitness score and rest of them  will be children\n",
    "        '''\n",
    "        population[0:parents.shape[0], :] = parents # Fittest parents\n",
    "        population[parents.shape[0]:, :]  = children_mutated # Children\n",
    "\n",
    "        populationHistory[(generation+1)*number_of_individuals : (generation+1)*number_of_individuals + number_of_individuals , :] = population # Store parent information\n",
    "\n",
    "    #Best solution from the final iteration\n",
    "\n",
    "    fitness = train_population(population = population,\n",
    "                               hyperparams_to_optimize = HYPERPARAMS_TO_OPTIMIZE,\n",
    "                               dMatrixTrain = dtrain,\n",
    "                               dMatrixTest = dtest,\n",
    "                               Y_test = Y_test_copy)\n",
    "\n",
    "    fitnessHistory[generation+1, :] = fitness # index of the best solution\n",
    "    bestFitnessIndex = np.where(fitness == np.max(fitness))[0][0]\n",
    "\n",
    "\n",
    "    best_hyperparams = {}\n",
    "    for n_param, hyperparam in enumerate(HYPERPARAMS_TO_OPTIMIZE):\n",
    "        best_hyperparams[hyperparam] = population[bestFitnessIndex][n_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a9cff61d-c0c4-43d1-8aba-f0128c249852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if calculate_weights and madrid:\n",
    "    #### PLOT FITNESS EVOLUTION ####\n",
    "    x_fitness = [np.max(fitnessHistory[i]) for i in range(0,fitnessHistory.shape[0])]\n",
    "\n",
    "    FILE_NAME = f\"{city_name}_ga_{MODEL_TIMESTAMP}.svg\"\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.plot(np.arange(len(x_fitness)), x_fitness)\n",
    "    plt.savefig(GA_SCORES_PATH + FILE_NAME)\n",
    "\n",
    "    #### PLOT HYPERPARAMS EVOLUTION ####\n",
    "    FILE_NAME = f\"{city_name}_ga_hyperparams_evolution_p{number_of_individuals}_c{numberOfParentsMating}_{MODEL_TIMESTAMP}.svg\"\n",
    "\n",
    "    LEGEND_LABELS = HYPERPARAMS_TO_OPTIMIZE.keys()\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    best_solution_history_aux = best_solution_history\n",
    "    best_solution_history_aux[:,1] = best_solution_history[:,1]/2\n",
    "    best_solution_history_aux[:,3] = best_solution_history[:,3]/100\n",
    "    plt.plot(best_solution_history_aux[:,:3])\n",
    "    plt.ylabel('Factor')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.legend(LEGEND_LABELS)\n",
    "    plt.savefig(HYPERPARAMS_EVOLUTON_PATH + FILE_NAME, dpi=300)\n",
    "\n",
    "    FILE_NAME = f\"{city_name}_population_p{number_of_individuals}_c{numberOfParentsMating}_{MODEL_TIMESTAMP}.txt\"\n",
    "\n",
    "    np.savetxt(FINAL_POPULATION_PATH + FILE_NAME, population, fmt='%s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7adde09b-86d0-4525-ad0f-55a841e5a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # best_solution_history_2 = best_solution_history.copy()\n",
    "# # best_solution_history_2 =  np.append([[0, 0, 0]] ,best_solution_history)\n",
    "\n",
    "FILE_NAME = \"save2.json\"\n",
    "\n",
    "# # np.savetxt(FILE_NAME, best_solution_history, fmt='%s')\n",
    "vector = load_json('./', FILE_NAME)\n",
    "with open(FILE_NAME) as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3ac216f1-f86f-4d4d-8117-2814e3643637",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array_to_append = [ [0.02, 4.0, 1.6099999999999999, 0.007437]]*30\n",
    "np_array_to_append = np.asarray(np_array_to_append)\n",
    "# data = np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "30fd2eb8-0250-4e02-90e2-1cdac060714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([data, np_array_to_append])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b5f16908-603e-4d1a-9955-acba7da05813",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = []\n",
    "for one_list in data:\n",
    "    new_array.append(np.asarray(one_list))\n",
    "\n",
    "new_array = np.asarray(new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebd3f25-ebc7-470b-9d40-77c0cb6a2c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6bfa1101-5ea0-44d2-97e6-9d545a784030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,4):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "401e608b-fffc-464c-ad41-8947dcf3c1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAHpCAYAAADXpYLRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABgeklEQVR4nO3deXhU9d3//9ds2XcgEAQBqSiIirJp3VGLWlCqVqu3drPau2pdqnWvVKT2xuWL1l273Xdr9Vfrvi8Fd0FEikZRFFCJQEKArGQmc+ac3x+TGfZkljMzJyfPx3X1uprJ5MwnOSTmlff783l7LMuyBAAAAADoM7y5XgAAAAAAILsIggAAAADQxxAEAQAAAKCPIQgCAAAAQB9DEAQAAACAPoYgCAAAAAB9TFaC4Jw5czRlyhTttddeWr58uSRp06ZNOvfcczV16lRNnz5dF154oTZu3JiN5QAAAABAn5aVIHj00UfroYce0m677RZ/zOPx6Gc/+5leeuklPfPMMxo6dKhuvfXWbCwHAAAAAPo0fzZeZMKECTs8VlFRocmTJ8ffHjdunB5++OGkrmuaptrb2xUIBOTxeNJeJwAAAAD0JpZlKRwOq7i4WF5v4nW+rATBnpimqYcfflhTpkxJ6uPa29vjraYAAAAA0FeNGjVKpaWlCT/fEUHwxhtvVFFRkc4666ykPi4QCEiKftJ5eXmZWBrSVFtbq7Fjx+Z6GegG98j5uEfOxv1xPu6Rs3F/nI975GydnZ1avnx5PBslKudBcM6cOfrqq6903333JVXKlBRvB83Ly1N+fn4mlgcbcG+cj3vkfNwjZ+P+OB/3yNm4P87HPXK+ZLfK5TQIzp07V7W1tXrggQeo6AEAAABAlmQlCM6ePVsvv/yyGhsb9ZOf/EQVFRW6/fbbdd9992n48OH6wQ9+IEkaMmSI7r777mwsCQAAAAD6rKwEweuuu07XXXfdDo9/9tln2Xh5AAAAAMBWcr5HEAAAAMAW4XBYdXV1CgaDuV6KJMnv92vZsmW5XkafV1BQoCFDhiR9KMyuEAQBwKGaOpp10fMzddqg43K9FABAFtXV1am0tFTDhw93xKzs9vZ2FRcX53oZfZplWdqwYYPq6uo0YsQIW66Z3DGdAICs2djRpKAR0qZwS66XAgDIomAwqH79+jkiBMIZPB6P+vXrZ2uVmCAIAA5lmBFJUsSK5HglAIBsIwRie3b/myAIAoBDhU1DEkEQAADYjyAIAA5ldAVBgyAIAHCglpYWPfjgg7leBlJEEAQAh9rSGmrmeCUAAOyopaVFf/zjH3O9DKSIU0MBwKEMWkMBoM+b9/7XeuW9rzNy7WMn7a4pE3ZP6LlLly7Vrbfeqvb2dknSRRddpH/84x9qbW3VSSedpMLCQj3yyCP685//rOeee06RSET5+fn67W9/q9GjR2dk/UgPQRAAHCocoTUUAJB7ra2tmjlzph544AFVV1eroaFBp556qu6//34tXbpUTz31VPy5M2bM0E9/+lNJ0jvvvKOZM2fqn//8Z66Wjm4QBAHAoagIAgCmTEi8apcpS5cuVV1dnc4999z4Yx6PR4Zh7PDc2tpa3X///WpubpbH49GXX36ZxZUiGQRBAHAo9ggCAJzAsizttddeeuihh7Z5vK6ubpu3Ozs7dfHFF+vvf/+79tlnH9XX1+vwww/P5lKRBA6LAQCHoiIIAHCC/fffX1999ZUWLFgQf+zDDz9UcXGxgsFgvDLY2dkpwzBUU1MjSfrHP/6Rk/UiMVQEAcChGB8BAHCCsrIy3XPPPbrlllt00003KRwOa+jQobrvvvs0ffp0TZ8+XeXl5XrkkUd00UUX6dRTT1VNTQ3VQIcjCAKAQ9EaCgBwiv32209/+9vfdnh89uzZ27x97rnnbrOX8Oc//3nG14bU0BoKAA5FaygAAMgUgiAAOBRBEAAAZApBEAAcijmCAAAgUwiCAOBQsT2CJnsEAQCAzQiCAOBQnBoKAAAyhSAIAA4Vju8RpCIIAADsRRAEAIfaMj6CiiAAALAXQRAAHIpTQwEAQKYQBAHAoWIVQfYIAgD6ujvvvFNz5sxJ6xqvvvqqPvzww/jbCxcu1Mknn5zu0notf64XAADYOSMSlsQeQQDoy1o/fE2tS+dl5Nql+09R6X5HZuTaTvTqq69q7Nix2m+//XK9FEcgCAKAQ7FHEADgBAceeKAuueQSvfrqq2pqatLs2bP1zjvv6M0335RhGLrjjjs0cuRIrV+/Xr/61a/U3t6uUCikI444QldccYUk6ZprrlFpaamuvvpqNTY26rTTTtPdd9+t0aNH7/Q1W1tbde211+qLL75QTU2Nqqqq1L9/f0lSZ2en5s6dq0WLFikcDmvUqFH67W9/q+LiYl111VXy+/2qq6vT2rVrNXHiRF1//fVauHCh5s2bp3feeUePPvqofvKTn6impkaRSETXX3+9lixZIo/Ho7lz52rkyJFZ+9rmEkEQAByKPYIAgNL9jnRE1a6srEyPPfaYXnjhBZ1//vmaO3euLrvsMj344IO69957deutt6qsrEz33XefiouLFQ6Hdc455+iNN97Q4Ycfruuvv17f//739eqrr+qhhx7SOeecs8sQKEl33323iouL9fzzz2vjxo06+eSTdfzxx0uS/vjHP6q0tFT/+te/JEm33HKLHnjgAV166aWSpKVLl+qRRx5Rfn6+zjvvPP3zn//UWWedpSlTpmjs2LE666yzJEVbQ7/44gv9/ve/16xZs3Tvvffqnnvu0W233Zbhr6YzEAQBwKHiFUGZsixLHo8nxysCAPRVsRC2zz77SJKOPPJISdLYsWP1yiuvSJIikYhuvvlmLVmyRJZlqbGxUZ9++qkOP/xwFRQU6Pbbb9epp56qQw89VP/1X//V7estXLhQ1113nSSpqqpKxx57bPx98+bNU1tbm1566SVJ0Qrh3nvvHX//CSecoOLiYknSjBkz9PLLL8fD3/ZGjBihMWPGSJLGjRun+fPnJ/V16c0IggDgULE5glK0OhjwBXK4GgBAX5afny9J8nq9ysvLiz/u9XplGNH/Xv3lL39RS0uLHn30UeXn5+s3v/mNQqFQ/LkrVqxQcXGx1q9fL8Mw5PfvOopYltXt+2bOnKmDDz64x3X39IfUXX0ufQGnhgKAQxlbBcGtQyEAAE7U2tqqAQMGKD8/X/X19fr3v/8df9/q1at100036e9//7uGDRum22+/vdtrHXzwwXr88cclSZs2bdKrr74af9+UKVP017/+VcFgUJLU1tamFStWxN//4osvavPmzTIMQ08//bQmT54sSSopKVFra6tdn26vRxAEAIeKtYZKkhEhCAIAnO3ss8/WBx98oBkzZmxTsevs7NSll16qyy67TMOHD9fMmTM1b948vf7667u81vnnn6+WlhadcMIJuuKKK3TIIYfE33feeedp77331qmnnqrp06frzDPP3CYITpw4URdccIG++93vqqamRqeddpok6cQTT9Szzz6rk046SU8++WRmvgi9iMfqru7qcKFQSLW1tRo7dmy8XA1nWbx4scaPH5/rZaAb3CPn+sXT12hDxyZJ0r3Tb1K/osocrwg7w/eQ83GPnI37s6Nly5Z1e5BKtrW3t8f33DndVVddtc2BMG6zs38bqWYiKoIA4FCGaSjfF927QGsoAACwE4fFAIBDGaahgkCBQpFOWkMBAK6zYcMG/fSnP93h8WOPPVYXXnhhStf8n//5n3SX1WcQBAHAoQwzotL8EjWLiiAAwH369eunp556KtfL6LNoDQUAhwqbhgoDBdH/HwnneDUAAMBNCIIA4ECmacq0TBX6o0HQoCIIAABsRBAEAAcyrOjoiIJYRZAgCAAAbEQQBAAHilUAC/3RY6DDHBYDAABsRBAEAAeKnRJaGCiMvk1FEADgcB999JEuu+wy26975513as6cOTt938MPP6y//vWvkqTHH39cF1100U6ft3DhQp188sm2r21r5557rr7++usen3f22Wdr/vz5O33f448/rlWrVtm9tJ3i1FAAcCDDjLaGUhEEgL7t9VULNH/VOxm59lEjvq0jRhxk2/X23Xdf3XbbbbZdLxFnnHFGVl+vOw8++GDa13jiiSdUWVmpESNG2LCi7lERBAAHireGskcQAJBjBx54oO69916dcsopOvroo/Xuu+/qtttu04wZMzRt2jStWLFC0rZVt7q6Ok2ePFlz587VjBkzNHXqVL3//vvdvk5ra6uuvvpqTZ8+XSeeeKJmzZoVf199fb3OPfdcHXfccTrvvPPU0dEhqftq4dy5c3XsscfqrLPO0muvvdbta69cuVLf/e53JUmGYWj8+PH64x//KEl6/vnn45XOhoYGXXTRRTr11FM1ffp03XffffFrTJkyRcuXL5ckffHFF/r+97+vadOm6fLLL9dpp522TRXwvffe0xlnnKGjjz5at956qyTpscceU21trWbPnq2TTjpJ77yTmT8AxFARBAAHigXBgq6KoGEyPgIA+qIjRhxka9UuVWVlZXrsscf0wgsv6Pzzz9fcuXN12WWX6cEHH9S9994bDzNba2pq0rhx43TppZfq6aef1q233qpHHnlkl69x0003qaioSE899ZS8Xq82btwYf19tba3+9a9/qbS0VOecc46eeeYZnXbaabu81rx58zRv3jw9+eSTKigo0AUXXNDt57fHHnuora1NDQ0N+uabb7Tnnnvq3Xff1c9+9jMtWLBABx0UvQdXXnmlzj//fE2cOFGdnZ368Y9/rH333VeHHHLINte74oor9KMf/UgnnXSSPvroox3WunbtWj300ENqb2/XMccco1NPPVWnnHKKnnzySf30pz/VUUcd1e167UBFEAAcKBw/LCY2R5CKIAAgd44//nhJ0j777CNJOvLIIyVJY8eO3eW+uKKionigGTdunFavXt3ta8yfP1/nnHOOvN5oRKmqqoq/79BDD1VZWZk8Ho/222+/HvfiLVy4UCeccIKKi4vl8/l06qmn9vg5Tp48We+++67eeecdnX766Vq3bp06Ozv1zjvv6KCDDtLmzZv13nvvxSt23//+99XQ0BCviMa0tbVp+fLlmj59uqRoy+xee+21zXOOO+44eb1elZaWauTIkQntLbQbFUEAcKD4HkFaQwEADpCfH+1Q8Xq9ysvLiz/u9XplGDv/b1Siz0vm9SXJ5/MpFAp1+3zLspJ+jYMPPlgLFixQXV2dbrnlFi1atEjPPfecJGno0KFqa2uTx+PRv/71LwUCgW5f2+PxyOPx7PI5238+kUgk6fWmi4ogADjQltZQBsoDAPqGo446Sn/605/iIW7r1tBkHXzwwXrhhRe0efNmRSIRPfbYYwl9zJtvvqnm5mYNGjRI3/72t3XnnXfG20JLSko0fvx4PfDAA/GPWbt2rdavX7/NdUpLS/Wtb31Lzz77rCTp448/ju8d7ElxcbFaW1sT/TTTQhAEAAeKtYLm+/PkkYfWUACA61199dVqb2/XtGnTdOKJJ+qee+5J+VpHHXWUjjrqKM2YMUM/+tGPNGbMmB4/ZtCgQSouLtb48eMlSQcddJDWrFkTD4KSdOutt2rFihWaPn26pk+frksvvVQtLS07XGvOnDn63//9X5188sl65JFHtPfee6u0tLTHNZx++um65557NGPGjIwfFuOxUqmbOkQoFFJtba3Gjh27TXkVzrF48eL4NxOciXvkTP9Z+4lueuNOzT761/rtvP+n40YdpR+OOyXXy8JO8D3kfNwjZ+P+7GjZsmUaPXp0rpcR197eruLi4lwvo1fZvHmzCgsL5fF49MUXX+jss8/Wiy++qPLy8rSuu7N/G6lmIvYIAoADxVpB/V6ffB5ffMA8AABwvg8++EA333xzvM31xhtvTDsE2o0gCAAOtCUI+uX3+DgsBgDgCsuWLdNVV121w+NnnXWWvv/972f89V9//XX9v//3/3Z4/Fe/+pWOOOII217n0EMP1aGHHmrb9TKBIAgADrR9RTDMHEEA6FNiJ0+6zejRo/XUU0/l7PWPOOIIWwNfNtm9o4/DYgDAgWLjI/y+gHweL62hANCH+Hw+hcP8ARDbCofD8vvtq+MRBAHAgXasCBIEAaCvqKioUH19vUzTzPVS4BCmaaq+vt7WfYa0hgKAA8Urgl17BJkjCAB9R//+/VVXV6fPPvss10uRJHV2dm4zHB65UVxcrP79+9t2PYIgADhQbG5gtCLoJQgCQB/i9Xq1++6753oZcYsXL9b++++f62XAZrSGAoADxYJfwOuPtoayRxAAANiIIAgADhQLgj72CAIAgAwgCAKAA4VNQz6PV16PN7pHkIogAACwEUEQABzIMCPye6PbuH0eLxVBAABgK4IgADiQYRry+2JBkNZQAABgL4IgADjQthVBWkMBAIC9CIIA4EBGxJDf65Mk+akIAgAAmxEEAcCBDNNQgD2CAAAgQwiCAOBAO7aGhnO8IgAA4CYEQQBwIMPc0hrq8/gUsUyZlpnjVQEAALfIShCcM2eOpkyZor322kvLly+PP75q1Sqdfvrpmjp1qk4//XR9+eWX2VgOADhe2DTiFUG/JxoIOTAGAADYJStB8Oijj9ZDDz2k3XbbbZvHZ86cqTPPPFMvvfSSzjzzTF1//fXZWA4AOJ5hGgr4tuwRlMQ+QQAAYJusBMEJEyaopqZmm8c2bNigTz75RNOmTZMkTZs2TZ988ok2btyYjSUBgKNF9whuaQ2VCIIAAMA+/ly98Nq1azVw4ED5fF2/6Ph8qq6u1tq1a1VVVZXUtWprazOxRNhk8eLFuV4CesA9cp6W1hYV+vK1ePHieBBc8p8lKguU5Hhl2Bm+h5yPe+Rs3B/n4x65T86CoJ3Gjh2r/Pz8XC8DO7F48WKNHz8+18tAN7hHzvTI+hdUVdJP48eP18evfS5J2nuf0aoprc7xyrA9voecj3vkbNwf5+MeOVsoFEqpMJazU0NrampUX1+vSCQiSYpEImpoaNihhRQA+iLDjGw1R7CrNZQREgAAwCY5C4L9+vXT6NGj9eyzz0qSnn32WY0ePTrptlAAcKPtx0fEHgMAALBDVlpDZ8+erZdfflmNjY36yU9+ooqKCj333HP67W9/q6uuukr33HOPysrKNGfOnGwsBwAcb+vxET5xWAwAALBXVoLgddddp+uuu26Hx0eOHKlHH300G0sAgF5l64qgPzY+gjmCAADAJjlrDQUA7NrO9gjSGgoAAOxCEAQABzJMQ37fdofFEAQBAIBNCIIA4EDhnRwWQ2soAACwC0EQABzGNE1ZliW/NyBpyx5BWkMBAIBdCIIA4DCxwLdjRZA5ggAAwB4EQQBwGMOMSNKW8RHsEQQAADYjCAKAw4TNaOVvy/gITg0FAAD2IggCgMPEKoKx8RFe5ggCAACbEQQBwGG27BGMBkE/raEAAMBmBEEAcJj4HkFfNAB6PB75PF5aQwEAgG0IggDgMLEW0FhFUJL8vgCtoQAAwDYEQQBwmFjlL7BVEAx4/fFDZAAAANJFEAQAh9l+fIQUDYIGFUEAAGATgiAAOIyx3fgISfL7/BwWAwAAbEMQBACH2VVFkCAIAADsQhAEAIfZfnyE1NUa2hUQAQAA0kUQBACH2VIR3LY11IhwWAwAALAHQRAAHCY+PsJHaygAAMgMgiAAOMxOx0f4ODUUAADYhyAIAA6zs8Ni/N4AFUEAAGAbgiAAOMyWw2K27BGkNRQAANiJIAgADhPeyamhflpDAQCAjQiCAOAwO90jSEUQAADYiCAIAA4T2yPoozUUAABkCEEQABzGMA35vD55PJ74Y8wRBAAAdiIIAoDDGBFjm/2BEhVBAABgL4IgADiMYUa22R8oRecIEgQBAIBdCIIA4DCGaWwzOkKKzhG0LEuRrv2DAAAA6SAIAoDDhM2dt4bG3gcAAJAugiAAOMzOKoIBXzQIMksQAADYgSAIAA6zsz2CfiqCAADARgRBAHAYg9ZQAACQYQRBAHCY7ltDmSUIAADSRxAEAIcxzIj8vsA2j9EaCgAA7EQQBACHiQ6U374iGA2GYQ6LAQAANiAIAoDDGGZkl3sEDSqCAADABgRBAHCY8E4HytMaCgAA7EMQBACHMUxjh/ERscNiaA0FAAB2IAgCgMN0Nz6C1lAAAGAHgiAAOMxOW0NjFUGT8REAACB9BEEAcJjuDouhNRQAANiBIAgADmOYRrwCGBPwBuLvAwAASBdBEAAcZmcVQT+HxQAAABsRBAHAQSzL2vlAecZHAAAAGxEEAcBBTMuUJYtTQwEAQEYRBAHAQQwzIkk7zBH0dVUIaQ0FAAB2IAgCgIPEKn7bt4Z6PB75vX5aQwEAgC0IggDgIOF4EPTv8L6A1y8jwhxBAACQPoIgADhIrCIY8O0YBP0+KoIAAMAeBEEAcJDYHsFdVQQJggAAwA4EQQBwECOy8z2CUldraFdQBAAASAdBEAAcxOhmj6Df548HRQAAgHQQBAHAQXpuDeWwGAAAkD6CIAA4yK7GR0ix1lAqggAAIH0EQQBwkO7GR/h9AQbKAwAAWxAEAcBBeqoIcmooAACwA0EQABwktkcw4Avs8D4OiwEAAHYhCAKAg1ARBAAA2UAQBAAHCUd2vUeQIAgAAOxCEAQAB9kyPmLHiiCtoQAAwC4EQQBwkFhraIA5ggAAIIMIggDgIEY34yNoDQUAAHYhCAKAg3R3WIzfF6A1FAAA2GLHPznnwPz583XHHXfIsiyZpqlf/vKX+s53vpPrZQFA1sX3CO5kfESsImhZljweT7aXBgAAXCTnQdCyLF1xxRV66KGHNGrUKH366ac644wzdMwxx8jrpWAJoG+JVQR9nh1//gV80R/ZETMivy/nP74BAEAv5oik5fV61draKklqbW1VdXU1IRBAnxSOGPJ7/Tut+MX2DbJPEAAApMtjWZaV60W8++67uuSSS1RUVKT29nbdf//9OuCAA3r8uFAopNra2iysEACy49/rF+jDls906cgf7fC+xU0f69XGd/XLEWepyFeQg9UBAACnGjt2rPLz8xN+fs57iwzD0P3336977rlH48eP1+LFi3XppZfqueeeU3FxcULXSPaTRvYsXrxY48ePz/Uy0A3ukbP8Z/Hnyu/I2+aexO7RphWbpcZ3tc/YfVRVVJG7RWIbfA85H/fI2bg/zsc9crZUi2M5779ctmyZGhoa4v+4xo8fr8LCQq1YsSLHKwOA7DPMyE5HR0hbt4YySxAAAKQn50Fw0KBBWrdunVauXClJWrFihRobG7X77rvneGUAkH1hM7zT0RHSlsNi2CMIAADSlfPW0AEDBui3v/2tLr744vjhCL///e9VUVGR24UBQA50VxEMeKMjJZglCAAA0pXzIChJJ554ok488cRcLwMAcs4wjV2OhuDUUAAAYJect4YCALaIVgR7aA2lIggAANJEEAQABzG65gjuTKDrcYOKIAAASBNBEAAcxDB3HQRpDQUAAHYhCAKAgxhmJF75296W1lDGRwAAgPQQBAHAQbodH0FrKAAAsAlBEAAcpNuB8r7o+AgOiwEAAOkiCAKAg3Q3PiLAHkEAAGATgiAAOEi34yNoDQUAADYhCAKAg3Q3PsLPHEEAAGATgiAAOEh0fET3FUFaQwEAQLoIggDgINHxEYGdvs/n9cnj8cgwGR8BAADSQxAEAAfpriIoRauCtIYCAIB0EQQBwCEsy1LY3PUeQakrCNIaCgAA0kQQBACHiFimJHVbEfR7/TLMSLaWBAAAXIogCAAOERsLEdjFHEEpenKoQWsoAABIE0EQABwiFgR7bg3lsBgAAJAegiAAOESs0tfjYTHsEQQAAGkiCAKAQ8T2/nVXEaQ1FAAA2IEgCAAOkVhraICKIAAASBtBEAAcIpxIEPT544ERAAAgVQRBAHCILa2h3Y+PYKA8AABIF0EQABwikfERHBYDAADsQBAEAIdIZI8gh8UAAAA7EAQBwCHCCY+PYI4gAABID0EQABwikfERtIYCAAA7EAQBwCHiewRpDQUAABlGEAQAh0isIsgcQQAAkD6CIAA4xJbDYrrZI+ijNRQAAKSPIAgADpHQqaFevyJmRKZlZmtZAADAhQiCAOAQ8SDYwxzB6HMjWVkTAABwJ4IgADhEQuMjukIiB8YAAIB0EAQBwCESOSwm9j5mCQIAgHQQBAHAIRLZIxiIB0EqggAAIHUEQQBwCMOMyCOPfJ5d/2gO+ALR59IaCgAA0kAQBACHCJuG/F6fPB7PLp/jpyIIAABsQBAEAIcwTKPbtlBpy2ExYSqCAAAgDQRBAHAIwzS6HR0hbT0+giAIAABSRxAEAIcwzEi3oyMkWkMBAIA9CIIA4BBGhNZQAACQHQRBAHAIo+uwmO5saQ1ljiAAAEgdQRAAHMIwIwp4A90+h9ZQAABgB4IgADhEQhXBrjmCtIYCAIB0EAQBwCHCiYyP4NRQAABgA4IgADhEQqeGclgMAACwAUEQABzCMI34qaC7EmCPIAAAsAFBEAAcwogY8tEaCgAAsoAgCAAOkchhMVtaQxkfAQAAUkcQBACHiO4R7L4i6PV45fN4aQ0FAABpIQgCgEMYphFv/eyO3xeQYUaysCIAAOBWBEEAcIhExkdI0X2CBqeGAgCANBAEAcAhEhkfIUWDIK2hAAAgHQRBAHCIxFtD/QqbHBYDAABSl1AQjEQiuvLKK9XZ2Znp9QBAn2WYkfipoN3xe320hgIAgLQkFAR9Pp/efvtteTyeTK8HAPoky7ISGh8hSQFvgNZQAACQloRbQ3/0ox/pzjvvVDhMOxIA2C3SdQpowofFEAQBAEAaev6No8vf//53NTY26i9/+Yuqqqq2qQ6+9tprmVgbAPQZsWCXSBD0+/wK0xoKAADSkHAQvOWWWzK5DgDo08LxIMipoQAAIPMSDoKTJk3K5DoAoE8zkmkN9fnVEQ5mekkAAMDFEt4jGA6H9Yc//EFHH3209t13Xx199NH6wx/+wEmiAGCDpFpDqQgCAIA0JdUa+uGHH+qGG27Q4MGDtWbNGt1zzz1qa2vTNddck8k1AoDrxSqCicwRjLaGcnAXAABIXcJB8MUXX9RTTz2lyspKSdIee+yhMWPG6KSTTiIIAkCawpFosPP7et4j6Pf5mSMIAADSknBrqGVZST0OAEhcUnsEmSMIAADSlHAQPO644/SLX/xCb775plasWKE33nhDF1xwgY4//vhMrs8Wa1rr9f43S3O9DADYJYNTQwEAQBYl3Br661//Wvfee69mzZqlhoYGDRw4UCeccILOP//8TK7PFs9+9m/9e+VbuuP432pQaXWulwMAO0hmjyCtoQAAIF0JB8Hm5mZdfPHFuvjii7d5fP369RowYEBaiwiFQrrpppv07rvvKj8/X+PGjdONN96Y1jW31hHukGVZevLTl/XfE8+y7boAYJdkTg2lIggAANKVcGvo1KlTd/r4d7/73bQXccsttyg/P18vvfSSnnnmmR3CZrqCRkiS9PqXC9S4eaOt1wYAOyQVBH1+mZYp0zQzvSwAAOBSaR0W09bWJo/Hk9YC2tvb9eSTT+riiy+OX6t///5pXXN7QSOk6uJ+kmXpmU9ftfXaAGCHZA6LiT2HqiAAAEhVj79xHHHEEfJ4PAqFQjryyCO3eV9TU1PaFcHVq1eroqJCd911lxYuXKji4mJdfPHFmjBhQsLXqK2t7fb9G5o3qsRXqOqSKr3yxRsaGR6sYn9hWutG4hYvXpzrJaAH3KPcW966QpL02aefakNe/Q7v3/oerWtaJ0l6/4P3VeDLz84C0S2+h5yPe+Rs3B/n4x65T49B8JZbbpFlWTrvvPN08803xx/3eDzq16+f9thjj7QWYBiGVq9erTFjxujKK6/U0qVL9d///d965ZVXVFJSktA1xo4dq/z8Xf8y9Pf6Z1VdUa0fjJ2uS1+YpbrCRp2534y01o3ELF68WOPHj8/1MtAN7pEztK0KS/XS/vvur0El2+673v4ebfiiTfMaF2ifffdRRWF5tpeK7fA95HzcI2fj/jgf98jZQqFQj4WxnekxCE6aNEmStGDBAhUW2l9FGzx4sPx+v6ZNmyZJ2n///VVZWalVq1Zp3333teU1gkZIBf58DS4bpIOHHqiXPn9dJ+59rEryim25PgCkK5nxEX5vQBKtoQAAIHUJ7xH89a9/rffff3+bx95//31ddNFFaS2gqqpKkydP1ttvvy1JWrVqlTZs2KBhw4aldd2tBY2gCvzRiuH3xhynDiOoFz9/zbbrA0C6khkfEWCPIAAASFPCQXDRokU64IADtnls3LhxWrhwYdqLuOGGG3T//fdr+vTp+tWvfqWbb75ZZWVlaV9Xih5yE6sIStKwiiEaP3hfPb98voLhoC2vAQDpCid5aqgkZgkCAICUJTxHMC8vTx0dHdvs29u8ebP8/oQvsUtDhw7V3/72t7SvszOGaShimfEgKEknjzle1756s15e8aZO3PvYjLwuACQjmfERnBoKAADSlXBF8NBDD9X111+vtrY2SdHREbNmzdJhhx2WscXZITZDsNBfEH9sz34jtO/AvfTsZ6+qMxLO1dIAIG7L+Iie9wjGKoJhKoIAACBFCQfBq666Sm1tbZo0aZIOPvhgTZo0SW1tbbrmmmsyub60xYLg1hVBSfre6OPVFGzR/JXv5GJZALANwzTk8XjkSyQIdlUEDZM/ZAEAgNQk3NdZXl6uBx54QA0NDVq3bp1qamo0YMCAnj8wxzq69gEWBLYNgvtUj9Kofnvo6U9f1tEjD03or/AAkCmGaSTUFirRGgoAANKXcEUwprq6Wvvuu6/69esn0zRlmmYm1mWbXVUEPR6PTh5znNZv3qi3vnovF0sDgDgjYiT8B6mAr2t8BK2hAAAgRQlXBOvr6zVr1iy9//77amlp2eZ9y5Yts31hdtlVEJSkA2rGanjFED3xyYs6fNhkeb1J52IAsIVhRhIaHSFt3RpKEAQAAKlJOPnMnDlTgUBAf/3rX1VUVKQnnnhCU6ZM0Q033JDJ9aVtSxAs2OF90arg8Vrb1qAFdR9ke2kAEJdUayiHxQAAgDQlHASXLFmim266SaNHj5bH49Hee++t3/3ud/rzn/+cyfWlrbuKoCRNGjJOu5UO0hOfvCjLsrK5NACIC5tJtIayRxAAAKQp4SDo9XrjMwPLysq0ceNGFRUVqb6+PmOLs0NPQdDr8WrG6Kn6qvkbLV7zUTaXBgBxhhlJuCJIaygAAEhXj0Fw/fr1kqT9999fr7/+uqToTMFLLrlEF154ocaOHZvZFaappyAoSYcMm6gBxf30xCcvUBUEkBOGaSS8R5DWUAAAkK4eg+DUqVMlSTfffLMmTpyoCy+8UNdcc40mT56sPffcU7fddlvGF5mOWBDM9+ft8jl+r08n7f0dfb7xS9U2fJatpQFAXDJ7BLe0hjJHEAAApKbH3zpiFbKysjJJ0nvvvaeCggJdcMEFmV2ZTYLhoPL9+fJ6us+8R444WI99/Lwe/+QF7Ttw7yytDgCijCT2CPrjraGRTC4JAAC4WI8VQY/Hk411ZEzQCHXbFhqT5wto+t7H6OOG5fp8w6osrAwAtjDMSLzlsycej0d+r589ggAAIGU9/tYRiUS0YMGCeGXQMIxt3pakgw8+OHMrTFOiQVCSDh02Sf/3n8f0+YZV2rPfiAyvDAC2MCKGivKKEn5+wOtnjyAAAEhZj0GwX79+uuaaa+JvV1RUbPO2x+PRv//978yszgbJBMGy/BL5vD41BVsyvCoA2FYy4yOk6IEx7BEEAACp6jEIzps3LxvryJhkgqDX41VFQZk2djRldlEAsJ1kxkdI0YqgQUUQAACkKOE5gr1VMkFQkqoKytXUQUUQQHYlc1iM1NUayh5BAACQIoLgdioKy7WJiiCALDPMiALeQMLPj7aGEgQBAEBq+kQQLPQXJPz8ysJybWKPIIAsS3aPIK2hAAAgHX0iCCZTEawsKFdbZ7s6IxzCACB7khkoL9EaCgAA0uP6INhhBFUQSCIIFlZIEieHAsiqZOYIStHWUOYIAgCAVLk6CBoRQxEzklxFsLBMktgnCCCrkj0sxs8cQQAAkAZXB8GgEZKkJFtDKyRJmzqaM7EkANiBaZmKpDA+gjmCAAAgVQTB7WypCBIEAWRHxIxIUtID5TksBgAApIoguJ3S/BL5PF5tChIEAWSH0RUEkxkfwWExAAAgHQTB7Xg9XlUUlFMRBJA1sUCX3PiIAEEQAACkzOVBMCgpuSAoRWcJNlERBJAlRjwIJnlqKK2hAAAgRS4PgrGKYOID5SWporBcG6kIAsgSI4U9grSGAgCAdLg6CHaEu4JgEnMEJamyoExNBEEAWRKrCAaSmCMY8BEEAQBA6lwdBFPZIyhFh8q3drYrHOFodgCZF2vxTKo11BttDbUsK1PLAgAALkYQ3InKgugIiaZgi+1rAoDtGSkdFuOXJUsRy8zUsgAAgIu5PAh2HRbjS74iKDFLEEB2bNkjmFxrqCQZdC4AAIAUuDwIhpTnC8jrTe7TrCwslyRmCQLIipRODe16LvsEAQBAKlwfBJNtC5W2CoJUBAFkQTiFIBgbPk8QBAAAqSAI7kRZfom8Hi9BEEBWpDQ+It4aShAEAADJc30QLExyhqAkeT1eVRSUEQQBZEUq4yNoDQUAAOlwfRBMpSIoSZUF5ewRBJAV4RTGR8RCY5iKIAAASIG7g2A4mPQw+ZjKwnIqggCyItXxEVt/LAAAQDLcHQSNkPJTrAhWFFIRBJAdqYyP2NIayvgIAACQPNcHwVRbQ6sKy9UaauMgBgAZF98jSGsoAADIEoLgLlQUREdINAVb7FwSAOwglTmCsfERtIYCAIBU9IEgmPypoVK0IihJGzuabFwRAOwolfERnBoKAADS4dogaJgRhU2DiiAAx0upIkhrKAAASINrg2DICEmSCtPYIyhREQSQeYZpyOvxyutN/Ecyp4YCAIB0uDYIBruCYKoVwbL8Unk8HjVxciiADAtHjKTaQiXJT0UQAACkwbVBsMMISlLKcwS9Xq8qCsq0qYPWUACZZZiRpNpCpS0VQcZHAACAVLg2CAbDsYpgaofFSFJlQbk20RoKIMMMM/mKIK2hAAAgHe4Ngmm2hkpSZWG5NnFYDIAMM8xIfBxEovy+2PiISCaWBAAAXI4g2A0qggCyIZxCRdDn8cojD3sEAQBASgiC3agsLFdLqI2/uAPIqGhraHJ7BD0ej/w+P3MEAQBASgiC3agsjM0S5ORQAJljmJH4KaDJCHj9MiIcFgMAAJJHEOxGZWGFJKmJk0MBZJARCSfdGipFgyAVQQAAkAqCYDcqC8okMVQeQGalMj5CEq2hAAAgZa4OggFfQL4U/soeE68I0hoKIINSGR8hxVpDCYIAACB57g2C4WBa1UBJKs8vlcfj0cYOgiCAzImOj0htjyAVQQAAkAr3BkEjlHYQ9Hq9qsgvUxNBEEAGhVM4NVSiNRQAAKSOINiDisIybaI1FEAGpTI+QpIC3gCtoQAAICUEwR5UFlZoExVBABkUPSwmhT2CVAQBAECKCII9qCwoJwgCyCjDNFKaI+hnjiAAAEgRQbAHlYXlagm1yTAjNqwKAHZkRFLcI+j1UREEAAApcXEQDKrQX5D2dSoLymXJUnOQofIAMiP18REBgiAAAEiJi4OgfRVBSbSHAsiYdAbKc1gMAABIhbuDYMDGIMjJoQAyJGwazBEEAABZ5cogGDEj6oyEbTssRqIiCCAzTNOUaZkptoYSBAEAQGocFQTvuusu7bXXXlq+fHla1wkZnZJkSxAsLyiVRx6CIICMMKzoQVS0hgIAgGxyTBD8+OOP9Z///EeDBw9O+1pBIyTJniDo8/pUVlBKayiAjDC6KnqBFMZHUBEEAACpckQQ7Ozs1KxZszRz5kx5PJ60rxc0gpLsCYKSVMUsQQAZEqvopVIRDPj8MkxDlmXZvSwAAOByyf/mkQF33HGHTjzxRA0dOjSlj6+trd3m7XXBRklS3Vd1WtyY/L6b7Xk6pTUda7V48eK0r9UX8XVzPu5R7rQa7ZKkb1Z/o8Utu74PO7tHDRsbJEnvLV4kvyf9n3VIHd9Dzsc9cjbuj/Nxj9wn50FwyZIl+uijj3T55ZenfI2xY8cqP39L9e+ThuVSnTR2rzEaO3DvtNe4yFymxWs+0vjx49O+Vl+zePFivm4Oxz3KrYa2RulLaeSIPTR+xM7vw67u0ZpPN0kb39e++++rokBhhleKXeF7yPm4R87G/XE+7pGzhUKhHQpjich5a+iiRYu0cuVKHX300ZoyZYrWrVunc845R2+99VbK19yyRzD9gfJS9OTQlmCrImbElusBQExsj2CqraGSODAGAAAkLecVwfPOO0/nnXde/O0pU6bovvvu06hRo1K+ZjwI2jBHUIrOErRkqTnYqqqiCluuCQCS4oe9pDI+IhYeOTAGAAAkK+cVwUzoCNt7WAxD5QFkimGmPj4iQBAEAAApynlFcHvz5s1L+xp2jo+Qth4q3yRpmC3XBACJ1lAAAJAbrqwIxoOgz+aKYEeLLdcDgJhYRTCVOYK0hgIAgFS5Ngj6vX75U/jFamfKC8rkkUebgk22XA8AYsKR1PcIxsJjOBK2dU0AAMD9XBsE7WoLlaK/oJXll1ARBGC7tFpDuz7GoCIIAACSRBBMUGVhedceQQCwj5HWqaEBSbSGAgCA5Lk2CBZmIghyaigAm8WCYCCNw2LCHBYDAACS5NogaHtFsKBcmzoIggDsZcf4CFpDAQBAstwbBG0aJh9TUViu5lCrIl2/tAGAHdLZI+inIggAAFLkziAYDirfX2DrNasKy2VZlppDrbZeF0DfFq8IpnDKMQPlAQBAqtwZBDPQGlrRNVS+ifZQADZKa3xEvDWU8REAACA5BMEEVRVWSJI2EgQB2MiO1lCDlnUAAJAkgmCCKgrLJElNnBwKwEbpjI8IxMZHsEcQAAAkyXVB0DRNhSKdGWsN5eRQAHYyzIh8Hq+8nuR/HLNHEAAApMp1QTAU6ZQk24Og3+tTWX4JQRCArcKmkVJbqCR5vdEAyR5BAACQLNcFwaARkiQV2nxqqCRVFlYwVB6ArQzTSKktNCbg9dMaCgAAkubaIGh3RVCSKgvKqAgCsJVhRlKuCErRA2NoDQUAAMlyXRDsCAclyfaB8pK7K4KbOpr196WPqzNCixmQTYZppDRDMCbg9cugIggAAJLkuiCY0YpgYZmagi0yTdP2a+faB2s+0tOfvqL36v6T66UAfYoRSX2PoNTVGkpFEAAAJIkgmITKggpZlqWWUKvt18615q7P6c2v3svxSoC+JdoamvoeQVpDAQBAKgiCSagsjI6QcONQ+ZZgNAguXfeJmoItOV4N0HcYaZwaKkVnCdIaCgAAkkUQTEIsCLpxqHxLqE35vjyZlql3vn4/18sB+oywacTnAaaC1lAAAJAKFwbBrsNiMtIa6t6KYHOoVcMqhmh4xRDaQ4EsSnd8hN/nZ44gAABImguDYObmCFYUlElyaUUw2KqyglIdPnyyVmz8Smta1uV6SUCfkO74COYIAgCAVLgyCPq8vrSOY98Vv8+v0vwS11YEy/NL9e3dJ8jj8egNqoJAVhimoUA64yM4LAYAAKTAlUEwE22hMVUF5WpyWRA0LVMtoTaV5ZeoqrBC+1bvrTe/ek+m5b4xGYDTGBFDvnQGyjNHEAAApMB9QTCc2SBYUViuTS4Lgps7O2RapsoLSiVJhw+frPXtG7S8cWWOVwa4X7rjIzgsBgAApMJ9QTDDFcHKgnJtctkewdgMwbL8aBCctNv+yvfl0R4KZEG64yP8BEEAAJACFwbBYGaDYGG5moItMk33tE02d80QjFUECwIFmjhknN5dvVjhCKcRAplkmJG0xkf4fbSGAgCA5LkwCGa4IlhYHt1T19mWsdfItpauimB5V0VQkg4fNkntnZu1ZO3HuVoW0CeEzTCtoQAAIOsIgkmKDZV30z7BWEWwLL8k/ti+A/dWeUGZ3vhyYa6WBfQJtoyPIAgCAIAkEQSTFBsq76YgGKsIlm4VBH1enw7ZfYI+WFurtlB7rpYGuJ4tA+Vp4QYAAElyZRDMxDD5mC0VwaaMvUa2NYdaVZpXLN92v4wePmySDNPQgroPcrQywP3C6c4R9PoVsUzGvQAAgKS4MghmdHxEQZkkaVOwJWOvkW0twTaVFZTu8PiIyt21W+kg2kOBDDFNU5Zlpdca6gtIEgfGAACApLgqCJqWGQ2CgcwFwYAvoNK8YtdVBLc+KCbG4/HosOGT9GnjCjW0NeZgZYC7GV17+9IdHyGJfYIAACAprgqCnUanJGW0Iih1DZV3VUWwNT5DcHuHDpskSXrr60XZXBLQJxhmRJLSPjVUIggCAIDkuCoIBo2QpMwHwarCcldVBFtCrSorKNnp+6qL+2n0gD31xpcLZVlWllcGuFvYjB7ykl5raPRjaQ0FAADJcGkQzNxhMZJUUVCupg53VAQjZkStne07bQ2NOWzYJK1prdfKTV9ncWWA+22pCNIaCgAAssulQTCzFcHKwnI1BZtdcUpfa6hNklS+k8NiYg4aeoD8Xj+HxgA227JHMI3W0K6KYJgREgAAIAkEwRRUFpQrYpnxENWbNYdiw+R3HQRL8oo1fvC+evvrRfEKBoD0xb6f0h0fEb0WFUEAAJA4gmAKtswS7P1D5ZuDPQdBKdoe2hJq00f1y7KxLKBPCEfsODU0Oj6C1lAAAJAMgmAK4kEw2PuDYEsCraGSdGDNWJXkFdMeCtjIjvERW1pDCYIAACBx7gyCgcweFlNZWCHJHRXBlq7W0O4Oi5Ekv8+vg4ceqEXfLFVHOJiNpQGuZ+f4CFpDAQBAMlwVBGMBJeNzBAvKJLkjCDYHW+XzeFWUV9jjcw8bNlmdkbAW1i3JwsoA94uFtwCnhgIAgCxzVRDMVmtoni+gkrxidwTBUHSYvNfT8z+Fvfrvoerifnrzq/eysDLA/WgNBQAAueK6IOj1eNP663qiKgvK3LFHMNiqsvydD5Pfnsfj0WHDJqu2/jNt7GjK7MKAPsCW8RG0hgIAgBS4LggW+PPl8Xgy/lqVhRVqaN8gy7Iy/lqZ1BJqU1kPB8Vs7bDhk2TJ0vyV72RwVUDfYMtAeR9BEAAAJM+VQTAb9hu0t75qqtNDHz7Rq8Ngc6i1x4Nitja4dKAOHLyv/vnxs1qw+oMMrgxwv/j4CBvmCNIaCgAAkkEQTNH0vY7Vd0Yerqc/fUWPfvxcVl4zE1qCrUlVBCXpkoN+qlFVI3THu3/S4jUfZWhlgPvZskeQOYIAACAFrguChf7Mjo6I8Xg8+un403Xk8IP1r4+f05PLXsrK69qp0+hUhxFMqiIoRcdzXH34hRpeMVS3vf2APlzHkHkgFXaMj6A1FAAApMJ1QbAgkJ2KoCR5PV7998Sz9O3dJ+gfHz6pF5bPz9pr2yE2TD7Rw2K2VpRXqGuP+KV2Kx2om9+6V580fG738gDXs6MiGAuR4UjYljUBAIC+wWVBMKj8LLWGxni9Xl04+ceauNv++suSf+rVFW9l9fXTER8mn2RraExJfrGuO/IiDSjqp/958259vmGVncsDXC9swxxBr8crn9dHaygAAEiKu4JgOHt7BLfm9/p0ycHnaNygMXrw/X/ojS8XZn0NqWjuCoJlSbaGbq28oEy/OfJileeX6qbX79SqTavtWh7genaMj5CiQdLgsBgAAJAEdwXBLB4Ws72AL6DLD/m5xlTvqbvf+99ecaJmczC9imBMVVGFrj/qEhUECjT79T9odfMaO5YHuF5sj6DPhiBIRRAAACSDIGijPH+erjz0F73mRM14a2gaFcGYAcX9NPPIS+T3+HTja3dobWtD2tcE3M4wDfm8Pnk96f0o9vsIggAAIDmuCYKWZeU8CEpbTtQcVjHE8SdqNgdbFfAFbNtXOai0Wr856mKZlqlZ829XQ/sGW64LuJURMdI6KCaG1lAAAJAs1wTBzkhYlqycB0Fpy4magx1+omZLqE3l+aXyeDy2XXNIWY2uO+JiBSMhzZo/V61Gu23XBtzGMCNp7w+UorMEqQgCAIBkuCYIBo2gJGVtjmBPSvNL9JutTtRc9M3SXC9pBy2hVlvaQrc3vHKIrj38l2oNtevhb57TV011tr8G4AaGaU9FkNZQAACQLBcFwZAkOaIiGBM7UXNQyQDd8tZ9uve9v2lzuCPXy4prDraqLM2DYnblW/2G65ojLlSnGdbVr8zR05++LNM0M/JaQG8VNo20RkfERFtDmSMIAAAS574gmMWB8omoKqrQTcdcqe+NPk6vffmufv3S77RsvTNaRZszVBGM2av/SP1095N14OCx+vvSJ3TDa3PV0NaYsdcDeptoRdCG1lAqggAAIEmuCYIdYedVBGP8Pr/O2O8kzZpymbzy6Lfz5urvSx9XOId/wbcsSy3BVpUVlGT0dYp8hbrs2+fpgkk/0peb6nT5S7M1b+U7siwro68L9AbRPYI2tIZyWAwAAEiSa4KgE1tDt7dX/5G6Zeq1mrLHIXr601d09StzcrZ/LmiEFDaNtIbJJ8rj8eiIEQfp1uOu08iqYbpv0d90y9v3qznYkvHXBpzMtoogcwQBAECSXBQEo4fFODkIStHxEj+f+F+68rDz1Rxq1dWvzNFTy7K/f67ZxhmCiRpQ3E+/OfJi/XDcKVq69mNd/uJsve/AQ3SAbDFs2iPIYTEAACBZLgqCzq8Ibm384H1129TrdODgsXrow+zvn2sJdgXBDB0Wsytej1fT9jpGvz/2KlUWluvmrkN0OsLBrK4DcALDjMjvY44gAADIPoJgDpUVlO6wfy5bYyZiFcFstIbuzO4Vu+mmY67UjNFT9dqX7+ryl2arrnltTtYC5Ep0oDxzBAEAQPa5Lgg6ZY5gorbeP9evsFKP1j6blddt7qoIZvqwmO74fX6dud8M3XDUZWoJtemFz+fnbC1ALth2WAytoQAAIEnp/waSpk2bNumKK67Q119/rby8PA0bNkyzZs1SVVVVUtcJGiF5PB4FfIEMrTSzBhT3036DRmv+quiJmh6PJ6Ov15LjiuDW9h4wUkPLarSurSHXSwGyKmzXQHmvjzmCAAAgKTmvCHo8Hv3sZz/TSy+9pGeeeUZDhw7VrbfemvR1gkZIBf78jAeoTBpY0l9BIxQPaZnUEmxVYaBAeQ4JzoNKq7W2dX2ulwFklWFTEOTUUAAAkKycVwQrKio0efLk+Nvjxo3Tww8/nPR1YkGwNxtUUi1Jqm9rVHlBWUZfK9PD5JNVUzJAb3+1SJ2RsGPCKZBpPY2PiLQ365u/Xq3y9mZ9+dquf1y3lwUULvXry9t+lIllogflEaPb+4Pc4x45G/fH+bhHzmYWVUqTzk764xx1R03T1MMPP6wpU6Yk9XG1tbVa07BWHkNavHhxhlaXeRs6myRJ7370nlrLNmX0terWr5HP8mTl65XIawRb22XJ0ryFr2tAfmXG14Rt9ebvm95sc7BDzZuadvn1DzR8rpKmehk1Y9QZKNrldSxvsyxPs1qr95JPvbcrojfrzPUC0CPukbNxf5yPe+RcZn5xSh/nqCB44403qqioSGeddVZSHzd27Fi90r5A5YGwxo8fn6HVZV44EtafVj+mwgElGj82s5/Hw+tfUE1JTca/XosXL07oNco39NMz9a+pavf+Gj9kXEbXhG0leo9gP8/qRzRowKBdfv2b3vlaGyW1jzlO4w86ZJfX+XzZy9KHT2jPMy7r9Z0RvRHfQ87HPXI27o/zcY+cLRQKqba2NumPy/kewZg5c+boq6++0u233y6vN/llRVtDe9eJodsL+ALqX1ip+rbM75VrcVpraGm0LZYDY9CX9NQa2tlYJ19plRTo/mdboGsWIbMEAQBAohwRBOfOnava2lrdfffdysvLS+kabtgjKEkDSwZoXYaDoGmZagm1qTyHoyO2V5xXpNL8Eg6MQZ/S00D5cONq5fUf2uN1YgfOcGAMAABIVM6D4Oeff6777rtPDQ0N+sEPfqCTTjpJF1xwQdLXcUsQHFQyIOMVwfbOzTIt0xGjI7ZWU1JNRRB9hmVZXQPldx4ELctUZ+M3CvQf0uO1AgRBAACQpJzvEdxzzz312WefpX2doBFSoQuC4MCSAWoJtWlzuENFgcKMvEZz13iK8gJnBcFBpQNUW5/+vwWgNzAtU5asXQZBo7lRVjiovAFDJbP7a21pDWWWIAAASEzOg6Bd3FIRHFjSX1J0hMSIyp5bwlLREnTOMPmt1ZRU640vFypkdCrfn1qLMNBbGGZEkna5RzDcuFqSoq2hDe3dXqs3tYY+/enL+qxxZa6XYaumpibNe2tRj8/zeXyasse3Na5mnyysCgCA7rkiCFqWFQ2Cgd4fBLfMElyfuSAYapMkRx0WI217YMywip7b4YDezOgKbbuqCHY21kmSAv13kxqWd3utQNfszbDDD4upa16rvy99QgOKqjLW8ZALm8Md6mzr+Wvf0tmmBXUf6MjhB+uHB5yikrzUjvsGAMAOrgiChmnItMxef2qotKUimMkDY5pjFUGntYaWxILgeoIgXC9WvQvsKgiur5OvuEK+wp6/T2PXMBxeEXxi2YvK9+Xp99+5WmX5zjmsKl2JHqsejoT12CfP68llL2vpuk907oQzNGG3/bOwQgAAdpTzw2LsEDKiIy7d0BpaGChQeX5pZoNgqFUeeVTqsL9GxyqCa1s5MAbut6UiuOvW0LwBiXUF9IbW0HVt6/XW14t07MjDXBUCkxHwBfSDfU/STcdcqbL8Et381n26490/xbs0AADIJncEwYh7gqCU+ZNDW4KtKskvlq+b+WW5UBgoUHlBmdYRBNEHbNkjuGNF0LIsdTauViCB0RHSlsNinNwa+tSyl+X3+DRt72NyvZSc26Nqd/3+2Kt02thpWlC3RL964Qa9u3pxrpcFAOhj3BEEjZAk9wTBTM8SbA61OvYv8jUlA7Q2w+MzACeIVwR9O/5BJtK6QVZnUHkJjI6QnN8aumHzJr325bs6asS3VVVYkevlOILf59ep+3xXc469Wv2LqjT3nT/qtrcfUFOwJddLAwD0Ee4Igi6rCA4s6a+Nm5sUztBR8C2hNscdFBMzqLSaiiD6BCMS2yMY2OF9neujJ4YGBiQWBGND6Z0aBJ/59BVZlqUTR38n10txnN0rdtPvjrlCZ+43Qx+s+Ui/emGW3vhyoSzLyvXSAAAu54rDYrbsEez9h8VI0UNTLFlqaN+g3coG2X79lmCrhlYMtv26dqgpqdZrwXcVDAdVEHDH/QR2prvxEZ1bj45IQHygvANbQ5uDLXp15Vs6bNgkVRf3y/VyHMnn9WnG6KmasNt+uve9v+muhX/VE5+8yBgdG23evFmPbng518vALnB/nI975Gxl/hJNLf920h/njiDowoqgFD1cIRNBsDnUqrGOrQgOkBT93IdnaHwG4ATdjY8Ir6+Tr7hcvqKyhK4Vqyo68bCY55bPUzhi6Hujp+Z6KY43pKxGN065XC9+8Zo+XLcs18txFU/IUnlBYt9PyD7uj/Nxj5ytxFeU0se5IwjGKoIumCMoRdsjJWXkwBjDjKits13lDhsdEVPTNUJibVsDQRCuFu4mCHY21imQ4P5AybmtoW2d7Xrp89c1eegBGpyBP2q5kdfr1QmjpuiEUVNyvRRXSXTEB3KD++N83CNnC4VCqq2tTfrjXLJH0F2HxZTmFaswUKB1rfYHwdauY8qdeljMoJJoRZAREnC7XY2PsCwrOjoiwbZQybmtoS9+/ro6jKBOHn18rpcCAAC244ogGAy7qzXU4/FoUPEA1bfbHwRbQl3D5B3aGloQKFBlQXlGQjDgJLsaHxFp2yQztDmpimA8CJqZOWAqFcFwUM8vn6cDB++r4ZWJfy4AACA7XBEEQ5FOeeRRnm/H0/d6q4GlmRkh0RyMBkGntoZK0dbYtW1UBOFuu6oIxk4MTXSYvKT4TFAntYa+suIttXW26+TRx+V6KQAAYCfcEQSNTuX78+T1uOLTkRRtkWxo3yDTNG29bqwi6NTxEVJ0liAjJOB2sTbOwHZ/wAoneWKoFO0iCHj9jmkN7YyE9cxnr2hs9V4a1X+PXC8HAADshCuSUyjS6Zq20JiBxf0VMSNq7Nhk63VjFcEyh1cEm0Ot2hzuyPVSgIzZ1fiIzsY6eQtL5U3wxNAYv8/vmFNDX1v1jpqCLTp5DNVAAACcyh1B0Ai5Lghm6uTQ5lCrfB6vigOpHTObDTVdnztVQbjZrsZHhBvrlNd/iDweT1LXC3j98SH1uWSYET217GXt2W+E9qneK9fLAQAAu+COIBgJqdAlw+Rj4rMEbT40pSXUprL80qR/ycymrUdIAG61sz2ClmWpc/1qBZLYHxgT8AYcURF866v3tH7zRp0y5nhH/5wBAKCvc0cQNDpdM0MwpqqwQgGv3/aTQ1uCrY5uC5WkgfEREpwcCveKBcHAVhXBSHuTzGBbUvsDY5zQGmqapp5Y9qKGVwzRATVjc7oWAADQPXcEQRfuEfR6vKou6W97RbA51Orog2IkKd+fp36FlbSGwtV2Nj4i3FgnScpLYnREjBNaQxfULdHa1gZ9b8xxVAMBAHA4dwTBcKfyXRYEpWhlzO49gr2hIihJg0oH0BoKV4tVBH1btYbGRkcEUqgIBrz+nM4RtCxLTyx7UYNLB2rybgfkbB0AACAx7giCLqwIStKg4v5a194oy7Jsu2ZzqFVl+SW2XS9TakqqMzJHEXAKw4zI5/VtUznrbFwtb0GxfCUVSV/P7/PndI7gB2tr9VVTnWaMniqv1xX/aQEAwNVc8V9rN54aKkVPDg0ZITUHW2y5XqfRqaARcnxrqBT93FtDbWrv3JzrpQAZEY4Y2+wPlKKtoYH+Q1Nqq8zlHEHLsvT4x89rQHE/HTpsUk7WAAAAkuPv+SnO59aKYPzk0LZGVRSWp329llCbJKm8F7SGxkZIrG1t0Lf6Dc/tYoAMMExjh9ERnY11Kh6VWpDK8wW0tH6Zfvz4r+xYXlIsWeoIB/Wz8WfsMBcRAAA4kyuCYMQyXRkEB5VsmSW494CRaV+vOdQ1TL4XVARjIyTWtREE4U6GGdkmNEXam2VublFeCqMjJGnG6KkaXDrQruUlrSivUEeNODhnrw8AAJLjiiAoyXVzBCVpQFGVPB6PbXvlmoPRINgbKoLVJf3lkUdrOTkULhU2w9u0hnY2xg6KSf7EUEkaUz1KY6pH2bI2AADgfq7YIyjJlRVBv8+v/kVVtp0c2hKvCDr/sJg8X0D9iyq1lgNj4FLRiuBWQXB9bHREahVBAACAZLgnCLpsoHzMIBtHSMSCYG84LEaKHhjDLEG4VXSP4JbW0HDjannyi+QrrcrhqgAAQF/hniDowoqgFJ0laGdraJ4v0GtmLg4qYZYg3GuHimBjnfL6D2EQOwAAyAqCoMMNKumv1s52W8YoNIdaVZ5f2mt+0awprVZ752a1dp12CriJETHk920JguGuIAgAAJANLgqC7jssRtr25NB0tQRbVdYLDoqJiX3uHBgDN9p6fERkc6si7U0KpHhiKAAAQLJcFATdWRHcepZgulpCbb1idERMbJagXa2xgJNsPT4idmIoB8UAAIBsIQg63MDiaBC0oyIYaw3tLQYW95fHwwgJuNPWFcFwY+zEUFpDAQBAdhAEHa4gUKCKgrK0q2KWZfW61lC/z68BRVUcGANXCptGfI5gZ+NqefIK5Cvrn+NVAQCAvsI1QTDfn5frJWTMQBtGSHQYQYVNo1dVBKVoeygjJOBGW4+PCK9frbz+Q3vNQU4AAKD3c0UQzPfnyetxxaeyUwNL+qs+zT2CLcGuGYK9qCIoRQ+MWdvWIMuycr0UwFZbj4/obKxTgLZQAACQRa5IT/k+91YDpWgY2tCxSZ1GZ8rXaOkawVCWX2LXsrKiprRaHeGgWkKtuV4KYCsjEq0IRjraFGnbxP5AAACQVe4Igi5uC5WiswQlqaF9Q8rXaO4KUr3p1FBp6xESnBwKdzHM6BzB8IbYQTGcGAoAALLHHUHQ586DYmJiYWhdGoemNPfS1tAtIyTYJwh3ibWGdq6Pjo4IDKAiCAAAsscdQdDlFUE7Zgm2xCuCvas1dEBxP3k9XkZIwHVi4yM6G+vkCeTLXz4g10sCAAB9iDuCoMv3CJbkFasoUJjWyaHNwVYVBQoV8AVsXFnm+b0+VRf3Y6g8XMWyrPj4iHDjagX6DZHHxQdeAQAA53HFbx5urwh6PB4NKhmQVhhqCbX2umpgDCMk4DYRy5QU/UNH5/o65dEWCgAAsswdQdDlewSl9GcJtoRae90MwRhGSMBtDNOQJPlMU5HWDZwYCgAAss4dQdDlFUEpuk9wffsGRcxISh/fHGxTWS87KCamprRaQSOk5mBLrpcC2CIWBNURHesS4MRQAACQZQTBXmJQSbUilqnGzRtT+vjmXl4RlKS1nBwKlzAi0SDoaY/+cSNvAEEQAABklzuCoMsPi5G2zBKsT+HkUNMy1RrqzRXB6GmKzBKEWxhdlX1Pe7M8/jxODAUAAFnnjiDYByqCA0uivyimcmBMe+dmmZbZaw+L6V9UJZ/XxyxBuEa8NbR1kwL9dpPH68vtggAAQJ/jjiDYBw6LqSwsV8AXSCkINod65zD5GF/XCAlmCcItYhVBtW6gLRQAAOSEO4JgH6gIej1eDSzun9LJoS3BriDYS/cISlJNCSMk4B7hroqgZ3OLApwYCgAAcsAdQbAP7BGUoieHplMRLOvFQXBQabXWta1nhARcIT4+whKjIwAAQE64Iwj2gYqgFD09s6GtMekw1Bzs3a2hUrQiGIp0alNHc66XAqRtSxC0GB0BAABywh1BsA/sEZSiFcFQpFNNSc7Tawm1ySOPSvN652ExUnSWoMQICbhDuGt8hN/rV6ByYI5XAwAA+iJ3BMFA36kISkr69MyWYKtK8ovl9fbe2z0oFgTZJwgXiB0WU1DWnxNDAQBATvTeZLCVvrJHMNVZgr15mHxM/8JK+b1+RkjAFWKtofnl1TleCQAA6KvcEQT7yB7B/sX95PV4kz4wpiXU2qv3B0qS1+vVwJL+VAThCuHODklSYWVNjlcCAAD6KncEQW/fCIJ+r08DiqqSDoLNwdZefWJoDCMk4BbBluj3cEG/wTleCQAA6KtcEQR78963ZA0sGZD0LMGWUJvK8nvvQTExg0qrta69UaZl5nopQFpCLdH27sJ+jI4AAAC54c/1ArKhY80KNSx9W3LBDLqi4AZ9Ht6gr57/34SeH7FMtXW2K2/tl9r42sMZXt2OCtat1cbW5bZcq2zzGoUjYa2c97+q8hXYck3Ye4+QmLZvlkl+WkMBAEDuuD4Irlv8ulpevFt+RWRanlwvJ22VFYXqGFCilv88q0Kz52Db4vNKe/STb1WtNrW+L4+y+zUosCw1rbTnNYsKA9Lgcq388BV5O8K2XBP23iMkJlheIPUvUcDfN0bfAAAA53FtELQsSyte+v/kef9R1ZnV6jjkv1Vc2S/Xy0qb1faZtPZfWnbkr1Vd0PP+ovXBddLqP+mJ9iP08IZq7TagRMdO2l1HTRiqqrLMV9UWL16s8ePH23Ktss0bpWeulWf6L7THtw6z5Zqw9x4hMR8te1n68An5fa79EQwAABzOlb+FWGZEHz30B5V8/ZY+0R4a8+Mrtcfu/XO9LFvs0eTRi2ul3YZ4dMjuPe8v+nBdq7Rauu6Hh2t9XYFeee9r/fW5T/R/LyzT+L2rdczE3TVxzCAF/M7fZ1lVWKGAL8BQefR6sfERfq8rfwQDAIBewHW/hRjBzVr6xxtV2bxcS/ImaMrPL1FlWWGul2Wb6iRnCbaEWiVJA0rKtf+kQTpm0jB9s75N/170tf69aLUWfbJIZcV5OnL8EB02bjcVFwRsXe/65rBW17cm9Fyfz6P8gE95sf/5vfJ4trQsej1eDSoZwMmh6PViA+V9Huf/AQYAALiTq4Jg+4YGffqnmSrrXK+lA47Xief8RAG/L9fLslWBP1+VBeUJj5BoDkZDWNlWcwR3G1CiH54wRv913Ggt+axBr773tZ5/e5WefmNlRtas5+pT/tA8v3dLMAx41VHj0drAKl20+CUbF5gZXssvj5z/769982YVv/FarpfRpzSXrpSnxKv5i1froLE1KrL5DzAAAAA9cU0QrP/iM637500qNIP6ap8fa8aM725TTXKTgSX9Ex4h0Rxqlc/jVXGgaIf3+bweTRg9UBNGD1RzW0i1KzfIjNh7surKVSu1x4g9enyeJUtGxFJnOKLOcEShcESdYXObt8OGqVVWlRoC32hdzZO2rjMTPJZfJcZglRm7q8QYIr+ceTCIxwypvJRTWLOpI9+jNtOruQ8vUZ5/qSaMGajDxw3RhDEDlR9w/h8PAABA7+eIILhq1SpdddVVampqUkVFhebMmaPhw4cn/PFfLnlf5qt3yrQCCh7zax1z8ITMLdYBBpVUa2n9Jwk9tyXYqrKC0h5DcXlJvg7Zz/7h1kXmOo0/YDfbrtcc3FMLVi9x/CxBS5bWtNRr0Zql+qbjLXk9Xo0ZsKcm7ra/Ju62v/oXV+V6iXEcFpN9f1y8Su9+/bVuuPAwvbGkTm8tXaN3Plyrwny/Dho7SIcfMETjRg2Q30frKAAAyAxHBMGZM2fqzDPP1EknnaSnnnpK119/vf7v//4v8Qu8/Wc1ecpUc8Y1Gj5yeMbW6RQDS/pr05fNChmdyvfndfvc5lCryvNLu31Ob1JeUKapex6R62Uk7KfW6Vq58Wst+mapFn2zVH9Z8k/9Zck/NaJiqCYOiYbC3ct3c231GjtnmBH5vX6NHlGl0SOq9LOTxuqjFY16Y8k3euejtZq/uE6lRXk6ZP/BOmS/GtU3hfXl2pZcLxu7wP1xPu6Rs3F/nI975Gwey0jx46zcTlnfsGGDpk6dqoULF8rn8ykSiWjy5Ml6+eWXVVXVfdUkGAzq448/1uZFL2uvGeeovLI8S6vOrcVrPtSfP/inBpUM6PHUwfWbN2iPit114UE/zs7itlNbW6uxY8fm5LWdqL69UR+tW6YP6z/Vyo1fy5KlysLynbbuZkuwo0MFhe45UKk32NjRpEJ/vmYdffkO7zMiEdWu2KD3PqnXf5avV2c4koMVAgCA3qKs0Keffqda++yzjwoKEt/uk/MgWFtbqyuvvFLPPfdc/LETTjhBt9xyi/bZZ59uP7a1tVXLly/P9BIBAAAAwNFGjRql0tLEOwEd0RqaquLiYo0aNUqBQIDWOgAAAAB9jmVZCofDKi4uTurjch4Ea2pqVF9fr0gkEm8NbWhoUE1NTY8f6/V6k0q9AAAAAOA2ybSExuT8SLp+/fpp9OjRevbZZyVJzz77rEaPHt3j/kAAAAAAQGpyvkdQklasWKGrrrpKLS0tKisr05w5c7THHj3PngMAAAAAJM8RQRAAAAAAkD05bw0FAAAAAGQXQRAAAAAA+hiCIAAAAAD0MQRBAAAAAOhjCIIAAAAA0MfkfKB8qlatWqWrrrpKTU1Nqqio0Jw5czR8+PBcL6tPmzNnjl566SV98803euaZZzRq1ChJ3Cun2LRpk6644gp9/fXXysvL07BhwzRr1ixVVVVxjxzi/PPPV11dnbxer4qKivSb3/xGo0eP5v440F133aU777wz/rOOe+QcU6ZMUV5envLz8yVJl19+uQ477DDukUOEQiHddNNNevfdd5Wfn69x48bpxhtv5P44RF1dnS644IL4262trWpra9N7773HPXKI+fPn64477pBlWTJNU7/85S/1ne98J7X7Y/VSZ599tvXkk09almVZTz75pHX22WfneEVYtGiRtWbNGuuoo46yPvvss/jj3Ctn2LRpk7VgwYL42//zP/9jXX311ZZlcY+coqWlJf7/X3nlFWvGjBmWZXF/nKa2ttY655xzrCOPPDL+s4575Bzb/zcohnvkDDfeeKP1u9/9zjJN07Isy1q/fr1lWdwfp5o9e7Z1ww03WJbFPXIC0zStCRMmxH/GLVu2zBo3bpwViURSuj+9sjV0w4YN+uSTTzRt2jRJ0rRp0/TJJ59o48aNOV5Z3zZhwgTV1NRs8xj3yjkqKio0efLk+Nvjxo3TmjVruEcOUlpaGv//bW1t8ng83B+H6ezs1KxZszRz5kx5PB5J/JzrDbhHztDe3q4nn3xSF198cfz7p3///twfh+rs7NQzzzyjU045hXvkIF6vV62trZKiFdvq6mpt2rQppfvTK1tD165dq4EDB8rn80mSfD6fqqurtXbtWlVVVeV4ddga98qZTNPUww8/rClTpnCPHObaa6/V22+/Lcuy9Mc//pH74zB33HGHTjzxRA0dOjT+GPfIeS6//HJZlqXx48frV7/6FffIIVavXq2KigrdddddWrhwoYqLi3XxxReroKCA++NA8+bN08CBA7XPPvuotraWe+QAHo9Ht99+u84//3wVFRWpvb1d999/f8o/43plRRBAem688UYVFRXprLPOyvVSsJ3f/e53eu2113TppZfq5ptvzvVysJUlS5boo48+0plnnpnrpaAbDz30kJ5++mk99thjsixLs2bNyvWS0MUwDK1evVpjxozR448/rssvv1y//OUvtXnz5lwvDTvx2GOP6ZRTTsn1MrAVwzB0//3365577tH8+fN177336tJLL035e6hXBsGamhrV19crEolIkiKRiBoaGnZoS0Tuca+cZ86cOfrqq690++23y+v1co8casaMGVq4cKEGDRrE/XGIRYsWaeXKlTr66KM1ZcoUrVu3Tuecc46+/vpr7pGDxL7ueXl5OvPMM/XBBx/wc84hBg8eLL/fH29f23///VVZWamCggLuj8PU19dr0aJFmj59uiR+n3OKZcuWqaGhQePHj5ckjR8/XoWFhcrPz0/p/vTKINivXz+NHj1azz77rCTp2Wef1ejRoylNOxD3ylnmzp2r2tpa3X333crLy5PEPXKK9vZ2rV27Nv72vHnzVF5ezv1xkPPOO09vvfWW5s2bp3nz5mnQoEH605/+pBNOOIF75BCbN2+O752xLEvPP/+8Ro8ezfeRQ1RVVWny5Ml6++23JUVPFd+wYYOGDx/O/XGYJ554QkcccYQqKysl8buCUwwaNEjr1q3TypUrJUkrVqxQY2Ojhg0bltL98ViWZWV81RmwYsUKXXXVVWppaVFZWZnmzJmjPfbYI9fL6tNmz56tl19+WY2NjaqsrFRFRYWee+457pVDfP7555o2bZqGDx+ugoICSdKQIUN09913c48coLGxUeeff746Ojrk9XpVXl6uK6+8Uvvssw/3x6GmTJmi++67T6NGjeIeOcTq1av1y1/+UpFIRKZpauTIkbruuutUXV3NPXKI1atX65prrlFTU5P8fr8uueQSHXHEEdwfh5k6daquvfZaHX744fHHuEfO8PTTT+vBBx+MH7h00UUX6Zhjjknp/vTaIAgAAAAASE2vbA0FAAAAAKSOIAgAAAAAfQxBEAAAAAD6GIIgAAAAAPQxBEEAAAAA6GMIggAA2OyAAw7Q6tWrc70MAAB2iSAIAHCdKVOm6J133tHjjz+uM844I6OvdfbZZ+vRRx/d5rElS5Zo6NChGX1dAADSQRAEAGAXDMPI9RIAAMgIgiAAwJVWrFihmTNn6j//+Y8OOOAATZgwQZLU2dmpOXPm6Mgjj9S3v/1tXX/99QoGg5KkhQsX6vDDD9cDDzygQw45RFdffbWam5v185//XAcddJAmTpyon//851q3bp0kae7cuXr//fc1a9YsHXDAAZo1a5Ykaa+99tJXX30lSWptbdUVV1yhgw46SEcddZTuuecemaYpSfGK5Zw5czRx4kRNmTJFr7/+evxzePzxx3X00UfrgAMO0JQpU/T0009n7esHAHA3giAAwJVGjhypG264QePGjdOSJUv0/vvvS5JuueUWrVq1Sk8++aRefvllNTQ06O67745/XGNjo5qbmzV//nzdeOONMk1TJ598subPn6/58+crPz8/HvguvfRSTZgwQddff72WLFmi66+/fod13HjjjWptbdWrr76qv/3tb3rqqaf02GOPxd//4YcfasSIEVqwYIF+9rOf6dprr5VlWdq8ebNmz56tBx98UEuWLNEjjzyi0aNHZ/irBgDoKwiCAIA+w7IsPfroo7rmmmtUUVGhkpIS/fznP9dzzz0Xf47X69VFF12kvLw8FRQUqLKyUlOnTlVhYaFKSkr0i1/8QosWLUro9SKRiJ5//nlddtllKikp0ZAhQ/STn/xkm8re4MGDddppp8nn8+l73/ue1q9fr8bGxvhaPv/8cwWDQVVXV2vPPfe09wsCAOiz/LleAAAA2bJx40Z1dHTo5JNPjj9mWVa8VVOSKisrlZ+fH3+7o6NDv//97/Xmm2+qublZktTe3q5IJCKfz9ft623atEnhcFiDBw+OPzZ48GDV19fH3+7fv3/8/xcWFkqSNm/erAEDBmju3Ln685//rGuvvVYHHnigrrzySo0cOTLFzx4AgC0IggAA1/J4PNu8XVlZqYKCAj333HMaOHBgQh/z5z//WatWrdI///lPDRgwQMuWLdOMGTNkWVaPr19ZWalAIKA1a9boW9/6liRp7dq1u3zt7R122GE67LDDFAwGdfvtt+s3v/mN/vGPfyT0sQAAdIfWUACAa/Xr10/19fXq7OyUFG21/P73v6+bbrpJGzZskCTV19frzTff3OU12tvblZ+fr7KyMjU1Nemuu+7a5v39+/ff5cxAn8+n4447TnPnzlVbW5u++eYb/eUvf9GJJ57Y49obGxv173//W5s3b1ZeXp6Kiop6rEACAJAogiAAwLUOOuggfetb39Khhx6qyZMnS5J+/etfa9iwYTrttNN04IEH6sc//rFWrVq1y2v86Ec/UigU0kEHHaTTTz9dhx122Dbv/+EPf6iXXnpJEydO1OzZs3f4+N/85jcqLCzUMcccozPPPFPTpk3TKaec0uPaTdPUX/7yFx122GGaNGmSFi1apJkzZyb5FQAAYOc8ViK9LQAAAAAA16AiCAAAAAB9DEEQAAAAAPoYgiAAAAAA9DEEQQAAAADoYwiCAAAAANDHEAQBAAAAoI8hCAIAAABAH0MQBAAAAIA+5v8H5R7PAcYpoywAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LEGEND_LABELS = HYPERPARAMS_TO_OPTIMIZE.keys()\n",
    "\n",
    "vector = np.array(data).reshape(-1, 4)\n",
    "\n",
    "vector[:,1] = vector[:,1]/2\n",
    "vector[:,3] = vector[:,3]/100\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "    \n",
    "for i in range(0,3):\n",
    "    plt.plot(vector[:,i])\n",
    "\n",
    "    plt.ylabel('Factor')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.legend(LEGEND_LABELS)\n",
    "    plt.ylim(ymin=0, ymax=12)\n",
    "    plt.xlim(xmin=0, xmax=80)\n",
    "\n",
    "    plt.savefig('new.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2446f940-aa2e-4580-9e19-53b92378785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48115b98-c658-4031-bdb1-a0024703952a",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ea677-b0e1-43eb-9964-37dcb5c0241f",
   "metadata": {},
   "source": [
    "- [Bayesian Optimization with HYPEROPT](https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40166b8f-b982-4cb1-bc9f-989b297970ad",
   "metadata": {},
   "source": [
    "#### Carga hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "55470307-b090-4ba0-a615-b200b386b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not calculate_weights and city:\n",
    "\n",
    "    # FILE_NAME = f\"{city_name}_hyperparams{loaded_timestamp}.json\"\n",
    "    FILE_NAME = f\"{city_name}_hyperparams2022-12-26-10:43:48.json\"\n",
    "\n",
    "    best_hyperparams = load_json(f\"{HYPERPARAMS_PATH}{city_name}/\", FILE_NAME)\n",
    "\n",
    "# # # 0.875 GA\n",
    "# # # 0.04, 1, 3.9, 900\n",
    "# # # best_hyperparams = {}\n",
    "# # # best_hyperparams['eta'] = 0.04\n",
    "# # # best_hyperparams['max_depth'] = 1\n",
    "# # # best_hyperparams['min_child_weight'] = 3.9\n",
    "# # # best_hyperparams['n_estimators'] = 900"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1213fe-2a09-4686-8834-edc9ba60d2ea",
   "metadata": {},
   "source": [
    "#### Escritura hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9dad8965-a095-4b09-9cc3-915c4d2c5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_weights and city:\n",
    "    FILE_NAME = f\"{city_name}_hyperparams{MODEL_TIMESTAMP}.json\"\n",
    "\n",
    "    write_json(best_hyperparams, f\"{HYPERPARAMS_PATH}{city_name}/\", FILE_NAME)\n",
    "    print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e290436-2027-4bac-99c1-78870fd94419",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Pesos de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5c496-8106-4310-acb2-0b9b8dd5ecaf",
   "metadata": {},
   "source": [
    "#### Carga definitiva/auxiliar de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "69adbb52-3650-4cde-8322-032613a81f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_NAME = 'madrid_adapted_leeds_default_weights.json'\n",
    "# # FILE_NAME = 'madrid_weights_no_roadClass.json'\n",
    "FILE_NAME = f\"{city_name}_weights{loaded_timestamp}.json\"\n",
    "\n",
    "feature_vector = load_json(WEIGHTS_PATH, FILE_NAME)\n",
    "\n",
    "########## 17-05-2022 ##########\n",
    "# Se ha cambiado 1stRoadClass (distrito) a RoadwayFeatures --> EN LEEDS NO ES ASÍ, PERO PARA Mí TIENE SENTIDO\n",
    "# Se ha cambiado tipo accidente de RoadwayFeatures a Accident --> EN LEEDS NO EXISTE ESTE CAMPO, PERO PARA Mí TIENE SENTIDO\n",
    "# feature_vector = {'Accident Features': {'feature_childs': ['coordenada_x_utm',\n",
    "#    'coordenada_y_utm',\n",
    "#    'hora',\n",
    "#    'vehiculos_implicados',\n",
    "#    'tipo_accidente'],\n",
    "#   'feature_weights': ['0.03979435',\n",
    "#    '0.061120145',\n",
    "#    '0.02675103',\n",
    "#    '0.083673365',\n",
    "#    '0.03753465'],\n",
    "#   'wpi': 0.255731688},\n",
    "#  'Roadway Features': {'feature_childs': ['distrito', 'tipo_carretera'],\n",
    "#   'feature_weights': ['0.044392798', '9999.9'],\n",
    "#   'wpi': 0.03753465},\n",
    "#  'Environmental Features': {'feature_childs': ['estado_meteorológico'],\n",
    "#   'feature_weights': ['0.024665328'],\n",
    "#   'wpi': 0.024665328},\n",
    "#  'Vehicle Features': {'feature_childs': ['tipo_vehiculo'],\n",
    "#   'feature_weights': ['0.048645806'],\n",
    "#   'wpi': 0.048645806},\n",
    "#  'Casualty Features': {'feature_childs': ['tipo_persona',\n",
    "#    'sexo',\n",
    "#    'rango_edad',\n",
    "#    'drogas_alcohol_positivo'],\n",
    "#   'feature_weights': ['0.2764425', '0.2201619', '0.06879471', '0.03230864'],\n",
    "#   'wpi': 0.59770775}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a5b938-bfc9-4d1b-94e6-571720665d88",
   "metadata": {},
   "source": [
    "#### Cálculo de pesos de caracetrísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b174b40a-9c9c-45f0-b709-92ea5dba4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_weights and city:\n",
    "    best_hyperparams['max_depth'] =  int(best_hyperparams['max_depth'])\n",
    "\n",
    "    xgboost = XGBClassifier(**best_hyperparams,\n",
    "                            tree_method = tree_method,\n",
    "                            single_precision_histogram =  True)\n",
    "\n",
    "    xgboost.fit(X_train, Y_train_onehot)\n",
    "\n",
    "    child_weights  = np.array(xgboost.feature_importances_)\n",
    "    feature_vector = fill_feature_vector(X_train, child_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f6472-a98c-4801-b5cc-31d0f46c13a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Visualización pesos calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "72fc1536-1b5a-4d6a-922d-5f27f58e7396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if calculate_weights and city:\n",
    "    FILE_NAME = f\"{city_name}_figure_weights_{MODEL_TIMESTAMP}.svg\"\n",
    "\n",
    "    print(xgboost.get_booster().get_score(importance_type= 'weight'))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.barh(X_train_downsampled.columns, xgboost.feature_importances_)\n",
    "    plt.savefig(WEIGHTS_PATH + FILE_NAME)\n",
    "\n",
    "    print(xgboost.feature_importances_)\n",
    "\n",
    "    for column, weight in zip(X_train_downsampled.columns,xgboost.feature_importances_):\n",
    "      print(column, weight)\n",
    "\n",
    "    child_weights  = np.array(xgboost.feature_importances_)\n",
    "    feature_vector = fill_feature_vector(X_train_downsampled, child_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278163f-8450-412d-8147-c235f6825646",
   "metadata": {},
   "source": [
    "#### Escritura de pesos de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e3738-44ef-45be-9b24-989e4610267e",
   "metadata": {},
   "source": [
    "- v5: Pesos calculados con hiperparámetros. En el dataset están tipificados los vehículos como en el artículo, las edades no están en rango.\n",
    "- v6: Pesos calculados con hiperparámetros. En el dataset están tipificados los vehículos como en el artículo, las edades están en rango.\n",
    "- v7: hiperparams, tipos de carretera tipificados por vía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3a4d2414-bf56-4519-aaf2-ae6333e69b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_weights and madrid:\n",
    "    matrix_indexes = fv2gi(feature_vector)\n",
    "\n",
    "    FILE_NAME = f\"{city_name}_weights{MODEL_TIMESTAMP}.json\"\n",
    "    # FILE_NAME = 'default_calculated_weights.json'\n",
    "\n",
    "    write_json(feature_vector, WEIGHTS_PATH, FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e0996e0b-b416-49a6-b0e4-ebc3a7918519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accident Features': {'feature_childs': ['coordenada_x_utm',\n",
       "   'coordenada_y_utm',\n",
       "   'hora',\n",
       "   'vehiculos_implicados',\n",
       "   'tipo_accidente'],\n",
       "  'feature_weights': ['0.07309744',\n",
       "   '0.06612965',\n",
       "   '0.05654749',\n",
       "   '0.05320325',\n",
       "   '0.06486504'],\n",
       "  'wpi': 0.31384287},\n",
       " 'Roadway Features': {'feature_childs': ['distrito', 'tipo_carretera'],\n",
       "  'feature_weights': ['0.06432042', '0.11238464'],\n",
       "  'wpi': 0.17670506},\n",
       " 'Environmental Features': {'feature_childs': ['estado_meteorológico'],\n",
       "  'feature_weights': ['0.04548008'],\n",
       "  'wpi': 0.04548008},\n",
       " 'Vehicle Features': {'feature_childs': ['tipo_vehiculo'],\n",
       "  'feature_weights': ['0.06430976'],\n",
       "  'wpi': 0.06430976},\n",
       " 'Casualty Features': {'feature_childs': ['tipo_persona',\n",
       "   'sexo',\n",
       "   'rango_edad',\n",
       "   'drogas_alcohol_positivo'],\n",
       "  'feature_weights': ['0.16324219',\n",
       "   '0.124546245',\n",
       "   '0.055401582',\n",
       "   '0.05647216'],\n",
       "  'wpi': 0.399662177}}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc80de-39c3-4818-b7eb-8a406aeed4e2",
   "metadata": {},
   "source": [
    "### Cálculo índices de matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bd560eed-aa5b-47ad-a8fd-fb142a5d123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city:\n",
    "    matrix_indexes = fv2gi(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dR3Ah2X24fbw",
   "metadata": {
    "id": "dR3Ah2X24fbw"
   },
   "source": [
    "## Construcción de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cWGYQ82UI4RM",
   "metadata": {
    "id": "cWGYQ82UI4RM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1848\n",
      "1848\n",
      "462\n"
     ]
    }
   ],
   "source": [
    "if city:\n",
    "\n",
    "    train_bgi = build_gray_images(X_train, 5, matrix_indexes)\n",
    "    train_original_bgi = build_gray_images(X_train_original, 5, matrix_indexes)\n",
    "\n",
    "    # val_bgi  = build_gray_images(X_val, 5, matrix_indexes)\n",
    "    test_bgi = build_gray_images(X_test, 5, matrix_indexes)\n",
    "\n",
    "    pd.DataFrame(train_bgi[:,:,1057])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yQTCws554zZL",
   "metadata": {
    "id": "yQTCws554zZL"
   },
   "source": [
    "## Reshape de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "mRrOKk3a43ZI",
   "metadata": {
    "id": "mRrOKk3a43ZI"
   },
   "outputs": [],
   "source": [
    "if city:\n",
    "\n",
    "    train_images = shape_images(X_data = X_train,\n",
    "                            gray_images = train_bgi)\n",
    "\n",
    "    train_original_images = shape_images(X_data = X_train_original,\n",
    "                                         gray_images = train_original_bgi)\n",
    "\n",
    "    # val_images  = shape_images(X_data = X_val,\n",
    "    #                            gray_images = val_bgi)\n",
    "\n",
    "    test_images  = shape_images(X_data = X_test,\n",
    "                                gray_images = test_bgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2991a700-e8db-47f1-aeaf-847129f13355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9521/4098190660.py:7: MatplotlibDeprecationWarning: The 'b' parameter of grid() has been renamed 'visible' since Matplotlib 3.5; support for the old name will be dropped two minor releases later.\n",
      "  plt.grid(b=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if city:\n",
    "    \n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.gray()\n",
    "    for i in range(100,103):\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.grid(b=None)\n",
    "        plt.imshow(train_bgi[:,:,i])\n",
    "        # plt.savefig(f\"{city_name}_image_example_{i}.svg\",transparent=True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340bc47d-fbac-497e-9c4d-ffca135562dc",
   "metadata": {},
   "source": [
    "## C-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a38a8218-ecd2-45fc-b2b3-ce209e3406a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_channels = 1\n",
    "num_classes = 2\n",
    "image_size = 28\n",
    "latent_dim = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fec703cf-bb7d-447c-b6bb-7f06eb055ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = {\n",
    "    'Slight': 0,\n",
    "    'Assistance': 1\n",
    "}   \n",
    "\n",
    "Y_train_categorical = Y_train.replace(transf)\n",
    "Y_test_categorical = Y_test.replace(transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ac338214-c5a3-402b-9536-c7f7d722520b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (2310, 5, 5, 1)\n",
      "Shape of training labels: (2310, 2)\n"
     ]
    }
   ],
   "source": [
    "# We'll use all the available examples from both the training and test\n",
    "# sets.\n",
    "# (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "all_train = np.concatenate([train_images, test_images])\n",
    "all_labels = np.concatenate([Y_train_categorical, Y_test_categorical])\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_train = all_train.astype(\"float32\")\n",
    "all_train = np.reshape(all_train, (-1, 5, 5, 1))\n",
    "all_labels = keras.utils.to_categorical(all_labels, 2)\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_train, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_train.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "dd0c88ab-6bf2-4800-b92b-bc8319688283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 3\n",
      "Epoch 1/20\n",
      "Tensor(\"strided_slice_2:0\", shape=(5, 5, 1), dtype=float32)\n",
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=int32)\n",
      "128\n",
      "Tensor(\"concat:0\", shape=(None, 130), dtype=float32)\n",
      "Tensor(\"strided_slice_3:0\", shape=(28, 28, 1), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/luis/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/luis/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/luis/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/tmp/ipykernel_9521/2448864178.py\", line 54, in train_step\n        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n\n    ValueError: Dimension 1 in both shapes must be equal, but are 5 and 28. Shapes are [?,5,5] and [?,28,28]. for '{{node concat_2}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](IteratorGetNext, Reshape_1, concat_2/axis)' with input shapes: [?,5,5,1], [?,28,28,2], [] and with computed input tensors: input[2] = <-1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [239]\u001b[0m, in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m cond_gan \u001b[38;5;241m=\u001b[39m ConditionalGAN(\n\u001b[1;32m     43\u001b[0m     discriminator\u001b[38;5;241m=\u001b[39mdiscriminator, generator\u001b[38;5;241m=\u001b[39mgenerator, latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m cond_gan\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     47\u001b[0m     d_optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0003\u001b[39m),\n\u001b[1;32m     48\u001b[0m     g_optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0003\u001b[39m),\n\u001b[1;32m     49\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     50\u001b[0m )\n\u001b[0;32m---> 52\u001b[0m \u001b[43mcond_gan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filefw1crh08.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Input \u001b[0;32mIn [236]\u001b[0m, in \u001b[0;36mConditionalGAN.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_images[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     53\u001b[0m fake_image_and_labels \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([generated_images, image_one_hot_labels], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m real_image_and_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreal_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_one_hot_labels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m combined_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m     56\u001b[0m     [fake_image_and_labels, real_image_and_labels], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Assemble labels discriminating real from fake images.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/luis/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/luis/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/luis/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/tmp/ipykernel_9521/2448864178.py\", line 54, in train_step\n        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n\n    ValueError: Dimension 1 in both shapes must be equal, but are 5 and 28. Shapes are [?,5,5] and [?,28,28]. for '{{node concat_2}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](IteratorGetNext, Reshape_1, concat_2/axis)' with input shapes: [?,5,5,1], [?,28,28,2], [] and with computed input tensors: input[2] = <-1>.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)\n",
    "\n",
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((28, 28, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(7 * 7 * generator_in_channels),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, 7, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2d341-a847-437b-a1fb-0e40e01cced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images = shape_images(X_data = X_train,\n",
    "#                             gray_images = train_bgi)\n",
    "# test_images  = shape_images(X_data = X_test,\n",
    "#                             gray_images = test_bgi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IStgg--F5L3F",
   "metadata": {
    "id": "IStgg--F5L3F",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Visualización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rvyfvMPy5L3G",
   "metadata": {
    "id": "rvyfvMPy5L3G"
   },
   "outputs": [],
   "source": [
    "# !conda install -c anaconda seaborn --y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dg0d7-k15L3H",
   "metadata": {
    "id": "dg0d7-k15L3H",
    "tags": []
   },
   "source": [
    "### Matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89065a3-06a7-4270-b078-047e0746b214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SN7gwKNO5L3H",
   "metadata": {
    "id": "SN7gwKNO5L3H"
   },
   "outputs": [],
   "source": [
    "# data_frame = ['', '', '', '', 'Weather conditions', 'Vehicle']\n",
    "# correlation_matrix(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fAIUUg5L3J",
   "metadata": {
    "id": "d5fAIUUg5L3J",
    "tags": []
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lhQElB3I5L3J",
   "metadata": {
    "id": "lhQElB3I5L3J"
   },
   "outputs": [],
   "source": [
    "# pca(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ffbfe4-9fce-4e68-81b9-766d485b87ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b224d1-ca07-4099-b308-4708c2d533e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city:\n",
    "    n_samples = 150\n",
    "    index_slight  = Y_train[Y_train == 'Slight'][:n_samples].index\n",
    "    index_serious = Y_train[Y_train == 'Serious'][:n_samples].index\n",
    "    index_fatal   = Y_train[Y_train == 'Fatal'][:n_samples].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebce2f-081d-4e3e-901c-f23b7f3ecedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city:\n",
    "\n",
    "    # Get same number of class samples from SMOTEII\n",
    "    X_slight_train_tsne  = X_train.loc[index_slight]\n",
    "    X_serious_train_tsne = X_train.loc[index_serious]\n",
    "    X_fatal_train_tsne   = X_train.loc[index_fatal]\n",
    "\n",
    "    X_train_tsne = pd.concat([X_slight_train_tsne, X_serious_train_tsne, X_fatal_train_tsne])\n",
    "\n",
    "    Y_slight_train_tsne  = Y_train[index_slight]\n",
    "    Y_serious_train_tsne = Y_train[index_serious]\n",
    "    Y_fatal_train_tsne   = Y_train[index_fatal]\n",
    "\n",
    "    Y_train_tsne = pd.concat([Y_slight_train_tsne, Y_serious_train_tsne, Y_fatal_train_tsne])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878dd80-e602-4a9f-94c8-3608a8b2417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city:\n",
    "\n",
    "    n_samples = len(Y_train_original[Y_train_original == 'Fatal'])\n",
    "\n",
    "    index_slight  = Y_train_original[Y_train_original == 'Slight'][:n_samples].index\n",
    "    index_serious = Y_train_original[Y_train_original == 'Serious'][:n_samples].index\n",
    "    index_fatal   = Y_train_original[Y_train_original == 'Fatal'][:n_samples].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5563a-01fd-443b-9c39-d62f4e7067e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city:\n",
    "\n",
    "    # Get same number of class samples from original\n",
    "    X_slight_clean_tsne  = X_train_original.loc[index_slight]\n",
    "    X_serious_clean_tsne = X_train_original.loc[index_serious]\n",
    "    X_fatal_clean_tsne   = X_train_original.loc[index_fatal]\n",
    "\n",
    "    X_clean_tsne = pd.concat([X_slight_clean_tsne, X_serious_clean_tsne, X_fatal_clean_tsne])\n",
    "\n",
    "    Y_slight_clean_tsne  = Y_train_original[index_slight]\n",
    "    Y_serious_clean_tsne = Y_train_original[index_serious]\n",
    "    Y_fatal_clean_tsne   = Y_train_original[index_fatal]\n",
    "\n",
    "    Y_clean_tsne = pd.concat([Y_slight_clean_tsne, Y_serious_clean_tsne, Y_fatal_clean_tsne])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669feae-6b17-4f05-b43b-6d3aa87a1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tsne and city:\n",
    "    FILE_NAME = f\"{TSNE_PATH}{city_name}/2d_tsne_clean.svg\"\n",
    "    plot_TSNE(X_clean_tsne, Y_clean_tsne, n_components = 2, output_file_name = FILE_NAME, title = 'Muestras originales 2 Componentes')\n",
    "\n",
    "    FILE_NAME = f\"{TSNE_PATH}{city_name}/3d_tsne_clean.svg\"\n",
    "    plot_TSNE(X_clean_tsne, Y_clean_tsne, n_components = 3, output_file_name = FILE_NAME, title = 'Muestras originales 3 Componentes')\n",
    "\n",
    "    FILE_NAME = f\"{TSNE_PATH}{city_name}/2d_tsne_train.svg\"\n",
    "    plot_TSNE(X_train_tsne, Y_train_tsne, n_components = 2, output_file_name = FILE_NAME, title = 'Muestras SMOTE-II 2 Componentes')\n",
    "\n",
    "    FILE_NAME = f\"{TSNE_PATH}{city_name}/3d_tsne_train.svg\"\n",
    "    plot_TSNE(X_train_tsne, Y_train_tsne, n_components = 3, output_file_name = FILE_NAME, title = 'Muestras SMOTE-II 3 Componentes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XBbgOcIz5L3J",
   "metadata": {
    "id": "XBbgOcIz5L3J",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U84H7J695L3J",
   "metadata": {
    "id": "U84H7J695L3J",
    "tags": []
   },
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A2mJaZVn5L3L",
   "metadata": {
    "id": "A2mJaZVn5L3L"
   },
   "outputs": [],
   "source": [
    "# # input_img = Input(shape=(25,))\n",
    "\n",
    "# # # definimos el encoder, que tendra una entrada de Input_img y una segunda capa con entrada de encoder1 y salida 3\n",
    "# # encoder1 = layers.Dense(15, activation='sigmoid')(input_img)\n",
    "# # encoder2 = layers.Dense(3, activation='sigmoid')(encoder1)\n",
    "\n",
    "# # # definimos el  decoder que tendra una entrada inicial de encoder3 y una salida de 128 y finalmete una capa de salida con los mismos que Input_img\n",
    "# # decoder1 = layers.Dense(15, activation='sigmoid')(encoder2)\n",
    "# # decoder2 = layers.Dense(25, activation='sigmoid')(decoder1)\n",
    "\n",
    "# # # this model maps an input to its reconstruction\n",
    "# # autoencoder = tf.keras.Model(inputs=input_img, outputs=decoder2)\n",
    "# # autoencoder.summary()\n",
    "\n",
    "# # autoencoder.compile(optimizer='adam', loss='binary_crossentropy') #se usan estos dos en estas arquitecturas\n",
    "\n",
    "# X_train = array_train_images\n",
    "# X_test = array_test_images\n",
    "\n",
    "# X_train = X_train.reshape(len(array_train_images), 25)\n",
    "# X_test  = X_test.reshape(len(X_test), 25)\n",
    "\n",
    "# autoencoder.fit(X_train, X_train,\n",
    "#                 epochs=120,\n",
    "#                 batch_size=32,\n",
    "#                 shuffle=True,\n",
    "#                 validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gIiKplwP5L3L",
   "metadata": {
    "id": "gIiKplwP5L3L",
    "tags": []
   },
   "source": [
    "#### Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opBOyrIx5L3M",
   "metadata": {
    "id": "opBOyrIx5L3M"
   },
   "outputs": [],
   "source": [
    "# # create encoder model\n",
    "# encoder = tf.keras.Model(inputs=input_img, outputs=encoder2)\n",
    "# encoder.summary()\n",
    "# # create decoder model\n",
    "# encoded_input = Input(shape=(3,))\n",
    "# #lo que hace aqui es quedarse con las capas que corresponden al decodificador\n",
    "# decoder_layer1 = autoencoder.layers[-2]\n",
    "# decoder_layer2 = autoencoder.layers[-1]\n",
    "# decoder = tf.keras.Model(inputs=encoded_input, outputs=decoder_layer2(decoder_layer1(encoded_input)))\n",
    "# decoder.summary()\n",
    "# # si miramos la salida, son simetricos el uno respecto al otro\n",
    "# # encoder va de input a 3 y decoder de 3 a input\n",
    "\n",
    "# # get latent vector for visualization\n",
    "# latent_vector = encoder.predict(X_test)\n",
    "# # get decoder output to visualize reconstructed image\n",
    "# reconstructed_imgs = decoder.predict(latent_vector)\n",
    "\n",
    "\n",
    "# # visualize in 3D plot\n",
    "# from pylab import rcParams\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "# fig = plt.figure(1)\n",
    "# ax = Axes3D(fig)\n",
    "\n",
    "# xs = latent_vector[:, 0]\n",
    "# ys = latent_vector[:, 1]\n",
    "# zs = latent_vector[:, 2]\n",
    "\n",
    "# # color=['red','green','blue']\n",
    "\n",
    "# # for x, y, z, label in zip(xs, ys, zs, Y_test):\n",
    "# #     c = color[int(label)]\n",
    "# #     ax.text(x, y, z, label, backgroundcolor=c)\n",
    "    \n",
    "# # ax.set_xlim(xs.min(), xs.max())\n",
    "# # ax.set_ylim(ys.min(), ys.max())\n",
    "# # ax.set_zlim(zs.min(), zs.max())\n",
    "\n",
    "# # plt.show()\n",
    "\n",
    "# # X_test_encoded = encoder.predict(X_test, batch_size=32)\n",
    "# # plt.figure(figsize=(6, 6))\n",
    "# # plt.scatter(X_test_encoded[:, 0], X_test_encoded[:, 1], c=Y_test)\n",
    "# # plt.colorbar()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593cb648-7d62-47a7-975f-3d1c718c5a05",
   "metadata": {
    "id": "1PdwhQuQ9o_P"
   },
   "source": [
    "## One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6hTctKZSI3re",
   "metadata": {
    "id": "6hTctKZSI3re"
   },
   "outputs": [],
   "source": [
    "if city:\n",
    "    Y_train_onehot = casualty_to_one_hot(Y_train)\n",
    "    Y_train_original_onehot = casualty_to_one_hot(Y_train_original)\n",
    "    # Y_val_onehot   = casualty_to_one_hot(Y_val)\n",
    "    Y_test_onehot  = casualty_to_one_hot(Y_test)\n",
    "\n",
    "    array_train_images = np.asarray(train_images)\n",
    "    array_train_original_images = np.asarray(train_original_images)\n",
    "    # array_val_images   = np.asarray(val_images)\n",
    "    array_test_images  = np.asarray(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c478f583-9071-4aec-9bb6-b4f65db21bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if city:\n",
    "#     array_val_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea5149-aa36-4789-a693-169d65b3c5ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b94cf5a-3223-4b1d-8d5e-ca001ccc999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city:\n",
    "    array_train_images = np.asarray(train_images)\n",
    "    # array_val_images   = np.asarray(val_images)\n",
    "    array_test_images  = np.asarray(test_images)\n",
    "\n",
    "    input_train_shape = (len(array_train_images), 5, 5, 1)\n",
    "    # input_val_shape = (len(array_val_images), 5, 5, 1)\n",
    "    input_test_shape  = (len(array_test_images), 5, 5, 1)\n",
    "\n",
    "    array_train_images = array_train_images.reshape(input_train_shape)\n",
    "    # array_val_images   = array_val_images.reshape(input_val_shape)\n",
    "    array_test_images  = array_test_images.reshape(input_test_shape)\n",
    "\n",
    "    Y_test_labels = one_hot_to_casualty(Y_test)\n",
    "\n",
    "    from sklearn.utils import class_weight\n",
    "\n",
    "    pesos = class_weight.compute_class_weight('balanced',\n",
    "                                              classes = np.unique(Y_train_original),\n",
    "                                              y = Y_train_original)\n",
    "\n",
    "\n",
    "    print('\\nPesos calculados:', pesos, '\\n\\n')\n",
    "\n",
    "\n",
    "    # Keras espera un diccionario donde la clave sea el número de clase \n",
    "    # y el valor sea el peso calculado. \n",
    "    pesos = dict(enumerate(pesos))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079cfec-3bb9-4a49-8bb9-915a9f16c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "if city:\n",
    "\n",
    "    times = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370e813-f071-4ef1-8272-3da770c04bb8",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82f890-343d-436a-bbac-306316b12f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city:\n",
    "\n",
    "    MODEL_NAME = MODELS_NAME[3]\n",
    "\n",
    "    MODEL_PATH = f\"{MODELS_PATH}{MODEL_NAME}/\"\n",
    "    MODEL_FILE_NAME = f\"{city_name}_{MODEL_NAME}_{MODEL_TIMESTAMP}.joblib\"\n",
    "\n",
    "    sns.reset_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13057516-8157-433b-840f-69e6de7373e4",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac81c6b-220c-43f0-ba37-33b300083e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "if city and train_nn and other_models:\n",
    "    start = time.time()\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "    gnb = gnb.fit(X_train, Y_train)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    ellapsed_time = round(end - start, 2)\n",
    "\n",
    "    model_time = pd.DataFrame({'city': [city_name], 'model': [MODEL_NAME], 'time': [ellapsed_time]})\n",
    "    times = times.append(model_time)\n",
    "\n",
    "\n",
    "    print(f\"Done! {MODEL_NAME} in {ellapsed_time} (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d312b-5707-4d35-8af1-b40005708628",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Escritura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1cef99-7333-428c-9410-8d9d6260d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and train_nn and other_models:\n",
    "\n",
    "    dump(gnb, MODEL_PATH + MODEL_FILE_NAME) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a1e22a-8576-4b07-8383-e52967f19450",
   "metadata": {},
   "source": [
    "#### Carga de modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4d9bb-2f02-481f-8110-2875933772e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and not train_nn and other_models:\n",
    "\n",
    "    gnb = load(MODEL_PATH + MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ab5b8-02b9-4df7-b3fe-3d524f9ed53f",
   "metadata": {},
   "source": [
    "#### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c6827-d015-42c2-9ac9-9e7d8100368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and other_models:\n",
    "    print(\"[INFO] evaluating model...\")\n",
    "    if train_nn:\n",
    "        Y_train_predicted = gnb.predict(X_train)\n",
    "        save_classification_report_and_confussion_matrix(model_name = MODEL_NAME,\n",
    "                                                         model_timestamp = MODEL_TIMESTAMP,\n",
    "                                                         y_true = Y_train,\n",
    "                                                         y_predicted = Y_train_predicted,\n",
    "                                                         data = 'train')\n",
    "    Y_predicted = gnb.predict(X_test)\n",
    "\n",
    "    save_classification_report_and_confussion_matrix(model_name = MODEL_NAME,\n",
    "                                                     model_timestamp = MODEL_TIMESTAMP,\n",
    "                                                     y_true = Y_test,\n",
    "                                                     y_predicted = Y_predicted,\n",
    "                                                     data = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1431141-a1f7-482c-93df-8c58336641e9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f1b72-1393-4a93-9914-b8eef3ee03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "if city:\n",
    "\n",
    "    MODEL_PATH = f\"{MODELS_PATH}{MODEL_NAME}/\"\n",
    "    MODEL_FILE_NAME = f\"{city_name}_{MODEL_NAME}_{MODEL_TIMESTAMP}.joblib\"\n",
    "    MODEL_NAME = MODELS_NAME[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835cb07-a647-4f28-aa47-53eacd809311",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and train_nn and other_models:\n",
    "    start = time.time()\n",
    "\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    ellapsed_time = round(end - start, 2)\n",
    "\n",
    "\n",
    "    model_time = pd.DataFrame({'city': [city_name], 'model': [MODEL_NAME], 'time': [ellapsed_time]})\n",
    "    times = times.append(model_time)\n",
    "\n",
    "    print(f\"Done! {MODEL_NAME} in {ellapsed_time} (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d7cb10-252d-4f34-9831-fd34013a9a6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Escritura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830cecd0-a029-42a3-9381-10a04c74b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and train_nn and other_models:\n",
    "\n",
    "    dump(clf, MODEL_PATH + MODEL_FILE_NAME) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc2a75-c746-4736-b888-62a5e8d93182",
   "metadata": {},
   "source": [
    "#### Carga de modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58fd62-021d-482f-a95b-c1e2c036ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and not train_nn and other_models:\n",
    "    MODEL_FILE_NAME = f\"{city_name}_{MODEL_NAME}_{timestamp_load}.joblib\"\n",
    "\n",
    "    clf = load(MODEL_PATH + MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101b979-5f76-4f51-ab6d-31d933cb6ea8",
   "metadata": {},
   "source": [
    "#### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405c4c4-a5cf-4339-b991-79bfb145017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and other_models:\n",
    "    print(\"[INFO] evaluating model...\")\n",
    "\n",
    "    if train_nn:\n",
    "        Y_train_predicted = clf.predict(X_train)\n",
    "        save_classification_report_and_confussion_matrix(model_name = MODEL_NAME,\n",
    "                                                         model_timestamp = MODEL_TIMESTAMP,\n",
    "                                                         y_true = Y_train,\n",
    "                                                         y_predicted = Y_train_predicted,\n",
    "                                                         data = 'train')\n",
    "\n",
    "    Y_predicted = clf.predict(X_test)\n",
    "\n",
    "    save_classification_report_and_confussion_matrix(model_name = MODEL_NAME,\n",
    "                                                     model_timestamp = MODEL_TIMESTAMP,\n",
    "                                                     y_true = Y_test,\n",
    "                                                     y_predicted = Y_predicted,\n",
    "                                                     data = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a39c2-0589-4599-998e-624c3ae30fb9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd71172-ec16-4ad8-9911-61f119055c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "if city:\n",
    "\n",
    "    MODEL_NAME = MODELS_NAME[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a5324-8a19-4d7a-9936-0528fac6a38b",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96cccc3-659c-4d47-b610-4c9bc701b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and other_models:\n",
    "    knn = KNeighborsClassifier(leaf_size = 7, n_neighbors = 91)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    knn.fit(X_train, Y_train)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    ellapsed_time = round(end - start, 2)\n",
    "\n",
    "    model_time = pd.DataFrame({'city': [city_name], 'model': [MODEL_NAME], 'time': [ellapsed_time]})\n",
    "    times = times.append(model_time)\n",
    "\n",
    "# leaf_size = list(range(1,10, 2))\n",
    "# n_neighbors = list(range(1,100, 10))\n",
    "# p = [1, 2]\n",
    "\n",
    "# if city and train_nn and other_models:\n",
    "\n",
    "#     start = time.time()\n",
    "\n",
    "#     # Create new KNN object\n",
    "#     hyperparameters = dict(leaf_size = leaf_size,\n",
    "#                            n_neighbors = n_neighbors)\n",
    "\n",
    "#     # Use GridSearch\n",
    "#     knn_2 = KNeighborsClassifier(leaf_size = 7, n_neighbors = 91)\n",
    "\n",
    "#     # Fit the model\n",
    "#     clf = GridSearchCV(knn_2,\n",
    "#                        hyperparameters,\n",
    "#                        cv = 4)\n",
    "\n",
    "#     knn = clf.fit(X_train, Y_train)\n",
    "\n",
    "#     end = time.time()\n",
    "\n",
    "#     ellapsed_time = round(end - start, 2)\n",
    "\n",
    "\n",
    "#     model_time = pd.DataFrame({'city': [city_name], 'model': [MODEL_NAME], 'time': [ellapsed_time]})\n",
    "#     times = times.append(model_time)\n",
    "\n",
    "#     # Print The value of best Hyperparameters\n",
    "\n",
    "#     best_leaf_size  = knn.best_estimator_.get_params()['leaf_size']\n",
    "#     best_n_neighbors = knn.best_estimator_.get_params()['n_neighbors']\n",
    "\n",
    "#     print('Best leaf_size:', best_leaf_size)\n",
    "#     print('Best n_neighbors:', best_n_neighbors)\n",
    "\n",
    "#     df = pd.DataFrame({'best_leaf_size':[best_leaf_size], 'n_neighbors':[best_n_neighbors]})\n",
    "\n",
    "#     FILE_NAME = f\"{MODEL_NAME}/madrid_{MODEL_TIMESTAMP}.csv\"\n",
    "\n",
    "#     df.to_csv(HYPERPARAMS_PATH + FILE_NAME, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fdabd2-a01a-444b-b802-535186798bd3",
   "metadata": {},
   "source": [
    "#### Escritura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea7f92a-3c77-40c7-9d58-82b2d321e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if city and train_nn and other_models:\n",
    "\n",
    "#     MODEL_PATH = f\"{MODELS_PATH}{MODEL_NAME}/\"\n",
    "#     MODEL_FILE_NAME = f\"{city_name}_{MODEL_NAME}_{MODEL_TIMESTAMP}.joblib\"\n",
    "\n",
    "#     dump(knn, MODEL_PATH + MODEL_FILE_NAME) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf557e-fae2-429c-8409-7cbb3b48ae85",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Carga de modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d9fe88-06b2-47ec-9459-6d931c50ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if city and not train_nn and other_models:\n",
    "\n",
    "#     version = 'X'\n",
    "#     MODEL_PATH = f\"{MODELS_PATH}{MODEL_NAME}/\"\n",
    "#     MODEL_FILE_NAME = f\"{city_name}_{MODEL_NAME}_{model_version}.joblib\"\n",
    "\n",
    "#     knn = load(MODEL_PATH + MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e34364-1192-4115-9796-6b64d6790e73",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdf70a-df80-4dce-ad02-c658c8bc197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and other_models:\n",
    "    print(\"[INFO] evaluating model...\")\n",
    "\n",
    "    if train_nn:\n",
    "        Y_train_predicted = knn.predict(X_train)\n",
    "        save_classification_report_and_confussion_matrix(model_name = MODEL_NAME,\n",
    "                                                         model_timestamp = MODEL_TIMESTAMP,\n",
    "                                                         y_true = Y_train,\n",
    "                                                         y_predicted = Y_train_predicted,\n",
    "                                                         data = 'train')\n",
    "    Y_predicted = knn.predict(X_test)\n",
    "\n",
    "    save_classification_report_and_confussion_matrix(model_name = MODEL_NAME,\n",
    "                                                     model_timestamp = MODEL_TIMESTAMP,\n",
    "                                                     y_true = Y_test,\n",
    "                                                     y_predicted = Y_predicted,\n",
    "                                                     data = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d85ab2-3416-4f93-a44e-bad2c346c015",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Convolution 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc8277-f9e1-4e68-8337-ae9eb66a3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city:\n",
    "\n",
    "    MODEL_NAME = MODELS_NAME[1]\n",
    "\n",
    "    MODEL_PATH = f\"{MODELS_PATH}{MODEL_NAME}/\"\n",
    "    MODEL_FILE_NAME = f\"{city_name}_{MODEL_NAME}_{MODEL_TIMESTAMP}.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca013c7b-48ea-476a-b585-e8c751463f7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e59f2-4185-4de6-9cd7-fb26cd7b729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aca6bf-90b1-42bd-9fba-d7b8a5ad36c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if city and train_nn and cnn1d:\n",
    "    start = time.time()\n",
    "\n",
    "    history = convolution_1d.fit(array_train_images, Y_train_onehot,\n",
    "                                 # class_weight = pesos,\n",
    "                                 batch_size = 128,\n",
    "                                 epochs = 100,\n",
    "                                 shuffle = True,\n",
    "                                 validation_data = (array_test_images, Y_test_onehot))\n",
    "    end = time.time()\n",
    "\n",
    "    ellapsed_time = round(end - start, 2)\n",
    "\n",
    "    model_time = pd.DataFrame({'city': [city_name],\n",
    "                               'model': [MODEL_NAME],\n",
    "                               'time': [ellapsed_time]})\n",
    "\n",
    "    times = times.append(model_time)\n",
    "\n",
    "    history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f2da5-5e07-4244-8e64-5d70a28aed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model_time = pd.DataFrame({'city': [city_name],\n",
    "                               'model': [MODEL_NAME],\n",
    "                               'time': 0})\n",
    "    times = times.append(model_time)\n",
    "    # wrap our model into a scikit-learn compatible classifier\n",
    "    print(\"[INFO] initializing model...\")\n",
    "    model = KerasClassifier(build_fn=get_1d_conv, verbose=10)\n",
    "\n",
    "    # define a grid of the hyperparameter search space\n",
    "\n",
    "    # fm_one = fm_two = fm_three = fm_four = fm_five = fm_six = [32, 64, 128, 256, 512]\n",
    "    fm_one = fm_two = fm_three = fm_four = [32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "    dense  = [32, 64, 128, 256]\n",
    "\n",
    "    learnRate = [0.1, 1e-2, 1e-3, 1e-4]\n",
    "\n",
    "    batchSize = [32, 64]\n",
    "\n",
    "    epochs = [1]\n",
    "\n",
    "    # create a dictionary from the hyperparameter grid\n",
    "    grid = dict(\n",
    "        fm_one = fm_one,\n",
    "        fm_two = fm_two,\n",
    "        fm_three = fm_three,\n",
    "        fm_four = fm_four,\n",
    "        # fm_five = fm_five,\n",
    "        # fm_six = fm_six,\n",
    "        dense = dense,\n",
    "        learnRate=learnRate,\n",
    "        batch_size=batchSize,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    # initialize a random search with a 3-fold cross-validation and then\n",
    "    # start the hyperparameter search process\n",
    "    print(\"[INFO] performing random search...\")\n",
    "    searcher = RandomizedSearchCV(estimator = model,\n",
    "                                  n_iter = 1,\n",
    "                                  cv = 2,\n",
    "                                  param_distributions = grid,\n",
    "                                  scoring = 'f1_micro')\n",
    "\n",
    "    searchResults = searcher.fit(array_train_images, Y_train)\n",
    "\n",
    "    # summarize grid search information\n",
    "    bestScore = searchResults.best_score_\n",
    "    bestParams = searchResults.best_params_\n",
    "\n",
    "    print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,\tbestParams))\n",
    "\n",
    "    print(\"[INFO] evaluating the best model...\")\n",
    "    taspcnn = bestModel = searchResults.best_estimator_\n",
    "    # accuracy = bestModel.score(array_test_images, Y_test)\n",
    "    # print(\"accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "    text_file = open(f\"./CNN2D-{MODEL_TIMESTAMP}.txt\", \"w\")\n",
    "    n = text_file.write(str(searchResults.cv_results_))\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57162dc6-95aa-4c54-88c7-9773e537479e",
   "metadata": {},
   "source": [
    "#### Escritura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c587c-a817-4892-8bc7-64200abf4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if city and train_nn and cnn1d:\n",
    "\n",
    "#     convolution_1d.save(MODEL_PATH + MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12a2f07-c130-41aa-88fe-677b9c10ddd8",
   "metadata": {},
   "source": [
    "#### Carga de modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b1f493-056a-4491-84c1-c62bae69551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and not train_nn and not laptop and cnn1d:\n",
    "    # MODEL_FILE_NAME = f\"{city_name}_{MODEL_NAME}_{timestamp_load}.joblib\"\n",
    "    MODEL_FILE_NAME = 'madrid_convolution_1d_2022-05-19-06:33:55.h5'\n",
    "\n",
    "    convolution_1d = tf.keras.models.load_model(MODEL_PATH + MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278dca3-abde-4aa5-8c59-42ccd1ee423a",
   "metadata": {},
   "source": [
    "#### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d8dac-a50d-454a-8f35-8d0a77292181",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and not laptop and cnn1d:\n",
    "\n",
    "    print(\"[INFO] evaluating network...\")\n",
    "\n",
    "    Y_predicted = convolution_1d.predict(x = array_test_images, batch_size = 128).argmax(axis = 1)\n",
    "\n",
    "    if train_nn:\n",
    "        F1_SCORE_PATH = f\"{F1_SCORES_PATH}{MODEL_NAME}/\"\n",
    "        F1_SCORE_NAME = f\"{city_name}_{MODEL_NAME}_f1_score_{MODEL_TIMESTAMP}.svg\"\n",
    "\n",
    "        plot_f1_score_history(f1_score_path = F1_SCORE_PATH,\n",
    "                              f1_score_name = F1_SCORE_NAME,\n",
    "                              history = history)\n",
    "\n",
    "        Y_train_predicted = convolution_1d.predict(x = array_train_images, batch_size = 128).argmax(axis = 1)\n",
    "\n",
    "        save_classification_report_and_confussion_matrix(model_name = MODEL_NAME,\n",
    "                                                         model_timestamp = MODEL_TIMESTAMP,\n",
    "                                                         y_true = Y_train,\n",
    "                                                         y_predicted = Y_train_predicted,\n",
    "                                                         data = 'train')\n",
    "\n",
    "    save_classification_report_and_confussion_matrix(model_name = MODEL_NAME,\n",
    "                                                     model_timestamp = MODEL_TIMESTAMP,\n",
    "                                                     y_true = Y_test,\n",
    "                                                     y_predicted = Y_predicted,\n",
    "                                                     data = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PohCQRSm67P0",
   "metadata": {
    "id": "PohCQRSm67P0",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Convolution 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a48c3-e0a7-4a93-ab64-901503503e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city:\n",
    "\n",
    "    MODEL_NAME = MODELS_NAME[2]\n",
    "\n",
    "    MODEL_PATH = f\"{MODELS_PATH}{MODEL_NAME}/\"\n",
    "    MODEL_FILE_NAME = 'madrid_convolution_2d_2022-05-19-06:33:55.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vPh1ixx-67P2",
   "metadata": {
    "id": "vPh1ixx-67P2"
   },
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b-rJTSQC67P2",
   "metadata": {
    "id": "b-rJTSQC67P2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if city and train_nn:\n",
    "    \n",
    "    fm_one, fm_two, fm_three, fm_four = (256, 512, 512, 256)\n",
    "\n",
    "    dense  = 128\n",
    "\n",
    "    learnRate = 0.0001\n",
    "\n",
    "    batchSize = 32\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    tasp_cnn = get_tasp_cnn(fm_one = fm_one,\n",
    "                            fm_two = fm_two,\n",
    "                            fm_three = fm_three,\n",
    "                            fm_four = fm_four,\n",
    "                            dense = dense,\n",
    "                            dropout = 0.1,\n",
    "                            learnRate = learnRate)\n",
    "\n",
    "    history = tasp_cnn.fit(array_train_images, Y_train_onehot,\n",
    "                           # class_weight = pesos,\n",
    "                           batch_size = batchSize,\n",
    "                           epochs = 500,\n",
    "                           shuffle = True,\n",
    "                           validation_data = (array_test_images, Y_test_onehot))\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    ellapsed_time = round(end - start, 2)\n",
    "\n",
    "    model_time = pd.DataFrame({'city': [city_name],\n",
    "                               'model': [MODEL_NAME],\n",
    "                               'time': [ellapsed_time]})\n",
    "    times = times.append(model_time)    \n",
    "\n",
    "    history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d19f33-9636-459c-a511-0a4ddcdde665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "model_time = pd.DataFrame({'city': [city_name],\n",
    "                           'model': [MODEL_NAME],\n",
    "                           'time': 0})\n",
    "times = times.append(model_time)\n",
    "# wrap our model into a scikit-learn compatible classifier\n",
    "print(\"[INFO] initializing model...\")\n",
    "model = KerasClassifier(build_fn=get_tasp_cnn, verbose=10)\n",
    "\n",
    "# define a grid of the hyperparameter search space\n",
    "\n",
    "# fm_one = fm_two = fm_three = fm_four = fm_five = fm_six = [32, 64, 128, 256, 512]\n",
    "fm_one = fm_two = fm_three = fm_four = [32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "dense  = [32, 64, 128, 256]\n",
    "\n",
    "learnRate = [0.1, 1e-2, 1e-3, 1e-4]\n",
    "\n",
    "batchSize = [32, 64, 128]\n",
    "\n",
    "epochs = [1]\n",
    "\n",
    "# create a dictionary from the hyperparameter grid\n",
    "grid = dict(\n",
    "\tfm_one = fm_one,\n",
    "    fm_two = fm_two,\n",
    "    fm_three = fm_three,\n",
    "    fm_four = fm_four,\n",
    "    # fm_five = fm_five,\n",
    "    # fm_six = fm_six,\n",
    "    dense = dense,\n",
    "\tlearnRate=learnRate,\n",
    "\tbatch_size=batchSize,\n",
    "\tepochs=epochs\n",
    ")\n",
    "\n",
    "# initialize a random search with a 3-fold cross-validation and then\n",
    "# start the hyperparameter search process\n",
    "print(\"[INFO] performing random search...\")\n",
    "searcher = RandomizedSearchCV(estimator = model,\n",
    "                              n_iter = 1,\n",
    "                              cv = 1,\n",
    "                              param_distributions = grid,\n",
    "                              scoring = 'f1_micro')\n",
    "\n",
    "searchResults = searcher.fit(array_train_images, Y_train)\n",
    "\n",
    "# summarize grid search information\n",
    "bestScore = searchResults.best_score_\n",
    "bestParams = searchResults.best_params_\n",
    "\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,\tbestParams))\n",
    "\n",
    "print(\"[INFO] evaluating the best model...\")\n",
    "tasp_cnn = bestModel = searchResults.best_estimator_\n",
    "# accuracy = bestModel.score(array_test_images, Y_test)\n",
    "# print(\"accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "text_file = open(f\"./madrid-CNN2D-{MODEL_TIMESTAMP}.txt\", \"w\")\n",
    "n = text_file.write(str(searchResults.cv_results_))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dca0f9-336a-4113-b58c-1fb300c89608",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Escritura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aac281b-8364-4710-b6e1-d75ae4a401d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city and train_nn:\n",
    "    MODEL_PATH = f\"{MODELS_PATH}{MODEL_NAME}/\"\n",
    "    MODEL_FILE_NAME = f\"{city_name}_{MODEL_NAME}_{MODEL_TIMESTAMP}_1.h5\"\n",
    "\n",
    "    tasp_cnn.save(MODEL_PATH + MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aT8XDceKGSdi",
   "metadata": {
    "id": "aT8XDceKGSdi",
    "tags": []
   },
   "source": [
    "#### Carga de modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dRaqg9SXGRwb",
   "metadata": {
    "id": "dRaqg9SXGRwb"
   },
   "outputs": [],
   "source": [
    "if city and not train_nn and not laptop:\n",
    "    # MODEL_FILE_NAME = f\"{city_name}_{MODEL_NAME}_{timestamp_load}.joblib\"\n",
    "    MODEL_FILE_NAME = 'madrid_convolution_2d_2022-05-18-19:50:16.h5'\n",
    "\n",
    "    tasp_cnn = tf.keras.models.load_model(MODEL_PATH + MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29ab0f-d59b-4646-98af-d26e1b1398dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Exportar los kernels\n",
    "\n",
    "# n_samples = 3\n",
    "# layers = [0, 2, 4, 6]\n",
    "\n",
    "# for layer_number in layers:\n",
    "#     filters, biases = tasp_cnn.layers[layer_number].get_weights()\n",
    "    \n",
    "#     layer_name = layer_number//2 + 1\n",
    "\n",
    "#     for i in range(n_samples):\n",
    "#         # X,Y, channel, filter_number\n",
    "#         current_filter = filters[:,:,0, i]\n",
    "\n",
    "#         plt.figure(figsize=(3, 3))\n",
    "#         plt.grid(b = None)\n",
    "#         plt.imshow(current_filter, cmap='gray')\n",
    "\n",
    "#         # plt.savefig(f\"filters/{city_name}_filter_layer_{layer_name}_{i}.svg\", transparent=True)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69cd710-082b-4800-a989-8b24142de759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import tf.keras.mo.Model\n",
    "# tasp_cnn_feature_maps = tf.keras.models.Model(inputs = tasp_cnn.inputs, outputs=tasp_cnn.layers[0].output)\n",
    "\n",
    "# tasp_cnn_feature_maps.predict(array_train_images[:3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17830ff4-9577-4f72-bd97-943844300fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_maps = tasp_cnn.predict(array_train_images)\n",
    "# # plot all 64 maps in an 8x8 squares\n",
    "# square = 5\n",
    "# ix = 1\n",
    "# for _ in range(square):\n",
    "#     for _ in range(square):\n",
    "#         # specify subplot and turn of axis\n",
    "\n",
    "#         # plot filter channel in grayscale\n",
    "#         plt.imshow(tasp_cnn_feature_maps[ix-1,:,:,:], cmap='gray')\n",
    "#         ix += 1\n",
    "# # show the figure\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wD_BOwcwGb4W",
   "metadata": {
    "id": "wD_BOwcwGb4W"
   },
   "source": [
    "#### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nHVVq0khGato",
   "metadata": {
    "id": "nHVVq0khGato",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if city and not laptop:\n",
    "\n",
    "    print(\"[INFO] evaluating network...\")\n",
    "\n",
    "    Y_predicted = tasp_cnn.predict(x = array_test_images, batch_size = 128).argmax(axis = 1)\n",
    "    rep = {'Slight': 0, 'Assistance': 1}\n",
    "    Y_train.replace(rep, inplace=True)\n",
    "    Y_test.replace(rep, inplace=True)\n",
    "\n",
    "    if train_nn:\n",
    "        F1_SCORE_PATH = f\"{F1_SCORES_PATH}{MODEL_NAME}/\"\n",
    "        F1_SCORE_NAME = f\"{city_name}_{MODEL_NAME}_f1_score_{MODEL_TIMESTAMP}_1.svg\"\n",
    "\n",
    "        plot_f1_score_history(f1_score_path = F1_SCORE_PATH,\n",
    "                              f1_score_name = F1_SCORE_NAME,\n",
    "                              history = history)\n",
    "\n",
    "        Y_train_predicted = tasp_cnn.predict(x = array_train_images, batch_size = 128).argmax(axis = 1)\n",
    "\n",
    "        save_classification_report_and_confussion_matrix(model_name = MODEL_NAME,\n",
    "                                                         model_timestamp = MODEL_TIMESTAMP,\n",
    "                                                         y_true = Y_train,\n",
    "                                                         y_predicted = Y_train_predicted,\n",
    "                                                         data = 'train')\n",
    "\n",
    "    save_classification_report_and_confussion_matrix(model_name = MODEL_NAME,\n",
    "                                                     model_timestamp = MODEL_TIMESTAMP,\n",
    "                                                     y_true = Y_test,\n",
    "                                                     y_predicted = Y_predicted,\n",
    "                                                     data = 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24be139-d394-439a-ad3a-91c026d98fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bdd334-024d-4846-b9bf-018e09a432dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a557fd15-2eb8-497f-bd7e-34e8fc596449",
   "metadata": {},
   "source": [
    "## AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6d7a4-039c-452e-bc4c-78c5199996c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = MODELS_NAME[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DoJbgcgC1d83",
   "metadata": {
    "id": "DoJbgcgC1d83",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tasp_cnn.save(root_path + 'madrid_model_XGBOOST_predicted.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b65f8d-ba77-42e8-850a-d4b8b5135641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autokeras as ak\n",
    "\n",
    "# # clf = ak.ImageClassifier(num_classes = 3,\n",
    "# #                          loss='categorical_crossentropy',\n",
    "# #                          metrics = [tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold = 0.1)],\n",
    "# #                          overwrite = True,\n",
    "# #                          tuner= 'bayesian',\n",
    "# #                          max_trials = 20,\n",
    "# #                          max_model_size = 3000000\n",
    "# #                         )\n",
    "# clf = ak.StructuredDataClassifier(num_classes = 3,\n",
    "#                              loss='categorical_crossentropy',\n",
    "#                              metrics = [tfa.metrics.F1Score(num_classes = num_classes, average='micro', threshold = 0.1)],\n",
    "#                              overwrite = True,\n",
    "#                              tuner= 'bayesian',\n",
    "#                              max_trials = 20\n",
    "#                         )\n",
    "\n",
    "# clf.fit(array_train_images,\n",
    "#         np.asarray(Y_train),\n",
    "#         epochs = 100,\n",
    "#         batch_size = 128,\n",
    "#         validation_data = (array_test_images, np.asarray(Y_test)))\n",
    "\n",
    "# best_auto_model = clf.export_model()\n",
    "# print(best_auto_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885bbb5c-e78f-426b-bdac-c679f9ee671c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Escritura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61062eb-31de-4166-8855-98f5b9277758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_PATH = f\"{MODELS_PATH}{MODEL_NAME}/\"\n",
    "# MODEL_FILE_NAME = f\"{city_name}_{MODEL_NAME}_{MODEL_TIMESTAMP}.h5\"\n",
    "\n",
    "# best_auto_model.save(MODEL_PATH + MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf8663f-213d-4010-9195-6ad9cbc9c9e1",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4216cee8-ff56-498d-98db-112eb635c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_predicted = best_auto_model.predict(x = array_test_images, batch_size = 128).argmax(axis = 1)\n",
    "\n",
    "# F1_SCORE_PATH = f\"{F1_SCORES_PATH}{MODEL_NAME}/\"\n",
    "# F1_SCORE_NAME = f\"{city_name}_{MODEL_NAME}_f1_score_{MODEL_TIMESTAMP}.svg\"\n",
    "\n",
    "# # plot_f1_score(f1_score_path = F1_SCORE_PATH,\n",
    "# #               f1_score_name = F1_SCORE_NAME,\n",
    "# #               history = history)\n",
    "\n",
    "# print(\"[INFO] evaluating network...\")\n",
    "\n",
    "# REPORT_PATH = f\"{REPORTS_PATH}{MODEL_NAME}/\"\n",
    "# REPORT_NAME  = f\"{city_name}_{MODEL_NAME}_report_{MODEL_TIMESTAMP}.csv\"\n",
    "\n",
    "# plot_classification_report(path = REPORT_PATH,\n",
    "#                            file_name = REPORT_NAME,\n",
    "#                            y_true = Y_test,\n",
    "#                            y_predicted = Y_predicted)\n",
    "\n",
    "\n",
    "# CONFUSION_MATRIX_PATH = f\"{CONFUSIONS_MATRIX_PATH}{MODEL_NAME}/\"\n",
    "# CONFUSION_MATRIX_NAME  = f\"{city_name}_{MODEL_NAME}_confusion_matrix_{MODEL_TIMESTAMP}.svg\"\n",
    "\n",
    "# plot_confusion_matrix(path = CONFUSION_MATRIX_PATH,\n",
    "#                       file_name = CONFUSION_MATRIX_NAME,\n",
    "#                       y_true = Y_test,\n",
    "#                       y_predicted = Y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe2ca4-bce3-4c90-9bc8-19752de1b923",
   "metadata": {},
   "source": [
    "## AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02492821-6fb2-497f-a9c0-f4a2ea2764c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = MODELS_NAME[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c44a9-dfca-4de5-a9c3-413d7ef4ab51",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Data Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28db0f9-8fdd-4900-9e53-af0f0bb12f0a",
   "metadata": {},
   "source": [
    "## Models times plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0299b-0261-43d6-9227-89be76889b77",
   "metadata": {},
   "source": [
    "### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa79304-4111-4c44-8578-ecbd30daef2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "times = times.sort_values('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ecd0c3-4678-46e6-a7c5-669ded20e4a3",
   "metadata": {},
   "source": [
    "### Save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd871a3-23bc-4efb-a3fa-8f87d9129f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = f\"{REPORTS_TIMES_PATH}{MODEL_TIMESTAMP}.csv\"\n",
    "times.to_csv(SAVE_PATH, index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8660de1-1623-450b-9179-6cfc87fab725",
   "metadata": {},
   "source": [
    "### Save fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72551f93-ced6-4c0f-bedf-73d1205fd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD_PATH = f\"{REPORTS_TIMES_PATH}2022-05-23-15:28:04.csv\"\n",
    "# times = pd.read_csv(LOAD_PATH)\n",
    "\n",
    "# ax = sns.barplot(x = 'time',\n",
    "#                  y = 'model',\n",
    "#                  palette='deep',\n",
    "#                  data = times).set(title = f\"Models Fitting Time (s)\")\n",
    "# plt.xlabel(\"Time (s)\")\n",
    "\n",
    "# SAVE_PATH = f\"{REPORTS_TIMES_PATH}{MODEL_TIMESTAMP}.png\"\n",
    "# plt.savefig(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d5612e-df65-4d90-bf1d-b34f624c4c98",
   "metadata": {},
   "source": [
    "## Models metrics file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60314a42-8590-48e1-9d87-9f41859c01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n",
    "reports_summary = pd.DataFrame()\n",
    "\n",
    "cities = []\n",
    "# MODEL_TIMESTAMP = '2022-08-02-10:10:19'\n",
    "\n",
    "cities.append('leeds')  if leeds else None\n",
    "cities.append('madrid') if madrid else None\n",
    "cities.append('UK') if UK else None\n",
    "\n",
    "models_renaming = {'knn': 'KNN',\n",
    "                   'convolution_1d': '1D-convolution',\n",
    "                   'convolution_2d': '2D-convolution',\n",
    "                   'nb': 'NB',\n",
    "                   'svc': 'SVC'}\n",
    "                   # 'auto_ml': 'AutoML'}\n",
    "\n",
    "splits = ['train', 'test']\n",
    "sorted_by_time_models_name = times.model\n",
    "\n",
    "for split in splits:\n",
    "    reports_summary = pd.DataFrame()\n",
    "\n",
    "    for model_name in sorted_by_time_models_name:\n",
    "\n",
    "        REPORT_PATH = f\"{REPORTS_PATH}{model_name}/{split}/\"\n",
    "\n",
    "        for city_name in cities:\n",
    "\n",
    "            REPORT_NAME  = f\"{city_name}_{model_name}_report_{MODEL_TIMESTAMP}.csv\"\n",
    "\n",
    "            if exists(REPORT_PATH + REPORT_NAME):\n",
    "                print(f\"Found: {model_name} for {split}\")\n",
    "                report = pd.read_csv(REPORT_PATH + REPORT_NAME, index_col=[0])\n",
    "                report.insert(0, 'split', split)\n",
    "                report.insert(1, 'city', city_name)\n",
    "                report.insert(2, 'model', models_renaming[model_name])\n",
    "\n",
    "                reports_summary = pd.concat([reports_summary, report])\n",
    "\n",
    "                reports_summary = reports_summary.sort_values(['city', 'model'], ascending = [True, True])\n",
    "\n",
    "    if not reports_summary.empty:\n",
    "        c_m = reports_summary['city'] + '_' + reports_summary['model']\n",
    "        reports_summary.insert(0, 'c_m', c_m)\n",
    "\n",
    "        SAVE_PATH =  f\"{REPORTS_SUMMARY_PATH}/{split}/{MODEL_TIMESTAMP}.csv\"\n",
    "\n",
    "        reports_summary.insert(0, 'accident_type', reports_summary.index)\n",
    "        reports_summary.to_csv(SAVE_PATH, index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee8508-988e-41c1-b1fa-53c45e6fea55",
   "metadata": {},
   "source": [
    "## Models scores plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5de0ef-2c61-42fb-886d-cabe6c9bb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "MEASURE_TYPES  = ['precision', 'recall', 'f1-score']\n",
    "# ACCIDENT_TYPES = ['Slight', 'Serious', 'Fatal']\n",
    "\n",
    "ACCIDENT_TYPES = ['Slight', 'Serious', 'Fatal']\n",
    "\n",
    "\n",
    "if leeds:\n",
    "    leeds_reports_summary  = reports_summary[reports_summary['city'] == 'leeds']\n",
    "if madrid:\n",
    "    madrid_reports_summary = reports_summary[reports_summary['city'] == 'madrid']\n",
    "if UK:\n",
    "    UK_reports_summary = reports_summary[reports_summary['city'] == 'UK']\n",
    "\n",
    "# print(leeds_reports_summary.loc[ACCIDENT_TYPES])\n",
    "\n",
    "for split in splits:\n",
    "    \n",
    "    REPORT_PATH = f\"{REPORTS_SUMMARY_PATH}{split}/{MODEL_TIMESTAMP}.csv\"\n",
    "\n",
    "    if exists(REPORT_PATH):\n",
    "        fig, axs = plt.subplots(len(MEASURE_TYPES), len(cities), figsize=(15,20))\n",
    "\n",
    "        print(f\"Found: {REPORT_PATH}\")\n",
    "\n",
    "        report = pd.read_csv(REPORT_PATH, index_col=[0])\n",
    "\n",
    "        if leeds:\n",
    "            leeds_reports_summary  = report[report['city'] == 'leeds']\n",
    "        if madrid:\n",
    "            madrid_reports_summary = report[report['city'] == 'madrid']\n",
    "        if UK:\n",
    "            UK_reports_summary = report[report['city'] == 'UK']\n",
    "\n",
    "        for index, measure_type in enumerate(MEASURE_TYPES):\n",
    "\n",
    "            # Si son dos ciudades el plot es bidimensional.\n",
    "            if len(cities) > 1:\n",
    "                axis_leeds = axs[index, 0]\n",
    "                axis_madrid = axs[index, 1]\n",
    "            else:\n",
    "                axis_leeds = axis_madrid = axis_UK = axs[index]\n",
    "\n",
    "            if leeds:\n",
    "                ax = sns.barplot(x = 'accident_type',\n",
    "                                 y = measure_type,\n",
    "                                 hue = 'model',\n",
    "                                 palette = 'deep',\n",
    "                                 data = leeds_reports_summary.loc[ACCIDENT_TYPES],\n",
    "                                 ax = axis_leeds).set(title = f\"{measure_type} Leeds\")\n",
    "                \n",
    "\n",
    "            if madrid:\n",
    "                ax = sns.barplot(x = 'accident_type',\n",
    "                                 y = measure_type,\n",
    "                                 hue = 'model',\n",
    "                                 palette = 'deep',\n",
    "                                 data = madrid_reports_summary.loc[ACCIDENT_TYPES],\n",
    "                                 ax = axis_madrid).set(title = f\"{measure_type} Madrid\")\n",
    "            \n",
    "            if UK:\n",
    "                ax = sns.barplot(x = 'accident_type',\n",
    "                                 y = measure_type,\n",
    "                                 hue = 'model',\n",
    "                                 palette = 'deep',\n",
    "                                 data = UK_reports_summary.loc[ACCIDENT_TYPES],\n",
    "                                 ax = axis_UK).set(title = f\"{measure_type} UK\")                \n",
    "\n",
    "        SAVE_PATH = f\"{REPORTS_SUMMARY_PATH}{split}/{MODEL_TIMESTAMP}.png\"\n",
    "\n",
    "        fig = fig.get_figure()\n",
    "        fig.savefig(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13321220-f5d7-4a0a-aee7-75e16bfa0226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0790f1e-f6d3-433c-89db-aca64f59c5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "V7Azjtl8gRth",
    "qKYh5EeThQ_7",
    "kISRP5AQhWTD",
    "cCo2emMclT8h",
    "gJfbDNO5oB1N",
    "7a4EsWwQhe_i",
    "ycdOBuHSjhSk",
    "5PmJpoCCcxMJ",
    "ybjvOI7x0PKz",
    "pVPFGQ0AoNRD",
    "_Z4nz3ioxtXb",
    "dg0d7-k15L3H",
    "d5fAIUUg5L3J"
   ],
   "name": "TFM_final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
