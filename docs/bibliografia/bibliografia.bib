% Encoding: UTF-8

% ESTADO DEL ARTE

%% Importancia de baja calidad actualmente de datasets
@article{ImportanciaDeBajaCalidadActualmenteDeDatasets,
  title = {Road safety data and information availability and priorities in South-East European regions},
  journal = {Transportation Research Procedia},
  volume = {25},
  pages = {3703-3714},
  year = {2017},
  note = {World Conference on Transport Research - WCTR 2016 Shanghai. 10-15 July 2016},
  issn = {2352-1465},
  doi = {https://doi.org/10.1016/j.trpro.2017.05.221},
  url = {https://www.sciencedirect.com/science/article/pii/S2352146517305227},
  author = {Alexandra Laiou and Eleonora Papadimitriou and George Yannis and Alberto Milotti},
  keywords = {road safety, South East Europe, ROSEE, data, questionnaire, availability, priorities},
  abstract = {While road deaths have been reduced by 53% in the European Union (EU) between 2001 and 2013, in South East European (SEE) members reductions vary from 64% (Slovakia) to 24% (Romania) indicating a significant diversity in the road safety level in the region and the need for urgent improvements. Moreover, the poor performance in the SEE countries is slowing down overall progress at EU level. ROSEE- ROad safety in South-East European regions is an EU co-funded project undertaken in Italy, Romania, Hungary, Greece, Slovenia and Bulgaria. ROSEE aimed at improving coordination in planning and operation of national and regional road networks with an emphasis on improving accessibility and road safety. The objective of this paper is to present the results of a survey conducted among a large panel of road safety stakeholders in SEE countries, aiming at assessing what they considered to be priorities and necessities in terms of scientific data, information, and tools to conduct their road safety activities. A questionnaire comprising of the following sections was used for the assessment:(a) background information;(b) data and resources for fact finding and diagnosis of road safety issues; (c) data and resources for the development of road safety related programmes; (d) data and resources for the implementation of road safety related measures; (e) data and resources for the monitoring and evaluation of road safety measures. In sections (b) to (d), the respondents evaluated each listed item on two dimensions: the perceived priority for their personal work, and the perceived availability at the level of their country (i.e. the extent to which, according to their knowledge, the item in question was available would they want to use it). In total, 112 questionnaires were analysed. Combined priority and availability ratings as well as ranking of priorities and identification of highest priorities per country was achieved. Furthermore, policy makers’ priorities were analysed separately. The analysis of the collected responses revealed that stakeholders expressed significant demand for data and knowledge in road safety-related decision making. They also expressed discontent about the current poor availability of such information. Groupings of the road safety needs and priorities of the different stakeholders were also performed.}
}

@article{MotorcycleCrashesMultinominalStatistic,
  title = {A multinomial logit model of motorcycle crash severity at Australian intersections},
  journal = {Journal of Safety Research},
  volume = {73},
  pages = {17-24},
  year = {2020},
  issn = {0022-4375},
  doi = {https://doi.org/10.1016/j.jsr.2020.02.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0022437520300153},
  author = {Mohammad {Abrari Vajari} and Kayvan Aghabayk and Mohammad Sadeghian and Nirajan Shiwakoti},
  keywords = {Multinomial logit model, Injury severity, Motorcycle crashes, Intersection, Risk factors},
  abstract = {Introduction: Motorcyclists are exposed to more fatalities and severe injuries per mile of travel as compared to other vehicle drivers. Moreover, crashes that take place at intersections are more likely to result in serious or fatal injuries as compared to those that occur at non-intersections. Therefore, the purpose of this study is to evaluate the contributing factors to motorcycle crash severity at intersections. Method: A data set of 7,714 motorcycle crashes at intersections in the State of Victoria, Australia was analyzed over the period of 2006–2018. The multinomial logit model was used for evaluating the motorcycle crashes. The severity of motorcycle crashes was divided into three categories: minor injury, serious injury and fatal injury. The risk factors consisted of four major categories: motorcyclist characteristics, environmental characteristics, intersection characteristics and crash characteristics. Results: The results of the model demonstrated that certain factors increased the probability of fatal injuries. These factors were: motorcyclists aged over 59 years, weekend crashes, midnight/early morning crashes, morning rush hours crashes, multiple vehicles involved in the crash, t-intersections, crashes in towns, crashes in rural areas, stop or give-way intersections, roundabouts, and uncontrolled intersections. By contrast, factors such as female motorcyclists, snowy or stormy or foggy weather, rainy weather, evening rush hours crashes, and unpaved roads reduced the probability of fatal injuries. Practical Applications: The results from our study demonstrated that certain treatment measures for t-intersections may reduce the probability of fatal injuries. An effective way for improving the safety of stop or give-way intersections and uncontrolled intersections could be to convert them to all-way stop controls. Further, it is recommended to educate the older riders that with ageing, there are physiological changes that occur within the body which can increase both crash likelihood and injury severity.}
}


@article{FactoresQueInfluyen2003,
  title = {Factors influencing injury severity of motor vehicle–crossing pedestrian crashes in rural Connecticut},
  journal = {Accident Analysis , Prevention},
  volume = {35},
  number = {3},
  pages = {369-379},
  year = {2003},
  issn = {0001-4575},
  doi = {https://doi.org/10.1016/S0001-4575(02)00013-1},
  url = {https://www.sciencedirect.com/science/article/pii/S0001457502000131},
  author = {Sylvia S Zajac and John N Ivan},
  keywords = {Pedestrian, Injury severity, Rural, Safety, Roadway features, Area type},
  abstract = {The ordered probit model was used to evaluate the effect of roadway and area type features on injury severity of pedestrian crashes in rural Connecticut. Injury severity was coded on the KABCO scale and crashes were limited to those in which the pedestrians were attempting to cross two-lane highways that were controlled by neither stop signs nor traffic signals. Variables that significantly influenced pedestrian injury severity were clear roadway width (the distance across the road including lane widths and shoulders, but excluding the area occupied by on-street parking), vehicle type, driver alcohol involvement, pedestrian age 65 years or older, and pedestrian alcohol involvement. Seven area types were identified: downtown, compact residential, village, downtown fringe, medium-density commercial, low-density commercial, and low-density residential. Two groups of these area types were found to experience significantly different injury severities. Downtown, compact residential, and medium- and low-density commercial areas generally experienced lower pedestrian injury severity than village, downtown fringe, and low-density residential areas.}
}


@article{RedNeuronalAutopistaAccidentes,
  title = {Expressway crash risk prediction using back propagation neural network: A brief investigation on safety resilience},
  journal = {Accident Analysis , Prevention},
  volume = {124},
  pages = {180-192},
  year = {2019},
  issn = {0001-4575},
  doi = {https://doi.org/10.1016/j.aap.2019.01.007},
  url = {https://www.sciencedirect.com/science/article/pii/S0001457519300302},
  author = {Junhua Wang and Yumeng Kong and Ting Fu},
  keywords = {Crash risk prediction, Expressway safety, Safety critical events, Safety resilience of traffic, Back-propagation neural network, Vehicle moving violation}
}


@inproceedings{ImageSegmentationCNNEA,
  title={V-net: Fully convolutional neural networks for volumetric medical image segmentation},
  author={Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
  booktitle={2016 fourth international conference on 3D vision (3DV)},
  pages={565--571},
  year={2016},
  organization={IEEE}
}

@inproceedings{ImageClassificationCNNEA,
  title={Medical image classification with convolutional neural network},
  author={Li, Qing and Cai, Weidong and Wang, Xiaogang and Zhou, Yun and Feng, David Dagan and Chen, Mei},
  booktitle={2014 13th international conference on control automation robotics \& vision (ICARCV)},
  pages={844--848},
  year={2014},
  organization={IEEE}
}

@inproceedings{LanguageRecognitionCNNEA,
  title={American sign language recognition using deep learning and computer vision},
  author={Bantupalli, Kshitij and Xie, Ying},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)},
  pages={4896--4899},
  year={2018},
  organization={IEEE}
}



@article{ArbolDecisionSeveridadDeAccidentes,
  title = {Analysis of traffic accident severity using Decision Rules via Decision Trees},
  journal = {Expert Systems with Applications},
  volume = {40},
  number = {15},
  pages = {6047-6054},
  year = {2013},
  issn = {0957-4174},
  doi = {https://doi.org/10.1016/j.eswa.2013.05.027},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417413003138},
  author = {Joaquín Abellán and Griselda López and Juan {de Oña}},
  keywords = {Traffic accident, Severity, Road safety, Decision Trees, Decision Rules},
  abstract = {A Decision Tree (DT) is a potential method for studying traffic accident severity. One of its main advantages is that Decision Rules (DRs) can be extracted from its structure. And these DRs can be used to identify safety problems and establish certain measures of performance. However, when only one DT is used, rule extraction is limited to the structure of that DT and some important relationships between variables cannot be extracted. This paper presents a more effective method for extracting rules from DTs. The method’s effectiveness when applied to a particular traffic accident dataset is shown. Specifically, our study focuses on traffic accident data from rural roads in Granada (Spain) from 2003 to 2009 (both included). The results show that we can obtain more than 70 relevant rules from our data using the new method, whereas with only one DT we would have extracted only five relevant rules from the same dataset.}
}

@article{LogisticRegressionPrediccionAccidentes,
  title = {Analyzing injury severity of motorcycle at-fault crashes using machine learning techniques, decision tree and logistic regression models},
  journal = {International Journal of Transportation Science and Technology},
  volume = {9},
  number = {2},
  pages = {89-99},
  year = {2020},
  issn = {2046-0430},
  doi = {https://doi.org/10.1016/j.ijtst.2019.10.002},
  url = {https://www.sciencedirect.com/science/article/pii/S2046043019301133},
  author = {Mahdi Rezapour and Amirarsalan {Mehrara Molan} and Khaled Ksaibati},
  keywords = {Motorcycle crashes, Injury severity, Machine learning techniques, Decision tree, Logistic regression},
  abstract = {A review of US mortality crashes revealed that motorcycle crashes are overrepresented in fatal crashes in the United States. Unlike passenger vehicles, motorcycles do not have much protection when it comes to crash involvement. In Wyoming, fatal or severe crashes account for 4% of all crashes, while 34% of motorcycle crashes are fatal or severe. Despite the heightened severity of motorcycle crashes, not much research has been conducted by using comprehensive methods to identify the contributory factors of such crashes. Furthermore, often the previous studies conducted analyses without evaluation of prediction accuracy of the models. Thus, this study evaluated the possibility of using both parametric and nonparametric methods in prediction of motorcycle at-fault injury severity. The goodness of the fit for the included methods was evaluated by comparing the performance of the models. Emphasis is given to mountainous highways where motorcycle use is high along with high crash incidence rates. Binary logistic regression as a parametric method, and the classification tree (CT) as a nonparametric method were employed in this study. Before conducting the analyses, an optimum set of included predictors was identified based on feature reduction. Also, in order to address the biased associated with selection of the test data, k-fold cross validation was used. The binary logistic regression has been used to analyze injury severity. However, this model relies on some very specific assumptions regarding the probability distribution, and logit link function. An alternative to binary logistic could be the classification tree (CT) which predicts injury severity based upon the set of predictors. The results indicated that although both models provided a comparable error rate binary logistic perform slightly better in prediction of motorcycle at-fault injury severity. The models performed similarly in terms of identified predictors. Some of the predictors that identified similarly with the two methods are posted speed limit, age, Highway functional class, and speed compliance.}
}

@INPROCEEDINGS{GeneticProgrammingAccidents,
  author={Beshah,
  Tibebe and Ejigu, Dejene and Krömer, Pavel and Sn´el, V'clav and Plato, Jan and Abraham, Ajith},
  booktitle={2012 Fourth International Conference on Intelligent Networking and Collaborative Systems},
  title={Learning the Classification of Traffic Accident Types},
  year={2012},
  volume={},
  number={},
  pages={463-468},
  doi={10.1109/iNCoS.2012.75}
}

@article{NSGAIIAccidentPrediction,
  title={Traffic accident severity prediction using a novel multi-objective genetic algorithm},
  author={Hashmienejad, Seyed Hessam-Allah and Hasheminejad, Seyed Mohammad Hossein},
  journal={International journal of crashworthiness},
  volume={22},
  number={4},
  pages={425--440},
  year={2017},
  publisher={Taylor \, Francis}
}

@article{GAPSMLPANNAccidents,
  author = {Kunt, Mehmet and Aghayan, Iman and Noii, Nima},
  year = {2011},
  month = {12},
  pages = {353-366},
  title = {Prediction for traffic accident severity: Comparing the artificial neural network, genetic algorithm, combined genetic algorithm and pattern search methods},
  volume = {26},
  journal = {Transport},
  doi = {10.3846/16484142.2011.635465}
}

@article{SVMPSOAccidents,
  author = {Xiaoning Gu and Ting Li and Yonghui Wang and Liu Zhang and Yitian Wang and Jinbao Yao},
  title ={Traffic fatalities prediction using support vector machine with hybrid particle swarm optimization},
  journal = {Journal of Algorithms \& Computational Technology},
  volume = {12},
  number = {1},
  pages = {20-29},
  year = {2018},
  doi = {10.1177/1748301817729953},
  URL = {https://doi.org/10.1177/1748301817729953},
  eprint = {https://doi.org/10.1177/1748301817729953}
}



@article{OtraPrediccionConCNNs,
  title = {A deep learning based traffic crash severity prediction framework},
  journal = {Accident Analysis , Prevention},
  volume = {154},
  pages = {106090},
  year = {2021},
  issn = {0001-4575},
  doi = {https://doi.org/10.1016/j.aap.2021.106090},
  url = {https://www.sciencedirect.com/science/article/pii/S0001457521001214}
}


@article{MetodosEstadisticosComparacionSVMOP,
  title = {Using support vector machine models for crash injury severity analysis},
  journal = {Accident Analysis , Prevention},
  volume = {45},
  pages = {478-486},
  year = {2012},
  issn = {0001-4575},
  doi = {https://doi.org/10.1016/j.aap.2011.08.016},
  url = {https://www.sciencedirect.com/science/article/pii/S0001457511002363},
  author = {Zhibin Li and Pan Liu and Wei Wang and Chengcheng Xu},
  keywords = {Support vector machine model, Ordered probit model, Crash severity, Freeway diverge area},
  abstract = {The study presented in this paper investigated the possibility of using support vector machine (SVM) models for crash injury severity analysis. Based on crash data collected at 326 freeway diverge areas, a SVM model was developed for predicting the injury severity associated with individual crashes. An ordered probit (OP) model was also developed using the same dataset. The research team compared the performance of the SVM model and the OP model. It was found that the SVM model produced better prediction performance for crash injury severity than did the OP model. The percent of correct prediction for the SVM model was found to be 48.8%, which was higher than that produced by the OP model (44.0%). Even though the SVM model may suffer from the multi-class classification problem, it still provides better prediction results for small proportion injury severities than the OP model does. The research also investigated the potential of using the SVM model for evaluating the impacts of external factors on crash injury severities. The sensitivity analysis results show that the SVM model produced comparable results regarding the impacts of variables on crash injury severity as compared to the OP model. For several variables such as the length of the exit ramp and the shoulder width of the freeway mainline, the results of the SVM model are more reasonable than those of the OP model.}
}

@article{DeepInsight,
  author = {Sharma, Alok and Vans, Edwin and Shigemizu, Daichi and Boroevich, Keith and Tsunoda, Tatsuhiko},
  year = {2019},
  month = {08},
  pages = {},
  title = {DeepInsight: A methodology to transform a non-image data to an image for convolution neural network architecture},
  volume = {9},
  journal = {Scientific Reports},
  doi = {10.1038/s41598-019-47765-6}
}


@article{CNNReviews,
  title={Deep convolutional neural networks for image classification: A comprehensive review},
  author={Rawat, Waseem and Wang, Zenghui},
  journal={Neural computation},
  volume={29},
  number={9},
  pages={2352--2449},
  year={2017},
  publisher={MIT Press}
}


@ARTICLE{MotorFailureCNN1D,
  author={Ince, Turker and Kiranyaz, Serkan and Eren, Levent and Askar, Murat and Gabbouj, Moncef},
  journal={IEEE Transactions on Industrial Electronics},
  title={Real-Time Motor Fault Detection by 1-D Convolutional Neural Networks},
  year={2016},
  volume={63},
  number={11},
  pages={7067-7075},
  doi={10.1109/TIE.2016.2582729}
}

@article{CNN1DMedicalSignalEA,
  title = {1D convolutional neural networks and applications: A survey},
  journal = {Mechanical Systems and Signal Processing},
  volume = {151},
  pages = {107398},
  year = {2021},
  issn = {0888-3270},
  doi = {https://doi.org/10.1016/j.ymssp.2020.107398},
  url = {https://www.sciencedirect.com/science/article/pii/S0888327020307846},
  author = {Serkan Kiranyaz and Onur Avci and Osama Abdeljaber and Turker Ince and Moncef Gabbouj and Daniel J. Inman},
  keywords = {Artificial Neural Networks, Machine learning, Deep learning, Convolutional neural networks, Structural health monitoring, Condition monitoring, Arrhythmia detection and identification, Fault detection, Structural damage detection}
}

@article{ElectricSystemFailureCNN1D,
  title={ASM1D-GAN: An intelligent fault diagnosis method based on assembled 1D convolutional neural network and generative adversarial networks},
  author={Gao, Shengyao and Wang, Xueren and Miao, Xuhong and Su, Changwei and Li, Yibin},
  journal={Journal of signal processing systems},
  volume={91},
  number={10},
  pages={1237--1247},
  year={2019},
  publisher={Springer}
}

@article{FaceRecognitionCNN2EA,
  title={Face recognition: A convolutional neural-network approach},
  author={Lawrence, Steve and Giles, C Lee and Tsoi, Ah Chung and Back, Andrew D},
  journal={IEEE transactions on neural networks},
  volume={8},
  number={1},
  pages={98--113},
  year={1997},
  publisher={IEEE}
}

@misc{DocumentAnalysisCNN2DEA,
  doi = {10.48550/ARXIV.1708.03273},
  url = {https://arxiv.org/abs/1708.03273},
  author = {Tensmeyer, Chris and Martinez, Tony},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Analysis of Convolutional Neural Networks for Document Image Classification},
  publisher = {arXiv},
  year = {2017}, 
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{WeatherClimateCNN2DEA,
  title={Application of deep convolutional neural networks for detecting extreme weather in climate datasets},
  author={Liu, Yunjie and Racah, Evan and Correa, Joaquin and Khosrowshahi, Amir and Lavers, David and Kunkel, Kenneth and Wehner, Michael and Collins, William and others},
  journal={arXiv preprint arXiv:1605.01156},
  year={2016}
}


@article{DeteccionDeAccidentesPorTweets,
  title = {A deep learning approach for detecting traffic accidents from social media data},
  journal = {Transportation Research Part C: Emerging Technologies},
  volume = {86},
  pages = {580-596},
  year = {2018},
  issn = {0968-090X},
  doi = {https://doi.org/10.1016/j.trc.2017.11.027},
  url = {https://www.sciencedirect.com/science/article/pii/S0968090X1730356X},
  author = {Zhenhua Zhang and Qing He and Jing Gao and Ming Ni},
  keywords = {Traffic accident detection, Tweet, Social media, Association rules, Deep learning},
  abstract = {This paper employs deep learning in detecting the traffic accident from social media data. First, we thoroughly investigate the 1-year over 3 million tweet contents in two metropolitan areas: Northern Virginia and New York City. Our results show that paired tokens can capture the association rules inherent in the accident-related tweets and further increase the accuracy of the traffic accident detection. Second, two deep learning methods: Deep Belief Network (DBN) and Long Short-Term Memory (LSTM) are investigated and implemented on the extracted token. Results show that DBN can obtain an overall accuracy of 85% with about 44 individual token features and 17 paired token features. The classification results from DBN outperform those of Support Vector Machines (SVMs) and supervised Latent Dirichlet allocation (sLDA). Finally, to validate this study, we compare the accident-related tweets with both the traffic accident log on freeways and traffic data on local roads from 15,000 loop detectors. It is found that nearly 66% of the accident-related tweets can be located by the accident log and more than 80% of them can be tied to nearby abnormal traffic data. Several important issues of using Twitter to detect traffic accidents have been brought up by the comparison including the location and time bias, as well as the characteristics of influential users and hashtags.}
}


@Article{RNNAccidentSeverityPrediction,
  AUTHOR = {Sameen, Maher Ibrahim and Pradhan, Biswajeet},
  TITLE = {Severity Prediction of Traffic Accidents with Recurrent Neural Networks},
  JOURNAL = {Applied Sciences},
  VOLUME = {7},
  YEAR = {2017},
  NUMBER = {6},
  ARTICLE-NUMBER = {476},
  URL = {https://www.mdpi.com/2076-3417/7/6/476},
  ISSN = {2076-3417},
  ABSTRACT = {In this paper, a deep learning model using a Recurrent Neural Network (RNN) was developed and employed to predict the injury severity of traffic accidents based on 1130 accident records that have occurred on the North-South Expressway (NSE), Malaysia over a six-year period from 2009 to 2015. Compared to traditional Neural Networks (NNs), the RNN method is more effective for sequential data, and is expected to capture temporal correlations among the traffic accident records. Several network architectures and configurations were tested through a systematic grid search to determine an optimal network for predicting the injury severity of traffic accidents. The selected network architecture comprised of a Long-Short Term Memory (LSTM) layer, two fully-connected (dense) layers and a Softmax layer. Next, to avoid over-fitting, the dropout technique with a probability of 0.3 was applied. Further, the network was trained with a Stochastic Gradient Descent (SGD) algorithm (learning rate = 0.01) in the Tensorflow framework. A sensitivity analysis of the RNN model was further conducted to determine these factors’ impact on injury severity outcomes. Also, the proposed RNN model was compared with Multilayer Perceptron (MLP) and Bayesian Logistic Regression (BLR) models to understand its advantages and limitations. The results of the comparative analyses showed that the RNN model outperformed the MLP and BLR models. The validation accuracy of the RNN model was 71.77%, whereas the MLP and BLR models achieved 65.48% and 58.30% respectively. The findings of this study indicate that the RNN model, in deep learning frameworks, can be a promising tool for predicting the injury severity of traffic accidents.},
  DOI = {10.3390/app7060476}
}

@misc{CNNExampleEAImage,
  author = {Shashikant},
  title = {Convolutional Neural Network: A Step By Step Guide},
  url = {https://towardsdatascience.com/convolutional-neural-network-a-step-by-step-guide-a8b4c88d6943},
  year = {2019}
}

@Article{ItalianoMetricasDesbalanceo,
  AUTHOR = {Fiorentini, Nicholas and Losa, Massimo},
  TITLE = {Handling Imbalanced Data in Road Crash Severity Prediction by Machine Learning Algorithms},
  JOURNAL = {Infrastructures},
  VOLUME = {5},
  YEAR = {2020},
  NUMBER = {7},
  ARTICLE-NUMBER = {61},
  URL = {https://www.mdpi.com/2412-3811/5/7/61},
  ISSN = {2412-3811},
  ABSTRACT = {Crash severity is undoubtedly a fundamental aspect of a crash event. Although machine learning algorithms for predicting crash severity have recently gained interest by the academic community, there is a significant trend towards neglecting the fact that crash datasets are acutely imbalanced. Overlooking this fact generally leads to weak classifiers for predicting the minority class (crashes with higher severity). In this paper, in order to handle imbalanced accident datasets and provide a better prediction for the minority class, the random undersampling the majority class (RUMC) technique is used. By employing an imbalanced and a RUMC-based balanced training set, we propose the calibration, validation, and evaluation of four different crash severity predictive models, including random tree, k-nearest neighbor, logistic regression, and random forest. Accuracy, true positive rate (recall), false positive rate, true negative rate, precision, F1-score, and the confusion matrix have been calculated to assess the performance. Outcomes show that RUMC-based models provide an enhancement in the reliability of the classifiers for detecting fatal crashes and those causing injury. Indeed, in imbalanced models, the true positive rate for predicting fatal crashes and those causing injury spans from 0% (logistic regression) to 18.3% (k-nearest neighbor), while for the RUMC-based models, it spans from 52.5% (RUMC-based logistic regression) to 57.2% (RUMC-based k-nearest neighbor). Organizations and decision-makers could make use of RUMC and machine learning algorithms in predicting the severity of a crash occurrence, managing the present, and planning the future of their works.},
  DOI = {10.3390/infrastructures5070061}
}

@INPROCEEDINGS{MIT,
  author={He, Songtao and Sadeghi, Mohammad Amin and Chawla, Sanjay and Alizadeh, Mohammad and Balakrishnan, Hari and Madden, Samuel},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  title={Inferring high-resolution traffic accident risk maps based on satellite imagery and GPS trajectories},
  year={2021},
  volume={},
  number={},
  pages={11957-11965},
  doi={10.1109/ICCV48922.2021.01176}
}

% TECNOLOGIAS

%% Modelos

%%% Algoritmos Genéticos


@article{GA,
  author = {Lingaraj, Haldurai},
  year = {2016},
  month = {10},
  pages = {139-143},
  title = {A Study on Genetic Algorithm and its Applications},
  volume = {4},
  journal = {International Journal of Computer Sciences and Engineering}
}


%%% XGBoost

@InProceedings{XGBoostTutorial,
  doi = {10.1145/2939672.2939785},  
  url = {https://doi.org/10.1145%2F2939672.2939785},  
  year = 2016,
  month = {aug},  
  publisher = {{ACM}},  
  author = {Tianqi Chen and Carlos Guestrin},  
  title = {{XGBoost}},  
  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining}
}


@misc{NvidiaXGBoost,
  author = {Nvidia},
  title = {Nvidia XGBoost},
  url = {https://www.nvidia.com/en-us/glossary/data-science/xgboost/},
  year = {2022},
}

%%% NB

@book{ISLR2,
  title={An introduction to statistical learning},
  author={James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  volume={112},
  year={2013},
  publisher={Springer}
}


%%% SVC

@article{SVC,
  title={Support-vector networks},
  author={Cortes, Corinna and Vapnik, Vladimir},
  journal={Machine learning},
  volume={20},
  number={3},
  pages={273--297},
  year={1995},
  publisher={Springer}
}

%%% NN

@ARTICLE{NNReview,
  AUTHOR={Emmert-Streib, Frank and Yang, Zhen and Feng, Han and Tripathi, Shailesh and Dehmer, Matthias},
  TITLE={An Introductory Review of Deep Learning for Prediction Models With Big Data},
  JOURNAL={Frontiers in Artificial Intelligence},
  VOLUME={3},
  YEAR={2020},
  URL={https://www.frontiersin.org/article/10.3389/frai.2020.00004},
  DOI={10.3389/frai.2020.00004},
  ISSN={2624-8212},
}

@misc{ReferenciaImagenNN,
  author = {Pragati Baheti - Microsoft},
  title = {12 Types of Neural Network Activation Functions: How to Choose?},
  url = {https://www.v7labs.com/blog/neural-networks-activation-functions},
  year = {2022}
}

@misc{Softmax,
  author = {Wikipedia},
  title = {Softmax Function},
  url = {https://en.wikipedia.org/wiki/Softmax_function},
  year = {2022}
}

@misc{Cross-Entropy,
  author = {Kiprono Elijah Koech},
  title = {Cross-Entropy Loss Function},
  url = {https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e},
  year = {2020}
}

@misc{LearningRate,
  doi = {10.48550/ARXIV.1803.09820},
  url = {https://arxiv.org/abs/1803.09820},  
  author = {Smith, Leslie N.},  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},  
  title = {A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay},  
  publisher = {arXiv},  
  year = {2018},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{BatchNormalization,
  doi = {10.48550/ARXIV.1502.03167},
  url = {https://arxiv.org/abs/1502.03167},
  author = {Ioffe, Sergey and Szegedy, Christian},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@book{KL-Divergence,
  title={Information theory and statistics},
  author={Kullback, Solomon},
  year={1997},
  publisher={Courier Corporation}
}


@misc{FiltersFeatureMaps,
  author = {Renu Khandelwal},
  title = {Filters and Feature Maps},
  url = {https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c},
  year = {2020}
}

@misc{ReferenciaImagenStrides,
  author = {MYO NeuralNet},
  title = {Calculating the Output Size of Convolutions and Transpose Convolutions},
  url = {http://makeyourownneuralnetwork.blogspot.com/2020/02/calculating-output-size-of-convolutions.html},
  year = {2020}
}


@misc{ReferenciaImagenKernelFiltro,
  author = {IndoML},
  title = {Student Notes: Convolutional Neural Networks (CNN) Introduction},
  url = {https://indoml.com/2018/03/07/student-notes-convolutional-neural-networks-cnn-introduction/},
  year = {2018}
}

@article{CNNReLUImage,
  author = {Kamrava, Serveh and Tahmasebi, Pejman and Sahimi, Muhammad},
  year = {2020},
  month = {01},
  pages = {},
  title = {Linking Morphology of Porous Media to Their Macroscopic Permeability by Deep Learning},
  volume = {131},
  journal = {Transport in Porous Media},
  doi = {10.1007/s11242-019-01352-5}
}

%%%% Conv1D

@misc{Conv1D_Survey,
  doi = {10.48550/ARXIV.1905.03554},
  url = {https://arxiv.org/abs/1905.03554},
  author = {Kiranyaz, Serkan and Avci, Onur and Abdeljaber, Osama and Ince, Turker and Gabbouj, Moncef and Inman, Daniel J.},
  keywords = {Signal Processing (eess.SP), Artificial Intelligence (cs.AI), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {1D Convolutional Neural Networks and Applications: A Survey},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license},
}

@article{CNN1DArchitectureImage,
  author = {Shenfield, Alex and Howarth, Martin},
  year = {2020},
  month = {09},
  pages = {},
  title = {A Novel Deep Learning Model for the Detection and Identification of Rolling Element-Bearing Faults},
  volume = {20},
  journal = {Sensors (Basel, Switzerland)},
  doi = {10.3390/s20185112}
}

@misc{CNN1DImage,
  author = {Knowledge Center},
  title = {How does 1D convolution work?},
  url = {https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/1d-convolution},
  year = {2021}
}
 
 
@misc{Kernels,
  author = {Prakhar Ganesh},
  title = {Types of Convolution Kernels : Simplified},
  url = {https://towardsdatascience.com/types-of-convolution-kernels-simplified-f040cb307c37},
  year = {2019}
}

%%%  KNN

@article{KNN,
  title={An introduction to kernel and nearest-neighbor nonparametric regression},
  author={Altman, Naomi S},
  journal={The American Statistician},
  volume={46},
  number={3},
  pages={175--185},
  year={1992},
  publisher={Taylor \, Francis}
}

@misc{ReferenciaKNNImagen,
  author = {Hemingway - Huawei},
  title = {¿Qué es KNN ó K-Nearest Neighbor?},
  url = {https://forum.huawei.com/enterprise/es/%C2%BFqu%C3%A9-es-knn-%C3%B3-k-nearest-neighbor/thread/765627-100757},
  year = {2020}
}

%% Especificaciones Técnicas

%%% Herramientas Utilizadas

@misc{Python,
  author = {Python},
  title = {Python Language},
  url = {https://www.python.org/about/quotes/},
  year = {2022}
}


@misc{Tensorflow,
  author = {tensorflow},
  title = {Tensorflow Library},
  url = {https://www.tensorflow.org},
  year = {2022}
}

@misc{Pandas,
  author = {pandas-dev},
  title = {Pandas Library},
  url = {https://pandas.pydata.org/docs/getting_started/overview.html},
  year = {2022}
}

@misc{Scikit-Learn,
  author = {scikit-learn},
  title = {Scikit-learn Library},
  url = {https://scikit-learn.org/stable/},
  year = {2022}
}

@misc{XGBoostLibrary,
  author = {dmlc},
  title = {Xgboost Library},
  url = {https://xgboost.readthedocs.io/en/stable/},
  year = {2022}
}

@misc{CUDA,
  author = {Nvidia},
  title = {CUDA Library},
  url = {https://developer.nvidia.com/cuda-zone},
  year = {2022}
}

@misc{Anaconda,
  author = {Anaconda, Inc},
  title = {Anaconda library},
  url = {https://www.anaconda.com/},
  year = {2022}
}

@misc{DiagramsNet,
  author = {jGraph},
  title = {DiagramsNet Software},
  url = {https://www.diagrams.net/},
  year = {2022}
}

@misc{GoogleMeet,
  author = {Google},
  title = {Google Meets Application},
  url = {https://meet.google.com/},
  year = {2022}
}

@misc{Github,
  author = {Github},
  title = {Github SVC},
  url = {https://github.com/},
  year = {2022}
}

@misc{JupyterNotebook,
  author = {Project Jupyter},
  title = {Jupyter Notebook},
  url = {https://jupyter.org/},
  year = {2022}
}

@misc{JupyterLab,
  author = {Project Jupyter},
  title = {Jupyter Lab},
  url = {https://jupyterlab.readthedocs.io/en/stable/},
  year = {2022}
}

%%% Especificaciones del servidor


% Metodología

%% Diagrama de Flujo

@misc{LifecycleDataScienceProjectsTimes,
  author = {Projectpro.io},
  title = {Why data preparation is an important part of data science?},
  url = {https://www.projectpro.io/article/why-data-preparation-is-an-important-part-of-data-science/242},
  year = {2022}
}
%% Diagrama de Gantt
%% Proceso


@misc{DatasetMadrid,
  author = {Portal de Datos Abiertos del Ayuntamiento de Madrid},
  title = {Accidentes de tráfico Madrid},
  url = {https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=7c2843010d9c3610VgnVCM2000001f4a900aRCRD,vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD,vgnextfmt=default},
  urldate = {2022-05-11},
  year = {2022}
}

@misc{InfoDatasetMadrid,
  author = {Portal de Datos Abiertos del Ayuntamiento de Madrid},
  title = {ESTRUCTURA DEL CONJUNTO DE DATOS},
  url = {https://datos.madrid.es/FWProjects/egob/Catalogo/Seguridad/Ficheros/Estructura_DS_Accidentes_trafico_desde_2019.pdf},
  year = {2019}
}

%%% Datos

%%%% Limpieza de datos

@misc{OpenRefine,
  author = {Metaweb Technologies, Inc.},
  title = {Open Refine Project},
  url = {https://openrefine.org/},
  year = {2022}
}
%%%% Transformaciones de datos

@book{RegeXBook,
  title={Regular Expressions Cookbook},
  author={Goyvaerts, J. and Levithan, S.},
  isbn={9781449319434},
  lccn={2012472268},
  series={Oreilly and Associate Series},
  url={https://books.google.es/books?id=6k7IfACN\_P8C},
  year={2012},
  publisher={O'Reilly Media, Incorporated}
}

%%%% Análisis de datos

@article{WhyImbalancedDataIsAProblem,
  title={Classification of imbalanced data: A review},
  author={Sun, Yanmin and Wong, Andrew KC and Kamel, Mohamed S},
  journal={International journal of pattern recognition and artificial intelligence},
  volume={23},
  number={04},
  pages={687--719},
  year={2009},
  publisher={World Scientific}
}


@article{ImbalancedDataReview,
  title = {Learning from class-imbalanced data: Review of methods and applications},
  journal = {Expert Systems with Applications},
  volume = {73},
  pages = {220-239},
  year = {2017},
  issn = {0957-4174},
  doi = {https://doi.org/10.1016/j.eswa.2016.12.035},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417416307175},
  author = {Guo Haixiang and Li Yijing and Jennifer Shang and Gu Mingyun and Huang Yuanyue and Gong Bing},
  keywords = {Rare events, Imbalanced data, Machine learning, Data mining},
  abstract = {Rare events, especially those that could potentially negatively impact society, often require humans’ decision-making responses. Detecting rare events can be viewed as a prediction task in data mining and machine learning communities. As these events are rarely observed in daily life, the prediction task suffers from a lack of balanced data. In this paper, we provide an in depth review of rare event detection from an imbalanced learning perspective. Five hundred and seventeen related papers that have been published in the past decade were collected for the study. The initial statistics suggested that rare events detection and imbalanced learning are concerned across a wide range of research areas from management science to engineering. We reviewed all collected papers from both a technical and a practical point of view. Modeling methods discussed include techniques such as data preprocessing, classification algorithms and model evaluation. For applications, we first provide a comprehensive taxonomy of the existing application domains of imbalanced learning, and then we detail the applications for each category. Finally, some suggestions from the reviewed papers are incorporated with our experiences and judgments to offer further research directions for the imbalanced learning and rare event detection fields.}
}


@article{PearsonCoefficientCorrelationMatrix,
  author = {Schober, Patrick and Boer, Christa and Schwarte, Lothar},
  year = {2018},
  month = {02},
  pages = {1},
  title = {Correlation Coefficients: Appropriate Use and Interpretation},
  volume = {126},
  journal = {Anesthesia and Analgesia},
  doi = {10.1213/ANE.0000000000002864}
}

%%%% Separación de datos
%%%% Normalización de datos

@misc{NormalizationSensitiveModels,
  author = {Data School},
  title = {Comparing supervised learning algorithms},
  url = {https://www.dataschool.io/comparing-supervised-learning-algorithms/},
  year = {2015}
}


@article{DataNormalizationInvestigation,
  title = {Investigating the impact of data normalization on classification performance},
  journal = {Applied Soft Computing},
  volume = {97},
  pages = {105524},
  year = {2020},
  issn = {1568-4946},
  doi = {https://doi.org/10.1016/j.asoc.2019.105524},
  url = {https://www.sciencedirect.com/science/article/pii/S1568494619302947},
  author = {Dalwinder Singh and Birmohan Singh},
  keywords = {Ant lion optimization, Data normalization, Feature selection, Feature weighting, -NN classifier},
  abstract = {Data normalization is one of the pre-processing approaches where the data is either scaled or transformed to make an equal contribution of each feature. The success of machine learning algorithms depends upon the quality of the data to obtain a generalized predictive model of the classification problem. The importance of data normalization for improving data quality and subsequently the performance of machine learning algorithms has been presented in many studies. But, the work lacks for the feature selection and feature weighting approaches, a current research trend in machine learning for improving performance. Therefore, this study aims to investigate the impact of fourteen data normalization methods on classification performance considering full feature set, feature selection, and feature weighting. In this paper, we also present a modified Ant Lion optimization that search feature subsets and the best feature weights along with the parameter of Nearest Neighbor Classifier. Experiments are performed on 21 publicly available real and synthetic datasets, and results are analyzed based on the accuracy, the percentage of feature reduced and runtime. It has been observed from the results that no single method outperforms others. Therefore, we have suggested a set of the best and the worst methods combining the normalization procedure and empirical analysis of results. The better performers are z-Score and Pareto Scaling for the full feature set and feature selection, and tanh and its variant for feature weighting. The worst performers are Mean Centered, Variable Stability Scaling and Median and Median Absolute Deviation methods along with un-normalized data.}
}

@misc{TrainTestSplitImage,
  author = {Adi Bronshtein},
  title = {Train/Test Split and Cross Validation in Python},
  url = {https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6},
  year = {2017}
}

%%% Muestreo

%%%% Downsampling

@ARTICLE{Downsampling,
  author = {Liu, Xu-Ying and Wu, Jianxin and Zhou, Zhi-Hua},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  title={Exploratory Undersampling for Class-Imbalance Learning},
  year={2009},
  volume={39},
  number={2},
  pages={539-550},
  doi={10.1109/TSMCB.2008.2007853}
  }

%%%% Synthetic Data

@article{SMOTEII,
  doi = {10.1613/jair.953},  
  url = {https://doi.org/10.1613%2Fjair.953},  
  year = 2002,
  month = {jun},  
  publisher = {AI Access Foundation},  
  volume = {16},  
  pages = {321--357},  
  author = {N. V. Chawla and K. W. Bowyer and L. O. Hall and W. P. Kegelmeyer},  
  title = {SMOTE: Synthetic Minority Over-sampling Technique},  
  journal = {Journal of Artificial Intelligence Research}
}



@article{SNE,
  title={Stochastic neighbor embedding},
  author={Hinton, Geoffrey E and Roweis, Sam},
  journal={Advances in neural information processing systems},
  volume={15},
  year={2002}
}


@article{TSNEPaper,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}


%%% Algoritmo Genético

@ARTICLE{GAXGBoostPaper,
  author={Jiang, Yu and Tong, Guoxiang and Yin, Henan and Xiong, Naixue},
  journal={IEEE Access},
  title={A Pedestrian Detection Method Based on Genetic Algorithm for Optimize XGBoost Training Parameters},
  year={2019},
  volume={7},
  number={},
  pages={118310-118321},
  doi={10.1109/ACCESS.2019.2936454}
}

@misc{GAXGBoostCode,
  author = {Mohit Jain},
  title = {Hyperparameter tuning in XGBoost using genetic algorithm},
  url = {https://towardsdatascience.com/hyperparameter-tuning-in-xgboost-using-genetic-algorithm-17bd2e581b17},
  year= {2018}
}

@misc{XGBoostHyperparamsMeaning,
  author = {Cambridge Spark},
  title = {Hyperparameter tuning in XGBoost},
  url = {https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f},
  year = {2017}
}
%%% XGBoost
@misc{XGBoostFeatureWeightsMeaning,
  author = {Jason Brownlee},
  title = {Feature Importance and Feature Selection With XGBoost in Python},
  url = {https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/},
  year= {2016}
}
%%% Construcción de imágenes

@article{JerarquiaImagenes,
  author = {Kopelias, Pantelis and Papadimitriou, Fanis and Papandreou, Konstantinos and Prevedouros, P. D.},
  year = {2007},
  month = {12},
  pages = {123-131},
  title = {Urban Freeway Crash Analysis: Geometric, Operational, and Weather Effects on Crash Number and Severity},
  volume = {2015},
  journal = {Transportation Research Record},
  doi = {10.3141/2015-14}
}

@article{TASPCNN,
  title={Traffic accident’s severity prediction: A deep-learning approach-based CNN network},
  author={Zheng, Ming and Li, Tong and Zhu, Rui and Chen, Jing and Ma, Zifei and Tang, Mingjing and Cui, Zhongqiang and Wang, Zhan},
  journal={IEEE Access},
  volume={7},
  pages={39897--39910},
  year={2019},
  publisher={IEEE}
}

%%% Implementación de Modelos


%%%% KNN

@misc{GridSearchSklearnLibrary,
  author = {Sklearn},
  title = {GridSearchCV},
  url = {https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html},
  year= {2021}
}

@article{AutoSklearn,
    title     = {Auto-Sklearn 2.0: Hands-free AutoML via Meta-Learning},
    author    = {Feurer, Matthias and Eggensperger, Katharina and Falkner, Stefan and Lindauer, Marius and Hutter, Frank},
    journal   = {arXiv:2007.04074 [cs.LG]},
    year      = {2020},
}


@inproceedings{GradientVanishingRelu,
  title={Deep sparse rectifier neural networks},
  author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={315--323},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@misc{MatrizConfusionReferenciaImagen,
  author = {Carlos Zelada},
  title = {Evaluación de modelos de clasificación},
  url = {https://rpubs.com/chzelada/275494},
  year= {2017}
}

% CONCLUSIONES
@misc{AutoKeras,
  doi = {10.48550/ARXIV.1806.10282},
  url = {https://arxiv.org/abs/1806.10282},
  author = {Jin, Haifeng and Song, Qingquan and Hu, Xia},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Auto-Keras: An Efficient Neural Architecture Search System},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@Comment{jabref-meta: databaseType:biblatex;}
