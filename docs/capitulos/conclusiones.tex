%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plantilla TFG/TFM
% Escuela Politécnica Superior de la Universidad de Alicante
% Realizado por: Jose Manuel Requena Plens
% Contacto: info@jmrplens.com / Telegram:@jmrplens
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusiones}
\label{conclusiones}



\section{Trabajos para futuro}

	\begin{enumerate}
		\item Utilizar NAS para encontrar la mejor estructura de la red para un problema, debe ser más \textbf{simple} de las que ha construido Autokeras.
		\item Hay que añadir más parametros del XGBoost el coste computacional es muy alto y hay que lanzarlo con mejores procesadores.
		\item formar de otra forma la matriz
		\item Utilizar metaaprendizaje para entrenar modelos que averiguen los mejores hiperparametros para otros modelos
		\item Añadir más características al dataset como la velocidad para aumentar el rendimiento, esto se puede hacer con otro dataset de Madrid que hay velocidades medias por tramos.
		\item Usar OpenRefine para clusterizar nombres de tipos de via
		\item Las transformaciones sobre las variables del dataset son un punto crítico, por ejemplo la variable día/noche podría tener otro rango de horas, que afectaría notablemente a los árboles de decisión de XGBoost.
		\item Otra opción es aumentar la complejidad del dataset en base a los datos que hay, como por ejemplo añadir la estación del año, añadir la temperatura ambiente (tal vez las temperaturas más frías de la carretera minimicen el agarre de los neumáticos)
		\item Probar a hacer resampling de otra forma (reduciendo el número de muestras artificiales por ejemplo)
		\item Rango de edad por ejemplo, acotar de otra forma o utilizar los que vienen por defecto.
	\end{enumerate}