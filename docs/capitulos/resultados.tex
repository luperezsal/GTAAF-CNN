%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plantilla TFG/TFM
% Escuela Politécnica Superior de la Universidad de Alicante
% Realizado por: Jose Manuel Requena Plens
% Contacto: info@jmrplens.com / Telegram:@jmrplens
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Resultados}
\label{resultados}

  En esta sección se detallarán los resultados de cada una de las etapas del proyecto y los experimentos finales para realizar un análisis comparativo entre ellos.

\section{Algoritmo Genético}

  En primer lugar analizaremos la evolución de los hiperparámetros del \glsentryshort{xgboost} gracias al algoritmo genético. En la figura \eqref{EvolucionHiperparametrosImage} se pueden visualizar la evolución de los hiperparámetros del mejor individuo en cada generación a través del transcurso de las iteraciones. Se puede observar cómo el mejor individuo de cada generación va variando los tres hiperparámetros probando distintos valores hasta converger aproximadamente en la iteración \textit{21}.

  \begin{figure}[H]
      \centering
      \includesvg[scale=0.4]{archivos/5.Resultados/GA/EvolucionHiperparametros}
      \caption{Evolución de hiperparámetros a lo largo de las iteraciones.}
      \label{EvolucionHiperparametrosImage}
   \end{figure}

  \begin{figure}
      \centering
      \includesvg[scale=0.4]{archivos/5.Resultados/GA/EvolucionF1Score}
      \caption{Evolución del macro F1 score a lo largo de las iteraciones.}
      \label{EvolucionF1ScoreImage}
   \end{figure}

  En la tabla \eqref{BestGASolutionTable} se puede observar el mejor individuo obtenido después de \textit{50} generaciones.

  \begin{table}[H]
      \centering
          \begin{tabular}{ |c|c| } 
              \hline
              \textbf{Hiperparámetro} & \textbf{Valor}\\
              \hline
                  Profundidad Máxima & 1 \\
                  Peso mínimo de los hijos & 0.01 \\ 
                  ETA & 0.049 \\ 
              \hline

          \end{tabular}
      \caption{Mejores parámetros de XGBoost tras aplicar el algoritmo genético.}
      \label{BestGASolutionTable}
  \end{table}

\section{XGBoost}

  A continuación se mostrará la importancia de las clases calculada por \glsentryshort{xgboost} mediante los hiperparámetros obtenidos en la ejecución del algoritmo genético. En la figura \eqref{FeatureWeightsImage} se puede observar un diagrama de barras en el que las características \textit{tipo de persona}, \textit{tipo de carretera} y \textit{sexo} son las que más han influido a la hora de entrenar el modelo \glsentryshort{xgboost}, obteniendo un peso de \textit{0.177}, \textit{0.127} y \textit{0.111} respectivamente. Se pueden consultar los pesos calculados de todas las características en la tabla \eqref{PesosFinalesCaracteristicas}, en la que los pesos de las categorías padres es la suma de cada una de las características hijas.

  \begin{figure}[H]
      \centering
      \includesvg[scale = 0.6]{archivos/5.Resultados/XGBoost/FeatureWeights}
      \caption{Pesos asignados por XGboost a las características.}
      \label{FeatureWeightsImage}
   \end{figure}


  \begin{table}[H]
    \centering
    \begin{tabular}{ |c|c|c|c| }
         \hline
         \textbf{Categoría} & \textbf{Peso Categoría} & \textbf{Característica} & \textbf{Peso Característica}\\

         \hline
         \multirow{4}{*}{Accidente}   & \multirow{4}{*}{0.299}        & Coordenada X          & 0.071\\
                                      &                               & Coordenada Y          & 0.066\\
                                      &                               & Hora                  & 0.055\\
                                      &                               & Vehículos implicados  & 0.051\\
                                      &                               & Tipo de accidente     & 0.057\\

         \hline
         \multirow{2}{*}{Carretera}   & \multirow{2}{*}{0.187}        & Distrito              & 0.059\\      
                                      &                               & Tipo carretera        & 0.127\\

         \hline
         \multirow{1}{*}{Ambiente}    & \multirow{1}{*}{0.050}        & Estado meteorológico  & 0.050\\

         \hline
         \multirow{1}{*}{Vehículo}    & \multirow{1}{*}{0.070}        & Tipo de vehículo      & 0.070\\


         \hline
         \multirow{4}{*}{Conductor}   & \multirow{4}{*}{0.394}        & Tipo Persona          & 0.177\\
                                      &                               & Sexo                  & 0.111\\
                                      &                               & Rango Edad            & 0.050\\
                                      &                               & Positivo              & 0.056\\
         \hline

    \end{tabular}

    \caption{Cálculo de pesos de características y categorías mediante XGBoost (los valores se han redondeado en base a tres decimales).}
    \label{PesosFinalesCaracteristicas}
  \end{table}


\section{Matrices}

  En esta sección se mostrará el proceso que sigue una observación del dataset original tipificada hasta llegar a una matriz de características \eqref{ProcesoMatriz}. En primer lugar, los valores de la muestra original \eqref{ProcesoMatriz:MuestraTipificada} se normalizan según el criterio \glsentryshort{zsn} para pasar a ser una observación cuyos valores estan acotados en un rango en función de la distribución normal de cada característica en el dataset \eqref{ProcesoMatriz:MuestraNormalizada}. El siguiente paso será posicionar cada uno de los valores de la muestra en la posición correspondiente de la matriz de acuerdo a los índices calculados en el paso anterior, de tal forma que servirán como entradas a las redes neuronales convolucionales \eqref{ProcesoMatriz:Array}.

    \begin{figure}[H]
        \scriptsize
        \centering
        \renewcommand{\arraystretch}{1.4}

        \captionsetup{singlelinecheck = false, format= hang, justification=raggedright, font=footnotesize, labelsep=space}

        \begin{subtable}{.4\textwidth}
          \centering
          \csvautotabular{archivos/5.Resultados/Matrices/fatal_original.csv}

          \captionsetup{singlelinecheck = false, format= hang, justification=raggedright, font=footnotesize, labelsep=space}
          \caption{Muestra de accidente tipificada.}
          \label{ProcesoMatriz:MuestraTipificada}
        \end{subtable}
        \hspace{20mm}
        \renewcommand{\arraystretch}{1.4}
        \begin{subtable}{.4\textwidth}
          \csvautotabular{archivos/5.Resultados/Matrices/fatal_normalized.csv}
          \caption{Muestra de accidente normalizada.}
          \label{ProcesoMatriz:MuestraNormalizada}
        \end{subtable}
        \vskip\baselineskip
        \begin{subtable}{.4\textwidth}
          \centering
          \renewcommand{\arraystretch}{.9}

          \csvautotabular{archivos/5.Resultados/Matrices/fatal_matrix.csv}
          \caption{Representación visual de la matriz de características.}
          \label{ProcesoMatriz:Array}
        \end{subtable}
        \hspace{5em}
        \begin{subfigure}{0.4\textwidth}
          \centering
          \includesvg[scale=0.4]{archivos/5.Resultados/Matrices/accidente_fatal}
          \caption{Muestra transformada en matriz de grises.}
          \label{ProcesoMatriz:VisualizacionDeMatriz}
        \end{subfigure}
      \caption{Proceso que sigue una muestra del conjunto de datos tipificada hasta llegar a una matriz.}
      \label{ProcesoMatriz}
      \end{figure}


  A modo de ejemplo se muestra en la figura \eqref{TresClasesAccidentesMatrices} un accidente de cada clase transformados a su matriz correspondiente.

  \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \includesvg[scale=0.5]{archivos/5.Resultados/Matrices/accidente_leve}
        \caption{Accidente leve.}
        \label{TresClasesAccidentesMatrices:AccidenteLeveImage}
      \end{subfigure}
      \hspace{1em}
      \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \includesvg[scale=0.5]{archivos/5.Resultados/Matrices/accidente_severo}
        \caption{Accidente severo.}
        \label{TresClasesAccidentesMatrices:AccidenteSeveroImage}
      \end{subfigure}
      \hspace{1em}
      \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \includesvg[scale=0.5]{archivos/5.Resultados/Matrices/accidente_fatal}
        \caption{Accidente fatal.}
        \label{TresClasesAccidentesMatrices:AccidenteFatalImage}
      \end{subfigure}

    \caption{Tres clases de accidentes convertidos a matrices.}
    \label{TresClasesAccidentesMatrices}
  \end{figure}

\section{KNN}

  Se puede observar en la tabla \eqref{BestParamsKNNGridSearchTable} los mejores parámetros para \textit{KNN} después de haber ejecutado \textit{Grid Search} sobre el conjunto de entrenamiento.\\

  \begin{table}[H]
      \centering
      \begin{tabular}{ |c|c| }
          \hline
          Atributo & Valor\\
          \hline
              Número de vecinos & 91 \\ 
              Tipo de distancia & Minkowski \\ 
          \hline
      \end{tabular}
      \caption{Mejores parámetros de KNN tras aplicar GridSearch.}
      \label{BestParamsKNNGridSearchTable}
  \end{table}


\section{Entrenamiento de modelos}

  A continuación se detallará una comparativa desde distintos puntos de vista de los resultados de los modelos. A nivel de rendimiento computacional se mostrarán los tiempos de entrenamiento. Para las redes neuronales, además, se mostrará la gráfica de evolución de la función de pérdida en base al Micro F1-score sobre los datos de entrenamiento y validación. En lo que respecta a los resultados de predicción se analizarán las métricas de clasificación y matrices de confusión para el conjunto de datos de entrenamiento. Cabe resaltar que las métricas de clasificación para la predicción de los modelos sobre el conjunto de entrenamiento no son concluyentes, esta primera clasificación es útil para hacerse a la idea de cómo han evaluado los modelos las muestras. Sin embargo, unos resultados prometedores sobre este conjunto no implican un buen rendimiento, un modelo que prediga a la perfección su conjunto de entrenamiento es síntoma de que está sobreentrenado y como consecuencia conllevará una pobre generalización sobre el conjunto de test o validación.  El objetivo es la predicción de datos futuros lleguen al modelo, por lo tanto, comprobaremos la calidad mediante los datos de test. En esta sección se analizarán los resultados sobre el conjunto de entrenamiento para mostrar a modo orientativo cómo han entrenado los modelos.

  \subsection{Tiempos de entrenamiento}

    En la figura \eqref{TiemposEntrenamientoImage} se muestran los tiempos de entrenamiento. Hay que recalcar que el método \glsentryshort{knn}, al proyectar las muestras de entrenamiento en un espacio n-dimensional, no conlleva un entrenamiento como tal. Observando la gráfica se puede apreciar que el modelo que más tiempo de entrenamiento emplea es el \glsentryshort{svc} con \textit{593} segundos, seguido de las redes convolucionales de una y dos dimensiones con \textit{287} y \textit{259} segundos respectivamente y, por último, el clasificador \glsentryshort{gnb}, que debido a su naturaleza es el que menos tiempo emplea en entrenar con \textit{0.02} segundos. 


    \begin{figure}[h]
      \centering
      \includegraphics[width=12cm]{archivos/5.Resultados/TiemposEntrenamiento}
      \caption{Comparación entre los tiempos de entrenamiento de los modelos.}
      \label{TiemposEntrenamientoImage}
    \end{figure}


  
  \subsection{Gráficas de entrenamiento}


    En las figuras \eqref{F1ScoreEvolution:1D} y \eqref{F1ScoreEvolution:2D} podemos observar la evolución de la métrica definida a maximizar (Micro F1-score) a lo largo de las 100 épocas que se han ejecutado para las redes convolucionales.\\


    Visualizando la gráfica de la convolucional de una dimensión \eqref{F1ScoreEvolution:1D} se puede comprobar que el Micro F1-score de entrenamiento va aumentando ligeramente a lo largo de las épocas sufriendo altibajos a medida que el modelo es entrenado, partiendo inicialmente desde un valor de entrenamiento menor a \textit{0.58} y llegando hasta \textit{0.68}. Observamos que los datos de validación sufren continuamente variaciones sin llegar a obtener una tendencia estable. Esto es debido a que, con la complejidad del problema, estos datos se asignan casi aleatoriamente entre las épocas.\\


    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{1\textwidth}
        \centering
        \includesvg[scale=0.3]{archivos/5.Resultados/CNN/1D/F1Score1D}
        \caption{Evolución de Micro F1-score sobre el conjunto de entrenamiento y validación CNN-1D.}
        \label{F1ScoreEvolution:1D}
      \end{subfigure}
      \vspace{1mm}
      \begin{subfigure}[b]{1\textwidth}
        \centering
        \includesvg[scale=0.3]{archivos/5.Resultados/CNN/2D/F1Score2D}
        \caption{Evolución de Micro F1-score sobre el conjunto de entrenamiento y validación CNN-2D.}
        \label{F1ScoreEvolution:2D}
      \end{subfigure}
        \caption{Evolución de Micro F1-score de las redes neuronales convolucionales.}
        \label{F1ScoreEvolution}
     \end{figure}

    En la figura \eqref{F1ScoreEvolution:2D} se puede apreciar la gráfica de entrenamiento y validación de la red convolucional de dos dimensiones. Observando que la tendencia de la función de pérdida sobre el conjunto de datos de entrenamiento es más estable respecto a la convolucional de una dimensión. Se aprecia cómo la red en la primera época comienza con un Micro F1-score de \textit {0.62} hasta llegar a \textit{0.78} en la época \textit{100}, por lo que se puede deducir que esta red consigue un mejor rendimiento sobre el conjunto de entrenamiento respecto a la red convolucional de una dimensión. Respecto a los datos de validación nos encontramos frente al mismo caso que la anterior figura, en cada epoch muchos de los datos son clasificados aleatoriamente debido a la complejidad del problema.

  \subsection{Reportes de clasificación}

    En la figura \eqref{TrainClassificationReport} se muestran los reportes de clasificación resultantes de predecir los datos de entrenamiento con los que han aprendido los modelos. Este análisis es útil para comprender qué han aprendido durante su entrenamiento, con la finalidad de observar cómo clasifican cada una de las clases. Como se puede observar, el modelo que mejores métricas de entrenamiento ofrece basándonos en el F1-score es el \glsentryshort{svc} \eqref{TrainClassificationReport:SVC}, que consigue un valor medio de \textit{0.841}. En segundo y tercer lugar, nos encontramos con dos modelos que, dependiendo de la clase a predecir, se intercalan en rendimiento, éstos son la red neuronal convolucional de una dimensión \eqref{TrainClassificationReport:CNN1D} y \glsentryshort{knn} \eqref{TrainClassificationReport:KNN}, que obtienen una media F1-score de \textit {0.721} y \textit {0.724} respectivamente. El cuarto lugar se posiciona la red neuronal convolucional de dos dimensiones \eqref{TrainClassificationReport:CNN2D}, consiguiendo un F1-score medio de \textit{0.599}, no llegando a superar en ninguna clase el rendimiento de las anteriores. Por último, el modelo que peor resultados ofrece sobre el conjunto de entrenamiento es el \textit{Gaussian Naive Bayes} \eqref{TrainClassificationReport:GNB}, que obtiene los valores más bajos de los cinco modelos entrenados con un valor medio F1-score de \textit{0.432}.

    \begin{table}[H]
        \scriptsize
        %\captionsetup{singlelinecheck = false, format= hang, justification=raggedright, font=footnotesize, labelsep=space}
        \renewcommand{\arraystretch}{1.1}
        \begin{subtable}{.5\textwidth}        
          \csvautotabular{archivos/5.Resultados/CNN/1D/1DClassificationReportTrain.csv}
          \caption{CNN-1D.}
          \label{TrainClassificationReport:CNN1D}
        \end{subtable}
        \hspace{1em}
        \begin{subtable}{.5\textwidth}
          \csvautotabular{archivos/5.Resultados/NB/NBClassificationReportTrain.csv}
          \caption{GNB.}
          \label{TrainClassificationReport:GNB}
        \end{subtable}
        \vspace*{2mm}
        \begin{subtable}{.5\textwidth}  
          \centering
          \csvautotabular{archivos/5.Resultados/SVC/SVCClassificationReportTrain.csv}
          \caption{SVC.}
          \label{TrainClassificationReport:SVC}
        \end{subtable}
        \hspace{1em}
        \begin{subtable}{.5\textwidth}
          \csvautotabular{archivos/5.Resultados/KNN/KNNClassificationReportTrain.csv}
          \caption{KNN.}
          \label{TrainClassificationReport:KNN}
        \end{subtable}
        \vspace*{2mm}
        %\captionsetup{justification=centering}
        \begin{subtable}{1\textwidth}
          \centering
          \csvautotabular{archivos/5.Resultados/CNN/2D/2DClassificationReportTrain.csv}
          \caption{CNN-2D.}
          \label{TrainClassificationReport:CNN2D}
        \end{subtable}
        \caption{Métricas clasificación para el conjunto de entrenamiento.}
        \label{TrainClassificationReport}
    \end{table}

  \subsection{Matrices de confusión}

    En este apartado analizaremos las matrices de confusión de los experimentos con los datos de entrenamiento. A simple vista se observa que \glsentryshort{gnb} \eqref{ConfusionMatrixTrainImages:GNB} tiende a predecir un gran número de muestras como accidentes fatales, lo que significa que debido a la simplicidad de este modelo no se consiguen predecir el resto de accidentes correctamente. Por otro lado, los modelos que mayor número de muestras de entrenamiento consiguen clasificar correctamente son el \glsentryshort{svc} \eqref{ConfusionMatrixTrainImages:SVC}, \glsentryshort{knn} \eqref{ConfusionMatrixTrainImages:KNN} y \glsentryshort{cnn1d} \eqref{ConfusionMatrixTrainImages:1D}. En una situación intermedia se encuentra la \glsentryshort{cnn1d} \eqref{ConfusionMatrixTrainImages:2D}, que ha clasificado un número de considerable de accidentes serios como leves.

    \begin{figure}[H]
        \centering
        \begin{subfigure}{0.4\textwidth}
            \includesvg[scale=0.35]{archivos/5.Resultados/CNN/1D/1DConfusionMatrixTrain}
            \caption{CNN-1D.}
            \label{ConfusionMatrixTrainImages:1D}
        \end{subfigure}
        \hspace{1mm}
        \begin{subfigure}{0.4\textwidth}
            \includesvg[scale=0.35]{archivos/5.Resultados/CNN/2D/2DConfusionMatrixTrain}
            \caption{CNN-2D.} 
            \label{ConfusionMatrixTrainImages:2D}
        \end{subfigure}
        \vspace*{0.1 mm}
        \begin{subfigure}{0.4\textwidth}
            \includesvg[scale=0.35]{archivos/5.Resultados/NB/NBConfusionMatrixTrain}
            \caption{GNB.}
            \label{ConfusionMatrixTrainImages:GNB}
        \end{subfigure}
        \hspace{1mm}
        \begin{subfigure}{0.4\textwidth}
            \includesvg[scale=0.35]{archivos/5.Resultados/KNN/KNNConfusionMatrixTrain}
            \caption{KNN.}
            \label{ConfusionMatrixTrainImages:KNN}
        \end{subfigure}
        \vspace*{0.1 mm}
        \begin{subfigure}{1\textwidth}
            \centering
            \includesvg[scale=0.35]{archivos/5.Resultados/SVC/SVCConfusionMatrixTrain}
            \caption{SVC.}
            \label{ConfusionMatrixTrainImages:SVC}
        \end{subfigure}
        \caption{Matrices de confusión de los modelos sobre el conjunto de entrenamiento.}
        \label{ConfusionMatrixTrainImages}
     \end{figure}


  \subsection{Comparativa entre modelos}

  En la figura \eqref{ResultsTrainImage} se muestra gráficamente el rendimiento de cada modelo sobre el conjunto de entrenamiento, las métricas utilizadas son la precisión, exhaustividad y el F1-score.

  \begin{figure}[H]
      \centering
      \includegraphics[width=13cm]{archivos/5.Resultados/ComparativaTrain}
      \caption{Comparativa de las métricas de las predicciones sobre el conjunto de entrenamiento de los modelos.}
      \label{ResultsTrainImage}
   \end{figure}



\section{Predicciones de modelos}

  \subsection{Reportes de clasificación}

    En esta sección se analizarán las métricas de clasificación mostradas en la tabla \eqref{TestClassificationReport} para cada una de las clases predecidas sobre el  conjunto de test. Estos reportes muestran la información con la que evaluaremos definitivamente los modelos, ya que explica cómo se comportan respecto a datos que nunca ha visto. Analizando el F1-score de los reportes se puede observar que el rendimiento de los modelos no se asemeja mucho a los resultados sobre el conjunto de entrenamiento. El modelo que mejor media F1-score presenta para las clases leves es la red convolucional de dos dimensiones \eqref{TestClassificationReport:CNN2D}, llegando a un \textit{0.949}, muy por encima del siguiente modelo \glsentryshort{knn} que ofrece un valor de \textit{0.81}. Además, la \glsentryshort{cnn2d} también ofrece la mejor métrica para los accidentes severos \textit{0.149}, llegando al doble de rendimiento respecto al modelo que le sigue, de nuevo el \glsentryshort{knn} con \textit{0.076}. En lo que respecta a los accidentes fatales, el modelo que mejor se adapta a esta clasificación es la red neuronal convolucional de una dimensión \eqref{TestClassificationReport:CNN1D}, obteniendo un \textit{0.004}, el doble que el \glsentryshort{knn} \eqref{TestClassificationReport:KNN}, que es de nuevo el siguiente mejor modelo en esta clase con \textit{0.002}.


    \begin{table}[H]
        \scriptsize
        \renewcommand{\arraystretch}{1.1}

        \begin{subtable}{.5\textwidth}     
          \csvautotabular{archivos/5.Resultados/CNN/1D/1DClassificationReportTest.csv}
          \caption{CNN-1D.}
          \label{TestClassificationReport:CNN1D}
        \end{subtable}
        \hspace{1em}
        \begin{subtable}{.5\textwidth}
          \csvautotabular{archivos/5.Resultados/NB/NBClassificationReportTest.csv}
          \caption{GNB.}
          \label{TestClassificationReport:GNB}
        \end{subtable}
        \vspace*{0.5 cm}
        \begin{subtable}{.5\textwidth}     
          \centering
          \csvautotabular{archivos/5.Resultados/SVC/SVCClassificationReportTest.csv}
          \caption{SVC.}
          \label{TestClassificationReport:SVC}
        \end{subtable}
        \hspace{1em}
        \begin{subtable}{.5\textwidth}     
          \csvautotabular{archivos/5.Resultados/KNN/KNNClassificationReportTest.csv}
          \caption{KNN.}
          \label{TestClassificationReport:KNN}
        \end{subtable}
        \vspace*{0.5 cm}
        \begin{subtable}{1\textwidth}     
          \centering
          \csvautotabular{archivos/5.Resultados/CNN/2D/2DClassificationReportTest.csv}
          \caption{CNN-2D.}
          \label{TestClassificationReport:CNN2D}
        \end{subtable}

      \caption{Métricas clasificación para el conjunto de test.}
      \label{TestClassificationReport}
    \end{table}


  \subsection{Matrices de confusión}

    En la figura \eqref{ConfusionMatrixTestImages} se muestran las matrices de confusión aplicadas al conjunto de test, se observa una representación visual de los reportes de clasificación. Esto nos permite atender a que los modelos \glsentryshort{gnb} \eqref{CConfusionMatrixTestImages:GNB}, \glsentryshort{svc} \eqref{ConfusionMatrixTestImages:SVC} y \glsentryshort{cnn2d} \eqref{ConfusionMatrixTestImages:2D} no clasifican correctamente ninguna de las observaciones de accidentes fatales, mientras que \glsentryshort{knn} \eqref{ConfusionMatrixTestImages:KNN} clasifica uno y \glsentryshort{cnn1d} \eqref{ConfusionMatrixTestImages:1D} clasifica cinco a costa de clasificar bastantes accidentes leves como fatales. En lo que respecta a los accdientes leves el modelo \glsentryshort{cnn2d} \eqref{ConfusionMatrixTestImages:2D} es el que mayor número clasifica correctamente, al igual que los accidentes serios.

    \begin{figure}[H]
        \centering
        \begin{subfigure}{0.4\textwidth}
            \includesvg[scale=0.35]{archivos/5.Resultados/CNN/1D/1DConfusionMatrixTest}
            \caption{CNN-1D.}
            \label{ConfusionMatrixTestImages:1D}
        \end{subfigure}
        \hspace{3em}
        % Añadir el espacio deseado, si se deja la linea en blanco la siguiente subfigura ira en una nueva linea
        \begin{subfigure}[b]{0.4\textwidth}
            \includesvg[scale=0.35]{archivos/5.Resultados/CNN/2D/2DConfusionMatrixTest}
            \caption{CNN-2D.} 
            \label{ConfusionMatrixTestImages:2D}
        \end{subfigure}
        \vspace*{0.5 cm}
        \begin{subfigure}[b]{0.4\textwidth}
            \includesvg[scale=0.35]{archivos/5.Resultados/NB/NBConfusionMatrixTest}
            \caption{GNB.}
            \label{ConfusionMatrixTestImages:GNB}
        \end{subfigure}
        \hspace{3em}
        \begin{subfigure}[b]{0.4\textwidth}
            \includesvg[scale=0.35]{archivos/5.Resultados/KNN/KNNConfusionMatrixTest}
            \caption{KNN.}
            \label{ConfusionMatrixTestImages:KNN}
        \end{subfigure}
        \vspace*{0.5 cm}
        \begin{subfigure}[b]{0.4\textwidth}
            \includesvg[scale=0.35]{archivos/5.Resultados/SVC/SVCConfusionMatrixTest}
            \caption{SVC.}
            \label{ConfusionMatrixTestImages:SVC}
        \end{subfigure}

        \caption{Matrices de confusión de los modelos sobre el conjunto de test.}
        \label{ConfusionMatrixTestImages}
     \end{figure}

  \subsection{Comparativa entre modelos}

    A continuación se puede observar una representación visual \eqref{ResultsTestImage} de las métricas analizadas en el apartado anterior, donde se muestra la precisión, exhaustividad y f1-score para cada modelo respecto al conjunto de datos de test.

    \begin{figure}[H]
        \centering
        \includegraphics[width=13cm]{archivos/5.Resultados/ComparativaTest}
        \caption{Comparativa de las métricas de las predicciones sobre el conjunto de test de los modelos.}
        \label{ResultsTestImage}
     \end{figure}