%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plantilla TFG/TFM
% Escuela Politécnica Superior de la Universidad de Alicante
% Realizado por: Jose Manuel Requena Plens
% Contacto: info@jmrplens.com / Telegram:@jmrplens
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Metodología}
\label{metodologia}

El desarrollo de este proyecto respeta tanto el proceso de desarrollo \textit{Software} como el ciclo de vida de proyectos de \textit{Ciencia de Datos}, por lo que se ha dividido en varias fases acontecidas que definiremos a continuación en base a la planificación mediante un \textit{Diagrama de Gantt}:


\section{Diagrama de flujo}

    \begin{figure}[H]
        \centering
        \includesvg[inkscapelatex=false]{archivos/DataflowImage}
        \caption{Flujo de datos del proceso del proyecto.}
        \label{DataflowImage}
    \end{figure}

\section{Diagrama de Gantt}

    \begin{figure}[H]
        \centering
        \includesvg[inkscapelatex=false]{archivos/GranttImage}
        \caption{Diagrama de Gantt de la planificación del proyecto.}
        \label{GranttImage}
    \end{figure}

\section{Proceso}

    En esta sección describiremos cada uno de los pasos que ha seguido el desarrollo del proyecto, desde la búsqueda inicial de datos hasta la implementación final de los algoritmos:

    \begin{enumerate}

        \item Datos

            El conjunto de datos con el que se ha trabajado en este proyecto describe accidentes de tráfico de la ciudad de Madrid en un periodo concreto, desde el año 2019 hasta el 2022. Este dataset ha sido obtenido desde \cite{DatasetMadrid}, repositorio donde es posible encontrar distintos datasets relativos a la Comunidad de Madrid.

            El número total de registros en este periodo de tiempo es de 60.966 instancias, cada una de las cuales consta de 17 características que se describirán en la tabla \ref{DescripcionDatosTabla}:

            \renewcommand{\arraystretch}{1.5}
            \begin{table}[H]
                \centering
                \begin{tabular}{|c|L{0.7\textwidth}|}
                    \hline
                    \textbf{Atributo}&\textbf{Descripción}\\
                    \hline
                    \texttt Número de expediente &
                    Identificador del incidente, si varios registros tienen el mismo un número de expediente se consideran como un mismo accidente y cada registro representa cada una de las distintas personas involucradas en él (Conductor, Pasajero o Peatón).\\
                    
                    \hline
                    \texttt Fecha &
                    Día mes y año en el que se ha producido el incidente.\\
                    
                    \hline
                    \texttt Hora &
                    Hora y minuto del día.\\

                    \hline
                    \texttt Localización &
                    Nombre de la calle (si procede).\\

                    \hline
                    \texttt Número &
                    Número de la calle donde ha ocurrido el incidiente (si procede).\\

                    \hline
                    \texttt Distrito &
                    Nombre del distrito de Madrid donde ha ocurrido el incidente.\\

                    \hline
                    \texttt Tipo de accidente &
                    Tipología de accidente, puede ser de diversos tipos (Colisión doble, Colisión múltiple, Alcance, Choque contra obstáculo, Atropello, Vuelco, Caída, Otras causas).\\

                    \hline
                    \texttt Estado meteorológico &
                    Condiciones climatológicas en el momento del incidente (Despejado, Nublado, Lluvia débil, Lluvia intensa, Granizado o Nevando)\\

                    \hline
                    \texttt Tipo de vehículo &
                    Clasificación en función del tipo de vehículos, p.e. motocicleta, turismo, cuadriciclo, etc.\\

                    \hline
                    \texttt Tipo de persona &
                    Rol de la persona involucrada (Conductor, Pasajero o Peatón)\\

                    \hline
                    \texttt Rango de edad &
                    Intervalo de edad la persona implicada.\\

                    \hline
                    \texttt Sexo &
                    Sexo de la persona implicada (Hombre o Mujer).\\

                    \hline
                    \texttt Lesividad &
                    Consecuencias físicas de la persona implicada, si ha necesitado asistencia sanitaria, si ha sido ingresada o si ha sido mortal.\\

                    \hline
                    \texttt Coordenada X &
                    Coordenada X del accidente en formato \textit{UTM}.\\

                    \hline
                    \texttt Coordenada Y &
                    Coordenada Y del accidente en formato \textit{UTM}.\\

                    \hline
                    \texttt Positivo en alcohol &
                    Si la persona implicada ha dado positivo en el control de alcoholemia (S o N).\\

                    \hline
                    \texttt Positivo en drogas &
                    Si la persona implicada ha dado positivo en el control de estupefacientes (S o N).\\

                    \hline
                \end{tabular}
                \caption{Descripción de los datos.}
                \label{DescripcionDatosTabla}

            \end{table}


            La variable respuesta de este proyecto es la lesividad, siguiendo la descripción del conjunto de datos, existen una serie de valores asignados a ésta categoría. Cada uno de ellos pertenece al menos a uno de los siguientes casos:

              \begin{itemize}
                    \item Consecuencias leves: comprende desde aquellas personas que no han resultado heridas hasta aquellas que han necesitado ingresar en un centro hospitalario no más de 24 horas.
                    \item Consecuencias severas: implicados que han requerido un ingreso hospitalario superior a 24 horas.
                    \item Consecuencias fatales: víctimas mortales dentro del margen de las 24 horas posteriores al accidente.
                \end{itemize}


            A continuación se muestran los códigos de numeración de la variable respuesta de este proyecto:

              \begin{itemize}
                    \item Leves:
                        \begin{itemize}
                            \item 1: Atención en urgencias sin posterior ingreso.
                            \item 2: Ingreso inferior o igual a 24 horas.
                            \item 5: Asistencia sanitaria ambulatoria con posterioridad.
                            \item 7: Asistencia sanitaria sólo en el lugar del accidente.
                            \item 14: Sin asistencia sanitaria.
                        \end{itemize}
                    \item Severos:
                        \begin{itemize}
                            \item 3: Ingreso superior a 24 horas.
                        \end{itemize}
                    \item Fatales:
                        \begin{itemize}
                            \item 4: Fallecido 24 horas.
                        \end{itemize}
                \end{itemize}



            Se pueden consultar los más detalles de las características del dataset descripción del conjunto de datos del portal \textit{Open Data} de Madrid \cite{InfoDatasetMadrid}.


            \begin{enumerate}

                \item Limpieza de datos

                    Una vez importados los datos en el proyecto, es requisito hacer una limpieza de éstos (\textit{Data Cleaning}), eligiendo las características que serán utilizadas como variables explicativas en las predicciones atendiendo además a los valores de las instancias, ya que pueden contener valores nulos, valores atípicos (\textit{outliers}) o contener valores erróneos. Esta problemática requiere de distintas estrategias a la hora de tratar estos valores.

                    En el caso del dataset de accidentes de tráfico de este proyecto se han escogido las siguientes características como variables explicativas \textit{hora, distrito, tipo accidente, estado meteorológico, tipo vehiculo, tipo persona, rango edad, sexo, positivo alcohol, positivo drogas, vehiculos implicados, coordenada x utm, coordenada y utm}.


                    Una vez que se han obtenido los predictores con los que trabajarán los modelos, se han eliminado aquellos registros duplicados y aquellos que tuvieran algún valor nulo en alguno de sus predictores. Por lo tanto, las dimensiones finales del conjunto de datos pasarán a ser 12 variables y 54.364 registros con respecto a las 17 características y 60966 filas originales. 

                \item Transformaciones de datos

                    En esta sección detallaremos las transformaciones sobre los datos que han sido necesarias para que los modelos trabajen con un conjunto de datos bien definido y consistente. Gran parte de los modelos de \glsentryshort{ml} necesitan de datos numéricos para poder ser entrenados debido a la necesidad de normalizar estos valores para una correcta optimización del modelo, por lo tanto se requiere de una serie de transformacíones que conviertan las variables categóricas a variables numéricas.

                    En primer lugar ha sido necesario transformar las columnas \textit{coordenada x utm} y \textit{coordenada y utm} a números enteros para que los modelos puedan interpretarlas y normalizarlas, ya que el rango de estas variables es del orden de 7 a 10 dígitos. Inicialmente estos valores estaban establecidos como \textit{String}, evitando cualquier formato de decimales estandarizado (utilizando puntos y comas indistintamente en distintas posiciones de los dígitos), debido a esto ha sido necesario crear un proceso que analizase cada casuístca y los tradujese a un formato estandarizado.

                    Las columnas \textit{positiva alcohol} y \textit{positiva drogas} se han unido en una nueva columna debido a la cantidad de valores nulos que existía en la segunda variable, por lo que se crea una nueva columna que hace referencia a la intoxicacion etílica o de estupefacientes.
  

                    En la tabla \ref{TransformacionDatosTabla} se define el resto de codificaciones aplicadas sobre el resto de variables del modelo para transformar estos campos a formato numérico.

                    \def\arraystretch{1.2}%
                    \begin{longtable}{|c|L{0.7\textwidth}|}\\

                        \hline
                        \textbf{Característica} & \textbf{Tipado}\\

                        \hline
                        \multirow{3}{*}{Lesividad}              & 0: Accidentes leves (\textit{1, 2, 5, 6, 7, 14}).\\
                                                                & 1: Accidentes severos (\textit{3}).\\
                                                                & 2: Accidentes fatales (\textit{4}).\\

                        \hline
                        \multirow{2}{*}{Hora}                   & 1: Noche (\textit{6 PM - 6 AM}).\\
                                                                & 2: Día (\textit{6 AM - 6 PM}).\\
                        \hline
                        \multirow{1}{*}{Distrito}               & Numeración en función de orden de aparición.\\

                        \hline
                        \multirow{2}{*}{Tipo Accidente}         & 1: Colisión fronto-lateral. \\
                                                                & 2: Alcance.\\
                                                                & 3: Colisión lateral.\\
                                                                & 4: Choque contra obstáculo fijo.\\
                                                                & 5: Colisión múltiple.\\
                                                                & 6: Caída.\\
                                                                & 7: Atropello a persona.\\
                                                                & 8: Colisión frontal.\\
                                                                & 9: Otro.\\
                                                                & 10: Solo salida de la vía.\\
                                                                & 11: Vuelco.\\
                                                                & 12: Atropello a animal.\\
                                                                & 13: Despeñamiento.\\
                        \hline
                        \multirow{7}{*}{Estado Meteorológico}   & 1: Despejado.\\
                                                                & 2: Nublado.\\
                                                                & 3: Lluvia débil.\\
                                                                & 4: Lluvia intensa.\\
                                                                & 5: Granizando.\\
                                                                & 6: Nevando.\\
                                                                & 7: Se desconoce.\\
                        \hline
                        \multirow{2}{*}{Tipo Vehículo}          & Numeración en función de orden de aparición.\\

                        \hline
                        \multirow{3}{*}{Tipo Persona}           & 1: Conductor.\\
                                                                & 2: Pasajero.\\
                                                                & 3: Peatón.\\
                        \hline
                        \multirow{5}{*}{Rango Edad}             & 1: Menores de 18 años.\\
                                                                & 2: De 18 a 25 años.\\
                                                                & 3: De 25 a 65 años.\\
                                                                & 4: Mayores de 65 años.\\
                                                                & 5: Edad desconocida.\\
                        \hline
                        \multirow{3}{*}{Sexo}                   & 1: Hombre.\\
                                                                & 2: Mujer.\\
                                                                & 3: Desconocido.\\
                        \hline
                        \multirow{2}{*}{Positivo}               & 1: Sí.\\
                                                                & 2: No.\\
                        \hline

                    \caption{Transformaciones aplicadas a los datos.}
                    \label{TransformacionDatosTabla}\\
                    \end{longtable}


                \item Análisis de datos

                    Una de las fases más importantes antes de comenzar el modelado en cualquier proyecto \textit{Data Science} es el análisis de datos. Este proceso tiene como objetivo la descripción de los datos, identificación de \textit{outliers}, valores erróneos y tendencias que se puedan dar en ellos.\\

                    Comenzaremos analizando los datos que correspondan a cada una de las tres posibles clases (leves, severos y fatales) realizando un histograma \ref{CasualtyClassImage}. Como podemos observar, nos encontramos ante un dataset claramente desbalanceado con respecto a la variable respuesta, contando con 53.009 accidentes leves, 1.271 severos y 84 fatales.\\

                    Un conjunto de datos desbalanceado se define como aquel que contiene un número de instancias mucho mayor de determinadas clases con respecto al resto \cite{WhyImbalancedDataIsAProblem}. Esto se convierte en un problema para los modelos de clasificación ya que estos modelos tenderán a predecir las muestras como aquellas que pertenecen a las mayoritarias sobre el conjunto de test debido a que las reglas de classificación de las clases menos numerosas tienden a ser ignoradas.

                    El desbalanceo de datos es un problema ampliamente estudiado a lo largo de los años y existen numerosos métodos orientados a tratar este problema mediante distintas técnicas de muestreo \cite{ImbalancedDataReview}, por lo que será necesario aplicar distintas técnicas sobre el conjunto de datos.


                    \begin{figure}[H]
                        \centering
                        \includesvg[scale=0.3]{archivos/Datos/CasualtyClass}
                        \caption{Histograma de tipo de accidente.}
                        \label{CasualtyClassImage}
                     \end{figure}


                    \begin{figure}[H]
                        \centering
                        \includesvg[scale=0.3]{archivos/Datos/CorrelationMatrix}
                        \caption{Matriz de correlación para los predictores escogidos del dataset.}
                        \label{CorrelationMatrixImage}
                     \end{figure}

                    \begin{figure}[H]
                        \centering
                        \includesvg[width=15cm]{archivos/Datos/PCAImage}
                        \caption{PCA aplicado a los datos.}
                        \label{PCAImage}
                     \end{figure}



                \item Normalización de datos


                    La normalización de datos es un proceso necesario a la hora de obtener buenos resultados en los modelos predictivos de \glsentryshort{ml}. Cuando un modelo es entrenado, es bastante probable existan características en distintas escalas. En consecuencia, las características que contengan un rango de valores numérico más alto, ya sea por la naturaleza de la variable o porque se encuentren en otra escala, dominarán a aquellas características que contengan un rango menor a la hora de aplicar modelos \glsentryshort{ml} que sean sensibles a la desnormalización de datos, como por ejemplo \glsentryshort{ml} o \glsentryshort{knn} \cite{NormalizationSensitiveModels}.\\


                    El proceso de normalización tiene como objetivo minimizar el \textit{bias} de aquellas características cuya contribución sea mayor a la hora de encontrar patrones entre los datos. Existen distintas técnicas de normalización como por ejemplo \glsentryfull{mc}, \glsentryfull{vss} o \glsentryfull{mmn} entre otras \cite{DataNormalizationInvestigation}.\\


                    En este proyecto se ha utilizado la normalización \glsentryfull{zsn} debido a las propiedades que ofrece, \glsentryshort{zsn} que utiliza la media y la desviación típica para reescalar los datos de tal forma que la distribución de ellos esté definida por una media de cero y una desviación típica unitaria, consiguiendo representaciones de acuerdo a una distribución normal.\\

                    Los resultados obtenidos después de aplicar esta técnica se pueden interpretar como la distancia de cada valor con respecto a la media.

                   \begin{center}
                        $x^* = \frac{x - u}{\sigma}$
                    \end{center}


                    Donde $x^*$ es una muestra de una característica de los datos, $u$ es la media total de dicha característica y $\sigma$ es la desviación típica total de los valores de la característica.


                \item Separación de datos

                    La siguiente fase en cualquier modelo de \glsentryshort{ML} es la separación de datos (\textit{split}). Esta fase consiste en dividir el conjunto total de datos en al menos dos subconjuntos, uno de entrenamiento y otro de test. El modelo se entrenará en base a los datos de entrenamiento y se evaluará con los datos de test, los resultados sobre este conjunto permitirán comparar los modelos en base a las predicciones sobre las muestras que nunca han visto.\\


                    Comúnmente la proporción de datos de entrenamiento y test está establecida en \textit{0.8} y \textit{0.2} respectivamente, en la figura \ref{DataSplitImage} se muestra una representación visual de esta división.


                    \begin{figure}[h]
                        \centering
                        \includegraphics[width=10cm]{archivos/Datos/DataSplit}
                        \caption{https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6. División de un conjunto de datos en datos de entrenamiento y test.}
                        \label{DataSplitImage}
                     \end{figure}


                \item Remuestreo


                    Estas técnicas permiten operar sobre el conjunto de datos para balancearlo, con el objetivo de que el modelo no se vea muy afectado debido a la diferencia de las clases mayoritarias respecto a las minoritarias. En este proyecto se han hecho uso de las siguientes técnicas de remuestreo:

                    
                    \begin{enumerate}

                        \item Downsampling: tiene como objetivo balancear el conjunto de datos para que todas las clases tengan el mismo número de muestras igualando el número de muestras de las clases mayoritarias a aquellas clases que contienen menos muestras, descartando aquellas que sobrepasen este límite. 
                        
                        
                        \cite{Downsampling}

                        \textbf{No se redactará más hasta que se compruebe en los experimentos que esa técnica nos sirve}
                        

                        \item Generación de datos sintéticos: técnica que permite generar datos artificiales en base a los límites que separan unas clases de otras. Se ha hecho uso de la tećnica \glsentryfull{smoteii} \cite{SMOTEII}. Esta técnica selecciona los vecinos más cercanos de la misma clase y genera nuevas muestras en base al espacio entre la clase minoritaria y sus vecinos más cercanos.\\

                        \glsentryshort{smoteii} ha sido utilizado para generar más muestras artificiales de los accidentes pertenecientes a las clases minoritarias (\textit{severos} y \textit{graves}).

                    \end{enumerate}


                    Una vez aplicadas las técnicas de remuestreo al conjunto de datos para balancearlo, es útil observar cuál es la representación espacial de los datos sintéticos generados por \glsentryshort{smoteii} con respecto a los datos originales mediante \glsentryfull{tsne} \cite{TSNEPaper}. \glsentryshort{tsne} es una técnica que permite visualizar datos multidimensionales proyectando cada muetra en un espacio bidimensional o tridimensional. Este método es una variante simplificada y optimizada del algoritmo \glsentryfull{sne}.

                    Mientras que \glsentryshort{sne} convierte las distancias Euclídeas entre las muestras a probabilidades condicionales que presenten similaridades entre sí mediante probabilidades Gaussianas, \glsentryshort{tsne} modifica su función de coste de tal forma que utiliza una distribución t-Student, permitiendo además trabajar con gradientes simplificados.


                    En la figura \ref{TSNEImages} se muestran las proyecciones de \glsentryshort{tsne} (tanto la representación bidimensional como la tridimensional) sobre el conjunto de datos de entrenamiento original y aquellos que han sido generados artificialmente por \glsentryshort{smoteii}.


                    \begin{figure}
                        \centering
                        \begin{subfigure}[b]{0.4\textwidth}
                            \centering
                            \includesvg[scale=0.4]{archivos/Datos/TSNE/2d_tsne_clean}
                            \caption{TSNE de 2 componentes aplicado a los datos originales.}
                            \label{TSNEImages:Clean2D}
                        \end{subfigure}
                        % Añadir el espacio deseado, si se deja la linea en blanco la siguiente subfigura ira en una nueva linea
                        \begin{subfigure}[b]{0.4\textwidth}
                            \centering
                            \includesvg[scale=0.4]{archivos/Datos/TSNE/2d_tsne_train}
                            \caption{TSNE de 2 componentes aplicado a los datos generados por SMOTE-II.}
                            \label{TSNEImages:Train2D}

                        \end{subfigure}
                        \begin{subfigure}[b]{0.4\textwidth}
                            \centering
                            \includesvg[scale=0.4]{archivos/Datos/TSNE/3d_tsne_clean}
                            \caption{TSNE de 3 componentes aplicado a los datos originales.}
                            \label{TSNEImages:Clean3D}
                        \end{subfigure}
                        \begin{subfigure}[b]{0.4\textwidth}
                            \centering
                            \includesvg[scale=0.4]{archivos/Datos/TSNE/3d_tsne_train}
                            \caption{TSNE de 3 componentes aplicado a los datos generados por SMOTE-II.}
                            \label{TSNEImages:Train3D}
                        \end{subfigure}
                        \caption{TSNE de 2 y 3 componentes aplicado a los datos originales y a los generados sintéticamente (\glsentryshort{smoteii}).}
                        \label{TSNEImages}
                     \end{figure}

            \end{enumerate}





        \item Algoritmo Genético

            Para una correcto entrenamiento de un modelo predictivo es necesario optimizar los hiperparámetros con los que el modelo será entrenado. En este proyecto es necesario optmizar los hiperparámetros del algoritmo \glsentryshort{xgboost}.\\

            Para ello se ha hecho uso de algoritmos genéticos \cite{GAXGBoostCode}, donde cada individuo perteneciente a la población de una generación está formado por una configuración de hiperparámetros específica, de tal forma que a lo largo de las iteraciones los individuos evolucionarán mediante el cruce y la mutación para dar lugar a nuevas configuraciones de hiperparámetros optimizadas \cite{GAXGBoostPaper}.

            Debido al coste computacional que tendría optimizar todos los parámetros por la magnitud del espacio de búsqueda y al no ser necesario tener en cuenta todos, se han seleccionado aquellos que más influencia tienen en el entrenamiento del modelo. Los hiperparámetros de los que consta cada individuo de la población son:

            \begin{enumerate}

                \item Profundidad máxima: es la máxima altura que puede tomar el árbol. Si el árbol de decisión alcanza demasiada profundidad tenderá al \textit{overfitting} ya que aprenderá relaciones complejas entre los datos que pueden deberse a ruido en los datos de entrenamiento.

                \item Peso mínimo de los hijos: es el mínimo peso que se establece a la hora de crear un nuevo nodo en el árbol. Cuando se entrena un árbol de decisión éste genera nuevos nodos en base a máxima separabilidad de los datos de entrenamiento en cada nivel. Con el límite de peso de los hijos establecemos un umbral mínimo de muestras que deben pertenecer a un nodo para realizar la separación. Un valor bajo en este parámetro permitirá crear nodos con menos muestras y por lo tanto el modelo tenderá al \textit{overfitting}.

                \item ETA: tamaño de paso utilizado para aplicar descenso por gradiente para minimizar la pérdida de los árboles anteriores.

            \end{enumerate}

            La inicialización y mutación de los valores de los individuos viene dada por una limitación mínima y máxima que pueden, ya que, si no se contemplase, los valores podrían tomar valores extremos reduciendo el rendimiento de entrenamiento y resultados. Por lo tanto los individuos variarán sus parámetros tomando un valor aleatorio de estos rangos.  Los parámetros de las nuevas soluciones mutarán dentro de unos límites específicos para cada parámetro establecidos como máximos y mínimos para que no tomen valores extremos. La tabla \cite{InitAndMutationLimitsHyperparamsTable} muestra los límites de los hiperparámetros.

            \begin{table}[H]
                \centering
                    \begin{tabular}{ |c|c|c| } 
                    \hline
                    Hiperparámetro & Inicialización & Mutación\\
                    \hline
                        Profundidad Máxima & [1, 25] & [-6, 6]\\ 
                        Peso mínimo de los hijos & [0.01, 20.0] & [-7, 7] \\ 
                        ETA & [0.01, 1] &  [-0.3, 0.3] \\ 
                    \hline

                    \end{tabular}

                \caption{Límites de inicialización y mutación de los hiperparámetros de los individuos.}
                \label{InitAndMutationLimitsHyperparamsTable}
            \end{table}

            Una vez inicializados aleatoriamente los TODO:X individuos especificados en la población, éstos se evaluarán instanciando TODO:X modelos \glsentryshort{xgboost}con los valores de cada individuo en la población. El conjunto de datos sobre el que entrenará cada instancia \glsentryshort{xgboost} será el conjunto de entrenamiento TODO:XX. La función \textit{fitness} que evaluará cada individuo será la métrica TODO:F1-X aplicada sobre el conjunto de test obtenido en el proceso de separación de datos.

            \textbf{TODO: No se redactará más hasta tener claro cuál es la mejor forma de entrenar el \glsentryshort{xgboost} (función de validación y datos de entrenamiento)}

            En la figura [\ref{EvolucionHiperparametrosImage}] se pueden visualizar la evolución de los parámetros del mejor individuo en cada generación.

            \begin{figure}[H]
                \centering
                \includesvg[scale=0.4]{archivos/GA/EvolucionHiperparametros}
                \caption{Evolución de hiperparámetros a lo largo de las iteraciones.}
                \label{EvolucionHiperparametrosImage}
             \end{figure}

            \begin{figure}[H]
                \centering
                \includesvg[scale=0.4]{archivos/GA/EvolucionF1Score}
                \caption{Evolución del macro F1 score a lo largo de las iteraciones.}
                \label{EvolucionF1ScoreImage}
             \end{figure}
             
            En la tabla \ref{BestGASolutionTable} se pueden observar el mejor individuo obtenido después de \textit{TODO: X} generaciones.

            \begin{table}[H]
                \centering
                    \begin{tabular}{ |c|c| } 
                        \hline
                        Hiperparámetro & Valor\\
                        \hline
                            Profundidad Máxima & TODO \\ 
                            Peso mínimo de los hijos & TODO \\ 
                            ETA & TODO \\ 
                        \hline

                    \end{tabular}
                \caption{Mejores parámetros de XGBoost tras aplicar el algoritmo genético.}
                \label{BestGASolutionTable}
            \end{table}

            %SE HACE CON EL CONJUNTO DE ENTRENAMIENTO DOWNSAMPLED
            %SE TESTA CON VALIDACION

        \item XGBoost


            Una vez se han optimizados los hiperparámetros del \glsentryshort{xgboost}, se calcula la importancia de cada clase mediante el cálculo de los pesos.


            \begin{figure}[H]
                \centering
                \includesvg[scale = 0.6]{archivos/XGBoost/FeatureWeights}
                \caption{Pesos asignados por XGboost a las características.}
                \label{FeatureWeightsImage}
             \end{figure}

        \item Construcción de imágenes


            Debido a que las \glsentryshort{cnn} aprenden patrones sobre la entrada de datos como imágenes, es importante que éstas estén construidas de tal forma que maximice la representación de la información, es decir, es necesario aplicar técnicas que posicionen cada característica en un pixel de la matriz maximizando la representación de los accidentes (TODO: \textbf{relamente no entiendo muy bien la motivación que ha seguido la gente de TASPCNN a la hora de construir las imágenes, falta entender por qué lo hacen así, no lo he encontrado en el paper.})

            Por lo tanto, el siguiente paso será transferir cada una de las muestras tabulares de los accidentes a una imagen en escala de grises, donde a cada característica se le asignará una posición de la matriz (\textit{5 x 5}), de tal forma que éstas sean la entrada a las \textit{CNN}.

            Para este objetivo se aplicará el algoritmo FV2GI propuesto en el artículo \cite{TASPCNN}, que asigna las características de una muestra en representación tabular en función de la importancia que éstas presenten en una jerarquía.

            Tal y como se propone en \cite{JerarquiaImagenes} las características que provocan un accidente de tráfico pueden englobarse en una serie de elementos o categorías principales, concretamente: \textit{características del conductor, el estado de la carretera, características propias del vehículo y condiciones del ambiente}. Se muestra en la tabla \ref{JerarquiaCaracteristicasTabla} las asignaciones de las variables explicativas del conjunto de datos en función de esta jerarquía.


            \begin{table}[H]
              \centering
              \begin{tabular}{ |c|c| }
                   \toprule
                   \textbf{Categoría} & \textbf{Variable}\\

                   \midrule
                   \multirow{4}{*}{Accidente}            & Coordenada X.\\
                                                         & Coordenada Y.\\
                                                         & Hora.\\
                                                         & Vehículos implicados.\\

                   \midrule
                   \multirow{1}{*}{Ambiente}             & Estado meteorológico.\\

                   \midrule
                   \multirow{2}{*}{Carretera}            & TODO: ESTO NO DEBERIA ESTAR AQUI Tipo de accidente\\
                                                         & Distrito\\

                   \midrule
                   \multirow{4}{*}{Conductor}            & Tipo Persona.\\
                                                         & Sexo.\\
                                                         & Rango Edad.\\
                                                         & Positivo.\\

                   \bottomrule
              \end{tabular}
              \caption{Transformaciones aplicadas a los datos.}
              \label{JerarquiaCaracteristicasTabla}
            \end{table}



            Una vez definida la jerarquía de características y los pesos asociados a cada una de ellas gracias al algoritmo \glsentryshort{xgboost} se construyen las imágenes de acuerdo al criterio \textit{FV2GI}. Este proceso consta de los siguientes pasos:

            \begin{enumerate}

                \item Generación de \textit{n} imágenes inicializadas a 0, donde \textit{n} es el número de muestras tabulares en el dataset.
                \item Asignación de una fila a cada padre en función de su peso.
                \item Asignacíón de la la posición de cada característica hija en función de su peso dentro de la fila de su padre.
            
            \end{enumerate}

            Se deben tomar las siguientes consideraciones a la hora de aplicar \textit{FV2GI}:

            \begin{enumerate}

                \item La importancia de un padre viene dada por ĺa suma de los pesos de las características hijas.

                \item La asignación de las filas de los padres se realiza de forma intercalada en función de su peso. Aquel padre que más importancia tenga irá posicionado en la fila central de la matriz, el segundo padre irá posicionado por encima de éste y el tercero por debajo y así sucesivamente, de tal forma que se irá creando una estructura en la que dichos padres se interpolan entre las filas en función de su peso.

                \item Una vez se han asignado los padres a las filas se realiza el mismo procedimiento con las características hijas a nivel de columna. Donde la característica que más importancia tenga irá posicionada en el centro, la segunda irá posicionada a su izquierda, la tercera a la derecha y así sucesivamente.


            \end{enumerate}

            El resultado de aplicar ambas técnicas da lugar a la representación en forma matricial de los accidentes, como se puede observar en la figura \ref{SampledImagesExampleImage}.

            \begin{figure}[H]
                \centering
                \includesvg[scale=0.5]{archivos/SampledImagesExample/madrid_image_example_0}
                \includesvg[scale=0.5]{archivos/SampledImagesExample/madrid_image_example_1}
                \includesvg[scale=0.5]{archivos/SampledImagesExample/madrid_image_example_2}
                \caption{Representación de las muestras de accidentes en forma de matriz de grises.}

                \label{SampledImagesExampleImage}
            \end{figure}

        \item Implementación de Modelos

            En esta sección analizaremos los modelos utilizados en este proyecto con el objetivo de realizar un estudio comparativo entre las arquitecturas.


            \begin{enumerate}

                \item KNN

                    El método \glsentryshort{knn} servirá como referencia para testar el rendimiento del resto de modelos. Al ser un método que se aplica sobre un conjunto de datos tabular original, no hará uso de las imágenes generadas.

                    Es necesario optimizar los parámetros de este algoritmo para conseguir un buen rendimiento, por lo que aplicaremos la técnica \textit{Grid Search} \cite{GridSearchSklearnLibrary}. Esta técnica permite la optimización de los valores de los hiperparámetros mediante una búsqueda exhaustiva en un espacio de búsqueda definido por el usuario, probando distintas combinaciones hasta cubrirlo por completo. 


                    Se puede observar en la tabla \ref{BestParamsKNNGridSearchTable} los mejores parámetros para \textit{KNN} después de haber ejecutado \textit{Grid Search} sobre el conjunto de entrenamiento.\\

                    \begin{table}[H]
                        \centering
                        \begin{tabular}{ |c|c| }
                            \hline
                            Atributo & Valor\\
                            \hline
                                Número de vecinos & 21 \\ 
                                Tipo de distancia & Minkowski \\ 
                            \hline
                        \end{tabular}
                        \caption{Mejores parámetros de KNN tras aplicar GridSearch.}
                        \label{BestParamsKNNGridSearchTable}
                    \end{table}


                \item CNN

                    Una vez definidos los pasos que sigue el entrenamiento de una \textit{NN} y las características propias de las \textit{CNNs}, podemos analizar las arquitecturas de las \textit{CNNs} implementadas que se han aplicado en este proyecto. Cabe mencionar que el funcionamiento de ambas \textit{CNNs} únicamente difiere en el tamaño del \textit{kernel} (unidimensionales o bidimensionales según sea el caso correspondiente) y la forma en la que éste se desplaza debido a su dimensionalidad, por lo tanto detallaremos ambas arquitecturas de la misma forma.

                    La arquitectura consta de cuatro capas convolucionales con tamaños de kernel (\textit{1 x 3}) en caso de las \glsentryshort{cnn1d} y de tamaño (\textit{3 x 3}) para las \glsentryshort{cnn2d}. Estos kernels se proyectarán en \textit{256} canales para formar el filtro convolucional asociado a cada capa. A la salida de cada uno de los mapas de características se aplica un proceso de \glsentryshort{batchnormalization}.

                    El \textit{padding} del kernel se ha establecido en 1 para ambos tipos de redes, de tal forma que las convoluciones se aplícarán añadiendo ceros en los ĺímites de las imágenes, y los \textit{strides} en (\textit{1}) para las \glsentryshort{cnn1d} y (\textit{1, 1}) para las \glsentryshort{cnn2d}, por lo tanto el desplazamiento de los kernels se hará píxel a píxel tanto en las \glsentryshort{cnn1d} como en las \glsentryshort{cnn2d}.

                    A la salida de cada capa convolucional se aplica la función de activación \glsentryfull{relu}, que se comporta devolviendo el valor $0$ para aquellas entradas que sean negativas y el valor original para aquellas que sean positivas, se puede apreciar el comportamiento en la figura \ref{RELUImage}. El rendimiento de esta función de activación en el campo de las imágenes está ampliamente extendido, además, evita la probabilidad de aparición del gradiente evanescente \cite{GradientVanishingRelu}.

                    \begin{center}
                        $f(x) = \left\{
                                       \begin{array}{lr}
                                         0 & \text{if } x<=0\\
                                         x & \text{if } x>0
                                       \end{array}
                                \right.$
                    \end{center}

                    \begin{figure}[h]
                        \centering
                        \includegraphics[width=10cm]{archivos/CNN/RELUImage}
                        \caption{https://www.researchgate.net/journal/Transport-in-Porous-Media-1573-1634. Función ReLU}
                        \label{RELUImage}
                     \end{figure}

                    La salida de la última capa de la convolución transformará el mapa de características de tamaño (\textit{5 x 5}) generada a una capa Flatten, que aplanará la matriz de tal forma que la convertirá en un vector unidimensional de (\textit{1 x 25}). A continuación se aplicará una capa densa que conectará cada uno de los \textit{25} nodos de la capa \textit{Flatten} con los \textit{128} nodos de la capa densa, que generará los logits antes de aplicar la última función de activación \textit{Softmax} que devolverá la clase predicha.


                    Para ejemplificar la arquitectura de las \glsentryshort{nn} propuestas se muestra el caso de la \glsentryshort{cnn2d} en la figura \ref{TASPCNNIMAGE}


                    \begin{figure}[h]
                        \centering
                        \includegraphics[width=17cm]{archivos/CNN/2D/TASCNN}
                        \caption{Arquitectura de la CNN-2D mostrando una  kernels aprendidos durante el entrenamiento.}
                        \label{TASPCNNIMAGE}
                     \end{figure}


            \end{enumerate}

            \cite{AutoSklearn}

    \end{enumerate}

\newpage



\section{Inserción de figuras}


Las figuras son un caso un poco especial ya que \LaTeX~busca el mejor lugar para ponerlas, no siendo necesariamente el lugar donde está la referencia. Por ello es importante añadirle un ``caption'' y un ``label'' para poder hacer referencia a ellas en el párrafo correspondiente. Nosotros ponemos la referencia a la figura \ref{multiimagen} que está en la página \pageref{multiimagen}, justo aquí debajo, pero \LaTeX ~puede que la ubique en otro lugar. (observa el código \LaTeX~ de este párrafo para observar como se realizan las referencias. Estos detalles también se aplican a tablas y otros objetos).



Existe también la posibilidad de realizarlo sin tablas, con subfiguras:
\begin{lstlisting}[style=Latex-color]
\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.4\textwidth} % Espacio horizontal ocupado por la subfigura
    	\centering
        \includegraphics[width=4cm]{archivos/subs-sin} % Tamaño de la imagen
        \caption{Sin procesado.}
        \label{fig:gull}
    \end{subfigure}
    ~ % Añadir el espacio deseado, si se deja la linea en blanco la siguiente subfigura ira en una nueva linea
    \begin{subfigure}[b]{0.4\textwidth} % Espacio horizontal ocupado por la subfigura
    	\centering
        \includegraphics[width=4cm]{archivos/subs-con} % Tamaño de la imagen
        \caption{Con procesado.}
        \label{fig:tiger}
    \end{subfigure}
    \caption{Ejemplo de subfiguras}\label{sistemass}
\end{figure}
\end{lstlisting}
\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
    	\centering
        \includegraphics[width=4cm]{archivos/subs-sin}
        \caption{Sin procesado.}
        \label{fig:gull1}
    \end{subfigure}
    ~ % Añadir el espacio deseado, si se deja la linea en blanco la siguiente subfigura ira en una nueva linea
    \begin{subfigure}[b]{0.4\textwidth}
    	\centering
        \includegraphics[width=4cm]{archivos/subs-con}
        \caption{Con procesado.}
        \label{fig:tiger1}
    \end{subfigure}
    \caption{Ejemplo de subfiguras}\label{sistemass1}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{\textwidth}
    	\centering
        \includegraphics[width=4cm]{archivos/subs-sin}
        \caption{Sin procesado.}
        \label{fig:gull2}
    \end{subfigure}
    
    \begin{subfigure}[b]{\textwidth}
    	\centering
        \includegraphics[width=4cm]{archivos/subs-con}
        \caption{Con procesado.}
        \label{fig:tiger2}
    \end{subfigure}
    \caption{Ejemplo de subfiguras vertical}\label{sistemass2}
\end{figure}

Si eliminas la línea '\textbackslash caption' de las subfiguras, tendrás las imágenes sin la información individual, aunque sí con la principal. Y obviamente, si eliminas el de la figura no se mostrará ninguna información.


\begin{table}[h]
\centering
\begin{tabular}{ccc}
\includegraphics[scale=0.2]{archivos/130} & \includegraphics[scale=0.2]{archivos/160} & \includegraphics[scale=0.2]{archivos/190} \\
$Dist=1m \; ; \; \phi=30º$  & $Dist=1m \; ; \; \phi=60º$  & $Dist=1m \; ; \; \phi=90º$  \\
\includegraphics[scale=0.2]{archivos/230} & \includegraphics[scale=0.2]{archivos/260} & \includegraphics[scale=0.2]{archivos/290} \\
$Dist=2m \; ; \; \phi=30º$  & $Dist=2m \; ; \; \phi=60º$  & $Dist=2m \; ; \; \phi=90º$  \\
\includegraphics[scale=0.2]{archivos/330} & \includegraphics[scale=0.2]{archivos/360} & \includegraphics[scale=0.2]{archivos/390} \\
$Dist=3m \; ; \; \phi=30º$  & $Dist=3m \; ; \; \phi=60º$  & $Dist=3m \; ; \; \phi=90º$ \\
\end{tabular}
\caption{Esta es una tabla con múltiples imágenes. Útil cuando se deben mostrar varias juntas.}
\label{multiimagen} % 
\end{table}